# ğŸ¼ Pandas ile Veri Analizi - KapsamlÄ± EÄŸitim DokÃ¼manÄ±

> **3 Saatlik Veri Bilimi AtÃ¶lyesi** | MiniMax Agent tarafÄ±ndan hazÄ±rlanmÄ±ÅŸtÄ±r

---

## ğŸ“š Ä°Ã§indekiler

1. [ğŸš€ Pandas'a GiriÅŸ ve Kurulum](#1-pandas-a-giriÅŸ-ve-kurulum)
2. [ğŸ“Š Temel Veri YapÄ±larÄ±: Series ve DataFrame](#2-temel-veri-yapÄ±larÄ±-series-ve-dataframe)
3. [ğŸ“ Veri Okuma/Yazma Ä°ÅŸlemleri](#3-veri-okuma-yazma-iÅŸlemleri)
4. [ğŸ› ï¸ Veri ManipÃ¼lasyonu ve Temizleme](#4-veri-manipÃ¼lasyonu-ve-temizleme)
5. [ğŸ” Veri Filtreleme ve SeÃ§me](#5-veri-filtreleme-ve-seÃ§me)
6. [ğŸ“ˆ Temel Ä°statistiksel Analizler](#6-temel-istatistiksel-analizler)
7. [ğŸ“‹ GruplandÄ±rma ve Pivot Tablolar](#7-gruplandÄ±rma-ve-pivot-tablolar)
8. [ğŸ’¼ Pratik Uygulama Projesi](#8-pratik-uygulama-projesi)
9. [ğŸ“ Pandas Cheat Sheet](#9-pandas-cheat-sheet)
10. [ğŸ”— Kaynaklar ve Ek Materyaller](#10-kaynaklar-ve-ek-materyaller)

---

## ğŸ¯ Hedef Kitle

Bu dokÃ¼man aÅŸaÄŸÄ±daki Ã¶zelliklere sahip katÄ±lÄ±mcÄ±lar iÃ§in tasarlanmÄ±ÅŸtÄ±r:

- âœ… **Temel Python bilgisi** (deÄŸiÅŸkenler, dÃ¶ngÃ¼ler, fonksiyonlar)
- ğŸ†• **Pandas'a yeni baÅŸlÄ±yor** veya hiÃ§ bilmiyor
- ğŸ“Š **Veri analizi/veri bilimi** alanÄ±na ilgi duyuyor
- ğŸ‘¥ **15-20 kiÅŸilik grup** ortamÄ±

## ğŸ“ Ã–ÄŸretim YaklaÅŸÄ±mÄ±

Bu dokÃ¼man **sarmal Ã¶ÄŸrenme metodolojisi** ile tasarlanmÄ±ÅŸtÄ±r:
- ğŸ“ˆ **Kademeli derinleÅŸtirme**: Basit kavramlardan karmaÅŸÄ±k analizlere
- ğŸ”„ **Tekrar ve pekiÅŸtirme**: Ã–nceki konularÄ± yeni Ã¶rneklerle gÃ¼Ã§lendirme
- ğŸ§© **ParÃ§alÄ± Ã¶ÄŸrenme**: Her kavramÄ± adÄ±m adÄ±m Ã¶ÄŸrenme

---

# 1. ğŸš€ Pandas'a GiriÅŸ ve Kurulum

## ğŸ¤” Pandas Nedir?

**Pandas** (Python Data Analysis Library), Python programlama dilinde veri analizi ve manipÃ¼lasyonu iÃ§in geliÅŸtirilmiÅŸ gÃ¼Ã§lÃ¼ bir kÃ¼tÃ¼phanedir. 

### ğŸŒŸ Pandas'Ä±n Temel AvantajlarÄ±:
- ğŸ“Š **Veri yapÄ±larÄ±**: Series ve DataFrame ile esnek veri saklama
- ğŸ”„ **Veri dÃ¶nÃ¼ÅŸtÃ¼rme**: Kolay veri temizleme ve manipÃ¼lasyon
- ğŸ“ **Dosya formatlarÄ±**: CSV, Excel, JSON, SQL gibi Ã§oklu format desteÄŸi
- ğŸ“ˆ **Analiz araÃ§larÄ±**: Ä°statistiksel analiz ve gÃ¶rselleÅŸtirme desteÄŸi
- âš¡ **Performans**: NumPy tabanlÄ± hÄ±zlÄ± iÅŸlemler

## ğŸ’» Kurulum

### Anaconda ile Kurulum (Ã–nerilen)
```bash
# Anaconda ile Pandas otomatik gelir
conda install pandas
```

### pip ile Kurulum
```bash
pip install pandas
```

### Kurulum KontrolÃ¼
```python
import pandas as pd
print(pd.__version__)
# Ã‡Ä±ktÄ±: 2.1.3 (veya gÃ¼ncel versiyon)
```

## ğŸ“š Temel Ä°mport ve KÄ±saltmalar

```python
# Standart import ÅŸekli
import pandas as pd
import numpy as np

# GÃ¶rselleÅŸtirme kÃ¼tÃ¼phaneleri (opsiyonel)
import matplotlib.pyplot as plt
import seaborn as sns

# Pandas ayarlarÄ±
pd.set_option('display.max_columns', None)  # TÃ¼m sÃ¼tunlarÄ± gÃ¶ster
pd.set_option('display.width', None)        # GeniÅŸlik sÄ±nÄ±rÄ± yok
```

## ğŸ”§ Ä°lk Pandas Kodu

```python
# Basit bir veri seti oluÅŸturma
import pandas as pd

# Basit bir sÃ¶zlÃ¼k
veri = {
    'isim': ['Ali', 'AyÅŸe', 'Mehmet', 'Fatma'],
    'yaÅŸ': [25, 30, 35, 28],
    'ÅŸehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa']
}

# DataFrame oluÅŸturma
df = pd.DataFrame(veri)
print(df)
```

**Ã‡Ä±ktÄ±:**
```
     isim  yaÅŸ     ÅŸehir
0     Ali   25  Ä°stanbul
1    AyÅŸe   30    Ankara
2  Mehmet   35     Ä°zmir
3   Fatma   28     Bursa
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ’¡ Ä°pucu**: Pandas'Ä± her zaman `pd` kÄ±saltmasÄ± ile import edin. Bu endÃ¼stri standardÄ±dÄ±r.

> **âš ï¸ UyarÄ±**: BÃ¼yÃ¼k veri setleri ile Ã§alÄ±ÅŸÄ±rken bellek kullanÄ±mÄ±na dikkat edin.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| `ModuleNotFoundError: No module named 'pandas'` | Pandas kurulu deÄŸil | `pip install pandas` komutu ile kurun |
| `AttributeError: module 'pandas' has no attribute 'DataFrame'` | YanlÄ±ÅŸ import | `import pandas as pd` ÅŸeklinde import edin |
| `KeyError: 'column_name'` | Olmayan sÃ¼tuna eriÅŸim | `df.columns` ile sÃ¼tun isimlerini kontrol edin |

## ğŸ¯ Egzersizler

### Egzersiz 1: Kurulum KontrolÃ¼
```python
# 1. Pandas'Ä± import edin ve versiyonunu yazdÄ±rÄ±n
# 2. NumPy'Ä± da import edin
# 3. Basit bir DataFrame oluÅŸturun

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: Ä°lk DataFrame
```python
# AÅŸaÄŸÄ±daki bilgilerle bir DataFrame oluÅŸturun:
# ÃœrÃ¼n isimleri: ['Laptop', 'Mouse', 'Klavye']
# Fiyatlar: [5000, 50, 150]
# Stok: [10, 100, 50]

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---

# 2. ğŸ“Š Temel Veri YapÄ±larÄ±: Series ve DataFrame

Pandas'Ä±n iki temel veri yapÄ±sÄ± vardÄ±r: **Series** (1 boyutlu) ve **DataFrame** (2 boyutlu). Bu yapÄ±larÄ± anlamak, Pandas'ta etkili Ã§alÄ±ÅŸmanÄ±n temelidir.

## ğŸ“ˆ Series - 1 Boyutlu Veri YapÄ±sÄ±

**Series**, etiketli (indexli) bir boyutlu veri yapÄ±sÄ±dÄ±r. Bir Excel sÃ¼tunu veya Python listesi gibi dÃ¼ÅŸÃ¼nebilirsiniz.

### Series OluÅŸturma YÃ¶ntemleri

#### 1ï¸âƒ£ Liste ile Series OluÅŸturma
```python
import pandas as pd

# Basit liste ile Series
sayilar = pd.Series([10, 20, 30, 40, 50])
print(sayilar)
```

**Ã‡Ä±ktÄ±:**
```
0    10
1    20
2    30
3    40
4    50
dtype: int64
```

#### 2ï¸âƒ£ Index ile Series OluÅŸturma
```python
# Ã–zel index ile Series
ÅŸehir_nufus = pd.Series([15000000, 5500000, 4300000], 
                       index=['Ä°stanbul', 'Ankara', 'Ä°zmir'])
print(ÅŸehir_nufus)
```

**Ã‡Ä±ktÄ±:**
```
Ä°stanbul    15000000
Ankara       5500000
Ä°zmir        4300000
dtype: int64
```

#### 3ï¸âƒ£ SÃ¶zlÃ¼k ile Series OluÅŸturma
```python
# SÃ¶zlÃ¼kten Series
notlar = pd.Series({
    'Matematik': 85,
    'Fizik': 90,
    'Kimya': 75,
    'Biyoloji': 88
})
print(notlar)
```

**Ã‡Ä±ktÄ±:**
```
Matematik    85
Fizik        90
Kimya        75
Biyoloji     88
dtype: int64
```

### Series Temel Ä°ÅŸlemleri

```python
# Series Ã¼zerinde temel iÅŸlemler
print(f"Ortalama: {notlar.mean()}")           # Ortalama: 84.5
print(f"Maksimum: {notlar.max()}")            # Maksimum: 90
print(f"Minimum ders: {notlar.idxmin()}")     # Minimum ders: Kimya
print(f"Eleman sayÄ±sÄ±: {notlar.count()}")     # Eleman sayÄ±sÄ±: 4

# Ä°ndexleme ve dilimlemek
print(f"Matematik notu: {notlar['Matematik']}")  # Matematik notu: 85
print(f"Ä°lk iki ders: \n{notlar[:2]}")           # Ä°lk iki dersi gÃ¶ster
```

## ğŸ“‹ DataFrame - 2 Boyutlu Veri YapÄ±sÄ±

**DataFrame**, satÄ±r ve sÃ¼tunlarÄ± olan tablo benzeri veri yapÄ±sÄ±dÄ±r. Excel tablosu veya SQL veritabanÄ± tablosu gibi dÃ¼ÅŸÃ¼nebilirsiniz.

### DataFrame OluÅŸturma YÃ¶ntemleri

#### 1ï¸âƒ£ SÃ¶zlÃ¼k ile DataFrame OluÅŸturma
```python
# SÃ¶zlÃ¼kten DataFrame oluÅŸturma
ogrenci_bilgileri = {
    'isim': ['Ali', 'AyÅŸe', 'Mehmet', 'Fatma', 'Kemal'],
    'yaÅŸ': [22, 23, 21, 24, 22],
    'ÅŸehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya'],
    'not_ortalamasÄ±': [3.2, 3.8, 2.9, 3.5, 3.0]
}

df_ogrenci = pd.DataFrame(ogrenci_bilgileri)
print(df_ogrenci)
```

**Ã‡Ä±ktÄ±:**
```
     isim  yaÅŸ     ÅŸehir  not_ortalamasÄ±
0     Ali   22  Ä°stanbul            3.2
1    AyÅŸe   23    Ankara            3.8
2  Mehmet   21     Ä°zmir            2.9
3   Fatma   24     Bursa            3.5
4   Kemal   22   Antalya            3.0
```

#### 2ï¸âƒ£ Liste listesi ile DataFrame
```python
# Ä°Ã§ iÃ§e liste ile DataFrame
veri = [
    ['Laptop', 'Teknoloji', 5000, 25],
    ['Kitap', 'EÄŸitim', 50, 100],
    ['Mouse', 'Teknoloji', 100, 75],
    ['Kalem', 'EÄŸitim', 5, 200]
]

sutun_isimleri = ['Ã¼rÃ¼n', 'kategori', 'fiyat', 'stok']
df_urun = pd.DataFrame(veri, columns=sutun_isimleri)
print(df_urun)
```

**Ã‡Ä±ktÄ±:**
```
    Ã¼rÃ¼n   kategori  fiyat  stok
0  Laptop  Teknoloji   5000    25
1   Kitap     EÄŸitim     50   100
2   Mouse  Teknoloji    100    75
3   Kalem     EÄŸitim      5   200
```

#### 3ï¸âƒ£ NumPy array ile DataFrame
```python
import numpy as np

# NumPy array ile DataFrame
rastgele_veri = np.random.randint(1, 100, size=(4, 3))
df_rastgele = pd.DataFrame(rastgele_veri, 
                          columns=['A', 'B', 'C'],
                          index=['SatÄ±r1', 'SatÄ±r2', 'SatÄ±r3', 'SatÄ±r4'])
print(df_rastgele)
```

### DataFrame Temel Bilgiler

```python
# DataFrame hakkÄ±nda temel bilgiler
print("DataFrame Åekli:", df_ogrenci.shape)           # (5, 4)
print("SÃ¼tun Ä°simleri:", df_ogrenci.columns.tolist()) # ['isim', 'yaÅŸ', 'ÅŸehir', 'not_ortalamasÄ±']
print("Index:", df_ogrenci.index.tolist())            # [0, 1, 2, 3, 4]
print("Veri Tipleri:\n", df_ogrenci.dtypes)

# Ä°lk ve son satÄ±rlar
print("Ä°lk 3 satÄ±r:\n", df_ogrenci.head(3))
print("Son 2 satÄ±r:\n", df_ogrenci.tail(2))

# Temel istatistikler
print("SayÄ±sal sÃ¼tunlar Ã¶zeti:\n", df_ogrenci.describe())
```

### DataFrame SÃ¼tun Ä°ÅŸlemleri

```python
# SÃ¼tun seÃ§me
print("Sadece isimler:\n", df_ogrenci['isim'])
print("Birden fazla sÃ¼tun:\n", df_ogrenci[['isim', 'not_ortalamasÄ±']])

# Yeni sÃ¼tun ekleme
df_ogrenci['geÃ§me_durumu'] = df_ogrenci['not_ortalamasÄ±'] >= 3.0
df_ogrenci['yaÅŸ_grubu'] = df_ogrenci['yaÅŸ'].apply(lambda x: 'GenÃ§' if x < 23 else 'YaÅŸlÄ±')

print("GÃ¼ncellenmiÅŸ DataFrame:\n", df_ogrenci)
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ’¡ Index Ã–nemli**: Pandas'ta her satÄ±r ve sÃ¼tunun bir index'i vardÄ±r. Bu index'ler veri eriÅŸimi iÃ§in kritiktir.

> **ğŸ” Veri Tipleri**: DataFrame'de her sÃ¼tun farklÄ± veri tipinde olabilir (int, float, string, boolean).

> **âš¡ Bellek**: BÃ¼yÃ¼k DataFrame'ler oluÅŸtururken bellek kullanÄ±mÄ±na dikkat edin.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| `KeyError: 'sÃ¼tun_adÄ±'` | Olmayan sÃ¼tuna eriÅŸim | `df.columns` ile sÃ¼tun isimlerini kontrol edin |
| `ValueError: arrays must all be same length` | FarklÄ± uzunlukta listeler | TÃ¼m listelerin aynÄ± uzunlukta olduÄŸundan emin olun |
| `AttributeError: 'Series' object has no attribute 'shape'` | Series ile DataFrame karÄ±ÅŸÄ±klÄ±ÄŸÄ± | Series iÃ§in `len()`, DataFrame iÃ§in `shape` kullanÄ±n |
| Index karÄ±ÅŸÄ±klÄ±ÄŸÄ± | YanlÄ±ÅŸ index kullanÄ±mÄ± | `reset_index()` ile index'i sÄ±fÄ±rlayÄ±n |

## ğŸ¯ Egzersizler

### Egzersiz 1: Series OluÅŸturma
```python
# 1. TÃ¼rkiye'nin 5 bÃ¼yÃ¼k ÅŸehrinin nÃ¼fusunu iÃ§eren bir Series oluÅŸturun
# 2. Bu Series'in ortalamasÄ±nÄ±, maksimumunu ve minimum deÄŸerini bulun
# 3. En kalabalÄ±k ÅŸehri yazdÄ±rÄ±n

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: DataFrame OluÅŸturma
```python
# AÅŸaÄŸÄ±daki bilgilerle bir "Ã§alÄ±ÅŸan" DataFrame'i oluÅŸturun:
# - Ä°sim: ['Ahmet', 'Zeynep', 'Ozan', 'Elif']
# - Departman: ['IT', 'HR', 'Finans', 'IT']  
# - MaaÅŸ: [7500, 6000, 8000, 7000]
# - TecrÃ¼be (yÄ±l): [3, 5, 7, 2]

# 1. DataFrame'i oluÅŸturun
# 2. Ortalama maaÅŸÄ± hesaplayÄ±n
# 3. IT departmanÄ±nda kaÃ§ kiÅŸi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± bulun
# 4. 5+ yÄ±l tecrÃ¼besi olan Ã§alÄ±ÅŸanlarÄ± listeleyin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 3: Ä°leri Ä°ÅŸlemler
```python
# YukarÄ±daki Ã§alÄ±ÅŸan DataFrame'ini kullanarak:
# 1. "maaÅŸ_seviyesi" sÃ¼tunu ekleyin (7000'den fazla ise "YÃ¼ksek", altÄ±nda ise "DÃ¼ÅŸÃ¼k")
# 2. Departmanlara gÃ¶re ortalama maaÅŸÄ± hesaplayÄ±n
# 3. En deneyimli Ã§alÄ±ÅŸanÄ±n bilgilerini yazdÄ±rÄ±n

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---# 3. ğŸ“ Veri Okuma/Yazma Ä°ÅŸlemleri

GerÃ§ek dÃ¼nyada veriler genellikle dosyalarda saklanÄ±r. Pandas, Ã§eÅŸitli dosya formatlarÄ±ndan veri okuma ve yazma konusunda gÃ¼Ã§lÃ¼ yeteneklere sahiptir.

## ğŸ“„ CSV (Comma Separated Values) Ä°ÅŸlemleri

CSV, veri analizinde en yaygÄ±n kullanÄ±lan dosya formatlarÄ±ndan biridir.

### CSV DosyasÄ± Okuma

#### 1ï¸âƒ£ Basit CSV Okuma
```python
import pandas as pd

# Basit CSV okuma
df = pd.read_csv('dosya_yolu.csv')
print(df.head())
```

#### 2ï¸âƒ£ GeliÅŸmiÅŸ CSV Okuma Parametreleri
```python
# DetaylÄ± parametrelerle CSV okuma
df = pd.read_csv(
    'satislar.csv',
    sep=',',                    # AyÄ±rÄ±cÄ± karakter
    encoding='utf-8',           # Karakter kodlamasÄ±
    index_col=0,               # Ä°lk sÃ¼tunu index olarak kullan
    header=0,                  # Hangi satÄ±rÄ± sÃ¼tun ismi olarak kullan
    skiprows=1,                # Ä°lk 1 satÄ±rÄ± atla
    nrows=1000,               # Sadece ilk 1000 satÄ±rÄ± oku
    usecols=['tarih', 'fiyat', 'miktar'],  # Sadece belirtilen sÃ¼tunlarÄ± oku
    dtype={'miktar': int},     # Belirli sÃ¼tunlar iÃ§in veri tipi
    na_values=['N/A', 'null', '']  # BoÅŸ deÄŸer olarak kabul edilecekler
)
print(df.info())
```

#### 3ï¸âƒ£ Ã–rnek CSV Verisi OluÅŸturup Okuma
```python
import pandas as pd
import numpy as np

# Ã–rnek veri oluÅŸturma
np.random.seed(42)
ornek_veri = {
    'tarih': pd.date_range('2024-01-01', periods=100),
    'Ã¼rÃ¼n': np.random.choice(['Laptop', 'Mouse', 'Klavye'], 100),
    'satÄ±ÅŸ_miktarÄ±': np.random.randint(1, 20, 100),
    'birim_fiyat': np.random.randint(50, 5000, 100),
    'satÄ±ÅŸ_temsilcisi': np.random.choice(['Ali', 'AyÅŸe', 'Mehmet'], 100)
}

df_satÄ±ÅŸ = pd.DataFrame(ornek_veri)

# CSV olarak kaydet
df_satÄ±ÅŸ.to_csv('satÄ±ÅŸlar.csv', index=False, encoding='utf-8')
print("CSV dosyasÄ± oluÅŸturuldu!")

# Kaydedilen dosyayÄ± oku
df_okunan = pd.read_csv('satÄ±ÅŸlar.csv')
print("Okunan veri:")
print(df_okunan.head())
print(f"Shape: {df_okunan.shape}")
```

### CSV DosyasÄ± Yazma

```python
# DataFrame'i CSV olarak kaydetme
df_satÄ±ÅŸ.to_csv(
    'Ã§Ä±ktÄ±_dosyasÄ±.csv',
    index=False,               # Index'i yazma
    sep=',',                   # AyÄ±rÄ±cÄ±
    encoding='utf-8',          # Karakter kodlamasÄ±
    float_format='%.2f',       # Float sayÄ±lar iÃ§in format
    date_format='%Y-%m-%d'     # Tarih formatÄ±
)

# Sadece belirli sÃ¼tunlarÄ± kaydetme
df_satÄ±ÅŸ[['Ã¼rÃ¼n', 'satÄ±ÅŸ_miktarÄ±']].to_csv('Ã¶zet_satÄ±ÅŸ.csv', index=False)
```

## ğŸ“Š Excel Ä°ÅŸlemleri

Excel dosyalarÄ± iÅŸ dÃ¼nyasÄ±nda Ã§ok yaygÄ±ndÄ±r. Pandas bu formatla da etkili Ã§alÄ±ÅŸabilir.

### Excel DosyasÄ± Okuma

#### 1ï¸âƒ£ Basit Excel Okuma
```python
# Excel dosyasÄ± okuma
df = pd.read_excel('dosya.xlsx')
print(df.head())
```

#### 2ï¸âƒ£ Ã‡oklu Sayfa ile Excel Okuma
```python
# Belirli bir sayfayÄ± okuma
df_sayfa1 = pd.read_excel('Ã§oklu_sayfa.xlsx', sheet_name='Sayfa1')

# TÃ¼m sayfalarÄ± okuma
tÃ¼m_sayfalar = pd.read_excel('Ã§oklu_sayfa.xlsx', sheet_name=None)
print("Sayfa isimleri:", tÃ¼m_sayfalar.keys())

# Birden fazla sayfayÄ± seÃ§me
seÃ§ili_sayfalar = pd.read_excel('Ã§oklu_sayfa.xlsx', sheet_name=['Sayfa1', 'Sayfa2'])
```

#### 3ï¸âƒ£ GeliÅŸmiÅŸ Excel Okuma
```python
# DetaylÄ± parametrelerle Excel okuma
df = pd.read_excel(
    'raporlar.xlsx',
    sheet_name='SatÄ±ÅŸlar',     # Sayfa adÄ±
    header=1,                  # 2. satÄ±rÄ± baÅŸlÄ±k olarak kullan
    skiprows=2,               # Ä°lk 2 satÄ±rÄ± atla
    usecols='A:D',            # A'dan D'ye kadar sÃ¼tunlarÄ± oku
    nrows=50,                 # Ä°lk 50 satÄ±rÄ± oku
    dtype={'ID': str},        # ID sÃ¼tununu string olarak oku
    converters={'Tarih': pd.to_datetime}  # Tarih dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼sÃ¼
)
```

### Excel DosyasÄ± Yazma

```python
# DataFrame'i Excel olarak kaydetme
df_satÄ±ÅŸ.to_excel('satÄ±ÅŸ_raporu.xlsx', index=False, sheet_name='SatÄ±ÅŸlar')

# Ã‡oklu sayfa ile Excel oluÅŸturma
with pd.ExcelWriter('detaylÄ±_rapor.xlsx') as writer:
    df_satÄ±ÅŸ.to_excel(writer, sheet_name='Ham_Veri', index=False)
    df_Ã¶zet = df_satÄ±ÅŸ.groupby('Ã¼rÃ¼n')['satÄ±ÅŸ_miktarÄ±'].sum()
    df_Ã¶zet.to_excel(writer, sheet_name='Ã–zet')
    
print("Ã‡oklu sayfalÄ± Excel dosyasÄ± oluÅŸturuldu!")
```

## ğŸ”§ Encoding SorunlarÄ± ve Ã‡Ã¶zÃ¼mleri

TÃ¼rkÃ§e karakterler ile Ã§alÄ±ÅŸÄ±rken encoding sorunlarÄ± yaÅŸayabilirsiniz.

### YaygÄ±n Encoding Problemleri

```python
# Problem: TÃ¼rkÃ§e karakterler yanlÄ±ÅŸ gÃ¶rÃ¼nÃ¼yor
# Ã‡Ã¶zÃ¼m 1: FarklÄ± encoding'ler deneyin
encodings = ['utf-8', 'latin-1', 'cp1254', 'iso-8859-9']

for enc in encodings:
    try:
        df = pd.read_csv('tÃ¼rkÃ§e_veri.csv', encoding=enc)
        print(f"{enc} ile baÅŸarÄ±lÄ±!")
        print(df.head())
        break
    except UnicodeDecodeError:
        print(f"{enc} Ã§alÄ±ÅŸmadÄ±, sonrakini deniyorum...")
```

### GÃ¼venli Okuma Fonksiyonu

```python
def gÃ¼venli_oku(dosya_yolu, **kwargs):
    """
    FarklÄ± encoding'leri deneyerek gÃ¼venli dosya okuma
    """
    encodings = ['utf-8', 'latin-1', 'cp1254', 'iso-8859-9']
    
    for encoding in encodings:
        try:
            df = pd.read_csv(dosya_yolu, encoding=encoding, **kwargs)
            print(f"âœ… {encoding} ile baÅŸarÄ±yla okundu")
            return df
        except UnicodeDecodeError:
            print(f"âŒ {encoding} Ã§alÄ±ÅŸmadÄ±")
            continue
    
    raise ValueError("HiÃ§bir encoding Ã§alÄ±ÅŸmadÄ±!")

# KullanÄ±m
df = gÃ¼venli_oku('problemli_dosya.csv')
```

## ğŸ“‹ DiÄŸer Dosya FormatlarÄ±

### JSON Ä°ÅŸlemleri
```python
# JSON okuma ve yazma
df.to_json('veri.json', orient='records', lines=True, force_ascii=False)
df_json = pd.read_json('veri.json', lines=True)
```

### Parquet Ä°ÅŸlemleri (BÃ¼yÃ¼k veriler iÃ§in)
```python
# Parquet formatÄ± - bÃ¼yÃ¼k veriler iÃ§in ideal
df.to_parquet('veri.parquet', index=False)
df_parquet = pd.read_parquet('veri.parquet')
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ”¤ Encoding**: TÃ¼rkÃ§e karakterler iÃ§in `utf-8` encoding kullanÄ±n.

> **ğŸ“Š BÃ¼yÃ¼k Dosyalar**: BÃ¼yÃ¼k dosyalar iÃ§in `chunksize` parametresini kullanÄ±n.

> **ğŸ’¾ Bellek**: Excel dosyalarÄ± CSV'lerden daha fazla bellek kullanÄ±r.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| `UnicodeDecodeError` | YanlÄ±ÅŸ encoding | FarklÄ± encoding'leri deneyin (`utf-8`, `latin-1`) |
| `FileNotFoundError` | Dosya bulunamadÄ± | Dosya yolunu kontrol edin |
| `ParserError` | CSV format hatasÄ± | `error_bad_lines=False` parametresi ekleyin |
| `xlrd` hatasÄ± | Excel kÃ¼tÃ¼phanesi eksik | `pip install openpyxl` komutu Ã§alÄ±ÅŸtÄ±rÄ±n |
| `MemoryError` | Dosya Ã§ok bÃ¼yÃ¼k | `chunksize` parametresi kullanÄ±n |

### BÃ¼yÃ¼k Dosyalar iÃ§in Chunk Ä°ÅŸleme

```python
# BÃ¼yÃ¼k dosyalarÄ± parÃ§a parÃ§a okuma
def bÃ¼yÃ¼k_dosya_iÅŸle(dosya_yolu, chunk_boyutu=10000):
    """
    BÃ¼yÃ¼k CSV dosyasÄ±nÄ± parÃ§a parÃ§a iÅŸleme
    """
    sonuÃ§lar = []
    
    for chunk in pd.read_csv(dosya_yolu, chunksize=chunk_boyutu):
        # Her parÃ§a Ã¼zerinde iÅŸlem yapÄ±n
        iÅŸlenmiÅŸ_chunk = chunk.groupby('kategori')['fiyat'].mean()
        sonuÃ§lar.append(iÅŸlenmiÅŸ_chunk)
    
    # TÃ¼m parÃ§alarÄ± birleÅŸtir
    final_sonuÃ§ = pd.concat(sonuÃ§lar).groupby(level=0).mean()
    return final_sonuÃ§

# KullanÄ±m
sonuÃ§ = bÃ¼yÃ¼k_dosya_iÅŸle('Ã§ok_bÃ¼yÃ¼k_dosya.csv')
```

## ğŸ¯ Egzersizler

### Egzersiz 1: CSV Ä°ÅŸlemleri
```python
# 1. AÅŸaÄŸÄ±daki veriyi CSV olarak kaydedin:
mÃ¼ÅŸteriler = {
    'ad': ['Ahmet YÄ±lmaz', 'Zeynep Kaya', 'Ozan Demir'],
    'ÅŸehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir'],
    'yaÅŸ': [28, 35, 31],
    'gelir': [45000, 52000, 48000]
}

# 2. Kaydedilen dosyayÄ± tekrar okuyun
# 3. Sadece 'ad' ve 'gelir' sÃ¼tunlarÄ±nÄ± iÃ§eren yeni bir CSV oluÅŸturun

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: Excel Ä°ÅŸlemleri
```python
# 1. YukarÄ±daki mÃ¼ÅŸteri verisini Excel olarak kaydedin
# 2. Ä°ki farklÄ± sayfa oluÅŸturun: 'MÃ¼ÅŸteriLista' ve 'Ã–zet'
# 3. Ã–zet sayfasÄ±nda ÅŸehirlere gÃ¶re ortalama geliri gÃ¶sterin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 3: Hata YÃ¶netimi
```python
# 1. Var olmayan bir dosyayÄ± okumaya Ã§alÄ±ÅŸÄ±n ve hatayÄ± yakalayÄ±n
# 2. Try-except bloÄŸu kullanarak gÃ¼venli dosya okuma fonksiyonu yazÄ±n
# 3. Fonksiyonunuzu test edin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---# 4. ğŸ› ï¸ Veri ManipÃ¼lasyonu ve Temizleme

GerÃ§ek dÃ¼nyadan gelen veriler nadiren temiz ve analiz iÃ§in hazÄ±r olur. Bu bÃ¶lÃ¼mde verileri temizleme ve manipÃ¼le etme tekniklerini Ã¶ÄŸreneceÄŸiz.

## ğŸ•³ï¸ Eksik Veri (Missing Data) YÃ¶netimi

Eksik veriler, veri analizinde en yaygÄ±n karÅŸÄ±laÅŸÄ±lan problemlerden biridir.

### Eksik Veri Tespiti

```python
import pandas as pd
import numpy as np

# Eksik veriler iÃ§eren Ã¶rnek dataset
veri_ham = {
    'ad': ['Ali', 'AyÅŸe', 'Mehmet', None, 'Fatma', 'Kemal'],
    'yaÅŸ': [25, 30, None, 22, 28, None],
    'maaÅŸ': [5000, np.nan, 7000, 4500, None, 6200],
    'ÅŸehir': ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', None, 'Antalya'],
    'deneyim': [2, 5, None, 1, 3, 8]
}

df = pd.DataFrame(veri_ham)
print("Ham veri:")
print(df)

# Eksik veri kontrolÃ¼
print("\nEksik veri sayÄ±sÄ± (sÃ¼tun bazÄ±nda):")
print(df.isnull().sum())

print("\nEksik veri oranlarÄ±:")
print((df.isnull().sum() / len(df)) * 100)

# Eksik veri olan satÄ±rlarÄ± gÃ¶ster
print("\nEksik veri iÃ§eren satÄ±rlar:")
print(df[df.isnull().any(axis=1)])
```

### Eksik Veri ile Ã‡alÄ±ÅŸma YÃ¶ntemleri

#### 1ï¸âƒ£ Eksik Veriyi Silme
```python
# Eksik veri iÃ§eren satÄ±rlarÄ± silme
df_temiz_satÄ±r = df.dropna()
print("Eksik satÄ±rlar silindikten sonra:")
print(df_temiz_satÄ±r)

# Eksik veri iÃ§eren sÃ¼tunlarÄ± silme
df_temiz_sÃ¼tun = df.dropna(axis=1)
print("Eksik sÃ¼tunlar silindikten sonra:")
print(df_temiz_sÃ¼tun)

# Belirli sÃ¼tunlarda eksik veri varsa satÄ±rÄ± sil
df_seÃ§ici_sil = df.dropna(subset=['ad', 'yaÅŸ'])
print("Ad veya yaÅŸ eksik olan satÄ±rlar silindi:")
print(df_seÃ§ici_sil)
```

#### 2ï¸âƒ£ Eksik Veriyi Doldurma
```python
# Sabit deÄŸer ile doldurma
df_dolu = df.fillna(0)
print("0 ile doldurulmuÅŸ:")
print(df_dolu)

# FarklÄ± sÃ¼tunlar iÃ§in farklÄ± deÄŸerler
df_akÄ±llÄ±_dolu = df.fillna({
    'ad': 'Bilinmeyen',
    'yaÅŸ': df['yaÅŸ'].mean(),  # Ortalama ile doldur
    'maaÅŸ': df['maaÅŸ'].median(),  # Medyan ile doldur
    'ÅŸehir': 'BelirtilmemiÅŸ',
    'deneyim': 0
})
print("AkÄ±llÄ± doldurma:")
print(df_akÄ±llÄ±_dolu)

# Forward fill (Ã¶nceki deÄŸeri kopyala)
df_ffill = df.fillna(method='ffill')
print("Forward fill:")
print(df_ffill)

# Backward fill (sonraki deÄŸeri kopyala)
df_bfill = df.fillna(method='bfill')
print("Backward fill:")
print(df_bfill)
```

#### 3ï¸âƒ£ Ä°leri Seviye Eksik Veri Ä°ÅŸleme
```python
# Ä°nterpolasyon ile doldurma
df_interpolated = df.copy()
df_interpolated['yaÅŸ'] = df_interpolated['yaÅŸ'].interpolate()
df_interpolated['deneyim'] = df_interpolated['deneyim'].interpolate()
print("Ä°nterpolasyon ile doldurulmuÅŸ:")
print(df_interpolated[['yaÅŸ', 'deneyim']])

# Gruplara gÃ¶re ortalama ile doldurma
# Ã–rnek: Åehirlere gÃ¶re ortalama maaÅŸ ile doldurma
df_grup_dolu = df.copy()
df_grup_dolu['maaÅŸ'] = df_grup_dolu.groupby('ÅŸehir')['maaÅŸ'].transform(
    lambda x: x.fillna(x.mean())
)
```

## ğŸ”„ Veri Tipleri DÃ¶nÃ¼ÅŸÃ¼mÃ¼

DoÄŸru veri tipleri, analiz performansÄ± ve doÄŸruluÄŸu iÃ§in kritiktir.

### Veri Tipi KontrolÃ¼ ve DÃ¶nÃ¼ÅŸtÃ¼rme

```python
# Mevcut veri tiplerini kontrol et
print("Mevcut veri tipleri:")
print(df.dtypes)
print("\nDetaylÄ± bilgi:")
print(df.info())

# Veri tipi dÃ¶nÃ¼ÅŸtÃ¼rme Ã¶rnekleri
df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ = df.copy()

# String'i sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rme (hatalÄ± veriler varsa)
df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ['yaÅŸ'] = pd.to_numeric(df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ['yaÅŸ'], errors='coerce')

# Object'i category'e dÃ¶nÃ¼ÅŸtÃ¼rme (bellek tasarrufu)
df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ['ÅŸehir'] = df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ['ÅŸehir'].astype('category')

# String'i datetime'a dÃ¶nÃ¼ÅŸtÃ¼rme
tarih_verisi = pd.Series(['2024-01-01', '2024-02-15', '2024-03-20'])
df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ['baÅŸlangÄ±Ã§_tarihi'] = pd.to_datetime(tarih_verisi)

print("DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veri tipleri:")
print(df_dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ.dtypes)
```

### GeliÅŸmiÅŸ Veri Tipi Ä°ÅŸlemleri

```python
# SayÄ±sal veriyi kategorik veye dÃ¶nÃ¼ÅŸtÃ¼rme
df['yaÅŸ_grubu'] = pd.cut(df['yaÅŸ'], 
                        bins=[0, 25, 35, float('inf')], 
                        labels=['GenÃ§', 'Orta YaÅŸ', 'YaÅŸlÄ±'])

# Boolean sÃ¼tun oluÅŸturma
df['yÃ¼ksek_maaÅŸ'] = df['maaÅŸ'] > df['maaÅŸ'].median()

print("Yeni sÃ¼tunlar eklenmiÅŸ DataFrame:")
print(df[['ad', 'yaÅŸ', 'yaÅŸ_grubu', 'maaÅŸ', 'yÃ¼ksek_maaÅŸ']])
```

## ğŸ”„ Duplikasyon YÃ¶netimi

Tekrarlanan veriler analizleri bozabilir.

### Duplikasyon Tespiti ve Temizleme

```python
# Duplikasyon iÃ§eren Ã¶rnek veri
duplikasyon_verisi = pd.DataFrame({
    'id': [1, 2, 3, 2, 4, 3, 5],
    'ad': ['Ali', 'AyÅŸe', 'Mehmet', 'AyÅŸe', 'Fatma', 'Mehmet', 'Kemal'],
    'departman': ['IT', 'HR', 'Finance', 'HR', 'IT', 'Finance', 'Marketing'],
    'maaÅŸ': [5000, 6000, 7000, 6000, 5500, 7000, 4800]
})

print("Duplikasyon iÃ§eren veri:")
print(duplikasyon_verisi)

# Duplikasyon kontrolÃ¼
print(f"\nTam duplikasyon sayÄ±sÄ±: {duplikasyon_verisi.duplicated().sum()}")
print("Duplikasyon olan satÄ±rlar:")
print(duplikasyon_verisi[duplikasyon_verisi.duplicated()])

# Belirli sÃ¼tunlara gÃ¶re duplikasyon kontrolÃ¼
print(f"\nAd bazÄ±nda duplikasyon: {duplikasyon_verisi.duplicated(subset=['ad']).sum()}")

# DuplikasyonlarÄ± temizleme
df_benzersiz = duplikasyon_verisi.drop_duplicates()
print("\nDuplikasyonlar silindikten sonra:")
print(df_benzersiz)

# Ä°lk deÄŸeri koru, diÄŸerlerini sil
df_ilk_koru = duplikasyon_verisi.drop_duplicates(subset=['ad'], keep='first')
print("\nAd bazÄ±nda ilk deÄŸerleri koruyarak:")
print(df_ilk_koru)

# Son deÄŸeri koru
df_son_koru = duplikasyon_verisi.drop_duplicates(subset=['ad'], keep='last')
print("\nAd bazÄ±nda son deÄŸerleri koruyarak:")
print(df_son_koru)
```

## ğŸ“Š SÃ¼tun Ä°ÅŸlemleri

### SÃ¼tun Ekleme, Silme ve DÃ¼zenleme

```python
# Yeni sÃ¼tun ekleme yÃ¶ntemleri
df_iÅŸlem = df.copy()

# Basit sÃ¼tun ekleme
df_iÅŸlem['yeni_sÃ¼tun'] = 'varsayÄ±lan_deÄŸer'

# Hesaplanan sÃ¼tun ekleme
df_iÅŸlem['maaÅŸ_deneyim_oranÄ±'] = df_iÅŸlem['maaÅŸ'] / (df_iÅŸlem['deneyim'] + 1)

# Apply fonksiyonu ile sÃ¼tun ekleme
df_iÅŸlem['maaÅŸ_kategorisi'] = df_iÅŸlem['maaÅŸ'].apply(
    lambda x: 'YÃ¼ksek' if x > 6000 else 'Orta' if x > 4000 else 'DÃ¼ÅŸÃ¼k'
)

# SÃ¼tun silme
df_iÅŸlem = df_iÅŸlem.drop(['yeni_sÃ¼tun'], axis=1)

# SÃ¼tun adÄ± deÄŸiÅŸtirme
df_iÅŸlem = df_iÅŸlem.rename(columns={
    'ad': 'Ã§alÄ±ÅŸan_adÄ±',
    'maaÅŸ': 'aylÄ±k_gelir'
})

print("Ä°ÅŸlenmiÅŸ DataFrame:")
print(df_iÅŸlem.head())
```

### String Ä°ÅŸlemleri

```python
# String sÃ¼tunlarÄ± ile Ã§alÄ±ÅŸma
Ã¶rnek_metinler = pd.DataFrame({
    'isim': ['  Ali YÄ±lmaz  ', 'AYÅE KAYA', 'mehmet demir', 'Fatma Ã–ZTÃœRK'],
    'email': ['ali@email.com', 'ayse@FIRMA.COM', 'mehmet123@gmail.com', 'fatma.ozturk@work.net'],
    'telefon': ['0555-123-45-67', '(0212) 345 67 89', '05551234567', '+90 533 123 45 67']
})

print("Ham string verisi:")
print(Ã¶rnek_metinler)

# String temizleme iÅŸlemleri
temiz_metinler = Ã¶rnek_metinler.copy()

# BoÅŸluklarÄ± temizleme
temiz_metinler['isim'] = temiz_metinler['isim'].str.strip()

# BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf dÃ¶nÃ¼ÅŸÃ¼mleri
temiz_metinler['isim_title'] = temiz_metinler['isim'].str.title()
temiz_metinler['email_lower'] = temiz_metinler['email'].str.lower()

# String deÄŸiÅŸtirme
temiz_metinler['telefon_temiz'] = temiz_metinler['telefon'].str.replace(r'[^\d]', '', regex=True)

# String bÃ¶lme
temiz_metinler[['ad', 'soyad']] = temiz_metinler['isim'].str.split(n=1, expand=True)

print("TemizlenmiÅŸ string verisi:")
print(temiz_metinler)
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ¯ Stratejik Karar**: Eksik veriyi silmek mi yoksa doldurmak mÄ±? Veri setinizin boyutuna ve eksik veri oranÄ±na gÃ¶re karar verin.

> **ğŸ“Š Veri Tipi Optimizasyonu**: Kategorik veriler iÃ§in 'category' tipini kullanÄ±n, bellek tasarrufu saÄŸlar.

> **ğŸ” Duplikasyon KontrolÃ¼**: Her veri temizleme iÅŸleminden sonra duplikasyon kontrolÃ¼ yapÄ±n.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| `TypeError: can't multiply sequence` | String'i sayÄ± ile Ã§arpmaya Ã§alÄ±ÅŸma | Veri tipini kontrol edin: `pd.to_numeric()` |
| `ValueError: cannot convert string to float` | String'i float'a dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ± | `errors='coerce'` parametresi kullanÄ±n |
| Eksik deÄŸerlerin gÃ¶zden kaÃ§masÄ± | NaN deÄŸerlerinin fark edilmemesi | `df.isnull().sum()` ile dÃ¼zenli kontrol |
| Duplikasyon kontrolsÃ¼zlÃ¼ÄŸÃ¼ | DuplikalarÄ± fark etmeme | Her veri iÅŸleminden sonra `duplicated()` kontrolÃ¼ |
| YanlÄ±ÅŸ veri tipi | Object tipinde sayÄ±sal veri | `dtypes` kontrolÃ¼ yapÄ±n ve gerekirse dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n |

### Pratik Temizleme Fonksiyonu

```python
def veri_temizle(df, eksik_strateji='drop', duplikasyon_temizle=True):
    """
    KapsamlÄ± veri temizleme fonksiyonu
    """
    print(f"ğŸ“Š BaÅŸlangÄ±Ã§ boyutu: {df.shape}")
    
    # 1. DuplikasyonlarÄ± temizle
    if duplikasyon_temizle:
        baÅŸlangÄ±Ã§_boyut = len(df)
        df = df.drop_duplicates()
        print(f"ğŸ”„ Duplikasyon temizleme: {baÅŸlangÄ±Ã§_boyut - len(df)} satÄ±r silindi")
    
    # 2. Eksik verileri iÅŸle
    if eksik_strateji == 'drop':
        baÅŸlangÄ±Ã§_boyut = len(df)
        df = df.dropna()
        print(f"ğŸ•³ï¸ Eksik veri temizleme: {baÅŸlangÄ±Ã§_boyut - len(df)} satÄ±r silindi")
    elif eksik_strateji == 'fill':
        for col in df.columns:
            if df[col].dtype in ['int64', 'float64']:
                df[col].fillna(df[col].median(), inplace=True)
            else:
                df[col].fillna(df[col].mode().iloc[0] if not df[col].mode().empty else 'Unknown', inplace=True)
        print("ğŸ”§ Eksik veriler dolduruldu")
    
    # 3. String sÃ¼tunlarÄ± temizle
    string_columns = df.select_dtypes(include=['object']).columns
    for col in string_columns:
        if df[col].dtype == 'object':
            try:
                df[col] = df[col].str.strip()  # BoÅŸluklarÄ± temizle
            except:
                pass
    
    print(f"âœ… Final boyut: {df.shape}")
    print(f"ğŸ“ˆ Temizlik oranÄ±: %{(1 - len(df)/len(df)) * 100:.1f}")
    
    return df

# KullanÄ±m Ã¶rneÄŸi
# temiz_df = veri_temizle(ham_df, eksik_strateji='fill')
```

## ğŸ¯ Egzersizler

### Egzersiz 1: Eksik Veri YÃ¶netimi
```python
# AÅŸaÄŸÄ±daki problematik veriyi temizleyin:
problematik_veri = pd.DataFrame({
    'id': [1, 2, 3, 4, 5, 6],
    'isim': ['Ali', None, 'Mehmet', 'AyÅŸe', '', 'Fatma'],
    'yaÅŸ': [25, 30, None, 35, 40, 45],
    'maaÅŸ': [5000, None, 7000, 6000, None, 8000],
    'departman': ['IT', 'HR', None, 'Finance', 'IT', 'HR']
})

# 1. Eksik verileri tespit edin
# 2. Ä°sim sÃ¼tunundaki boÅŸ string'i NaN'a Ã§evirin
# 3. SayÄ±sal sÃ¼tunlarÄ± ortalama ile, kategorik sÃ¼tunlarÄ± mod ile doldurun
# 4. SonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rÄ±n

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: Duplikasyon Temizleme
```python
# Duplikasyon iÃ§eren mÃ¼ÅŸteri verisini temizleyin:
mÃ¼ÅŸteri_verisi = pd.DataFrame({
    'mÃ¼ÅŸteri_id': [101, 102, 103, 102, 104, 103, 105],
    'ad': ['Ali YÄ±lmaz', 'AyÅŸe Kaya', 'Mehmet Ã–z', 'AyÅŸe Kaya', 'Fatma Er', 'Mehmet Ã–z', 'Kemal As'],
    'email': ['ali@email.com', 'ayse@email.com', 'mehmet@email.com', 'ayse@email.com', 'fatma@email.com', 'mehmet@email.com', 'kemal@email.com'],
    'telefon': ['5551234567', '5559876543', '5555555555', '5559876543', '5553333333', '5555555555', '5551111111']
})

# 1. Tam duplikasyonlarÄ± bulun
# 2. Email bazÄ±nda duplikasyonlarÄ± bulun  
# 3. Her email iÃ§in en son kaydÄ± tutun
# 4. SonuÃ§ tablosunu gÃ¶sterin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 3: Veri Tipi DÃ¶nÃ¼ÅŸÃ¼mÃ¼
```python
# Ham veriyi dÃ¼zgÃ¼n tiplere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n:
ham_veri = pd.DataFrame({
    'tarih': ['2024-01-01', '2024-02-15', '2024-03-20'],
    'fiyat': ['100.50', '200,75', '150.25'],  # VirgÃ¼llÃ¼ decimal
    'miktar': ['10', '20', '15'],
    'aktif': ['Evet', 'HayÄ±r', 'Evet'],
    'kategori': ['A', 'B', 'A']
})

# 1. Tarih sÃ¼tununu datetime'a Ã§evirin
# 2. Fiyat sÃ¼tunundaki virgÃ¼lÃ¼ nokta yapÄ±n ve float'a Ã§evirin
# 3. Miktar'Ä± integer'a Ã§evirin
# 4. Aktif'i boolean'a Ã§evirin (Evet=True, HayÄ±r=False)
# 5. Kategori'yi category tipine Ã§evirin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---# 5. ğŸ” Veri Filtreleme ve SeÃ§me

BÃ¼yÃ¼k veri setlerinden istediÄŸiniz kÄ±smÄ± seÃ§mek, veri analizinin temel taÅŸÄ±dÄ±r. Pandas'ta bu iÅŸlemler iÃ§in gÃ¼Ã§lÃ¼ araÃ§lar mevcuttur.

## ğŸ¯ Temel Ä°ndexleme ve SeÃ§im

### Ã–rnek Veri Seti

```python
import pandas as pd
import numpy as np

# KapsamlÄ± Ã¶rnek veri seti
np.random.seed(42)
Ã§alÄ±ÅŸan_verisi = pd.DataFrame({
    'ad': ['Ali YÄ±lmaz', 'AyÅŸe Kaya', 'Mehmet Ã–z', 'Fatma Er', 'Kemal As', 
           'Zeynep Ak', 'Ozan Demir', 'Elif Åen', 'Murat Can', 'Selin Kor'],
    'yaÅŸ': [28, 32, 45, 29, 38, 26, 41, 35, 31, 27],
    'departman': ['IT', 'HR', 'Finance', 'IT', 'Marketing', 'HR', 'Finance', 'IT', 'Marketing', 'HR'],
    'maaÅŸ': [7500, 6500, 9500, 7000, 8200, 6000, 9800, 7800, 8500, 6200],
    'deneyim_yÄ±l': [3, 7, 15, 2, 10, 1, 18, 8, 6, 2],
    'performans_puanÄ±': [85, 92, 78, 88, 95, 82, 89, 91, 87, 84],
    'uzaktan_Ã§alÄ±ÅŸma': [True, False, True, True, False, True, False, True, False, True]
})

print("Ã‡alÄ±ÅŸan veri seti:")
print(Ã§alÄ±ÅŸan_verisi)
print(f"\nVeri boyutu: {Ã§alÄ±ÅŸan_verisi.shape}")
```

### SÃ¼tun SeÃ§me Ä°ÅŸlemleri

```python
# Tek sÃ¼tun seÃ§me
print("Sadece isimler:")
print(Ã§alÄ±ÅŸan_verisi['ad'])

# Birden fazla sÃ¼tun seÃ§me
print("\nÄ°sim, departman ve maaÅŸ:")
print(Ã§alÄ±ÅŸan_verisi[['ad', 'departman', 'maaÅŸ']])

# SÃ¼tun sÄ±rasÄ±nÄ± deÄŸiÅŸtirerek seÃ§me
print("\nÃ–zel sÄ±ralama:")
seÃ§ilen_sÃ¼tunlar = ['maaÅŸ', 'ad', 'departman']
print(Ã§alÄ±ÅŸan_verisi[seÃ§ilen_sÃ¼tunlar])

# Belirli koÅŸula gÃ¶re sÃ¼tunlarÄ± seÃ§me
sayÄ±sal_sÃ¼tunlar = Ã§alÄ±ÅŸan_verisi.select_dtypes(include=[np.number]).columns
print(f"\nSayÄ±sal sÃ¼tunlar: {sayÄ±sal_sÃ¼tunlar.tolist()}")
print(Ã§alÄ±ÅŸan_verisi[sayÄ±sal_sÃ¼tunlar])
```

### SatÄ±r SeÃ§me Ä°ÅŸlemleri

```python
# Index ile seÃ§me
print("Ä°lk Ã¼Ã§ Ã§alÄ±ÅŸan:")
print(Ã§alÄ±ÅŸan_verisi[:3])

print("\nSon iki Ã§alÄ±ÅŸan:")
print(Ã§alÄ±ÅŸan_verisi[-2:])

print("\n2. ve 4. Ã§alÄ±ÅŸanlar:")
print(Ã§alÄ±ÅŸan_verisi.iloc[[1, 3]])

# Belirli satÄ±r aralÄ±ÄŸÄ±
print("\n3. ile 6. Ã§alÄ±ÅŸanlar arasÄ±:")
print(Ã§alÄ±ÅŸan_verisi[2:6])
```

## ğŸ” Boolean Ä°ndexleme

Boolean indexleme, koÅŸullu filtreleme iÃ§in en gÃ¼Ã§lÃ¼ araÃ§tÄ±r.

### Basit Boolean Filtreleme

```python
# Tek koÅŸul
print("MaaÅŸÄ± 8000'den fazla olanlar:")
yÃ¼ksek_maaÅŸ = Ã§alÄ±ÅŸan_verisi['maaÅŸ'] > 8000
print(Ã§alÄ±ÅŸan_verisi[yÃ¼ksek_maaÅŸ])

# ÅÄ±kÃ§a kullanÄ±lan tek satÄ±rda yazÄ±m
print("\nIT departmanÄ± Ã§alÄ±ÅŸanlarÄ±:")
print(Ã§alÄ±ÅŸan_verisi[Ã§alÄ±ÅŸan_verisi['departman'] == 'IT'])

# String kontrolleri
print("\nAdÄ±nda 'A' harfi geÃ§enler:")
print(Ã§alÄ±ÅŸan_verisi[Ã§alÄ±ÅŸan_verisi['ad'].str.contains('A')])
```

### Ã‡oklu KoÅŸul Filtreleme

```python
# AND koÅŸulu (&)
print("IT'de Ã§alÄ±ÅŸan VE maaÅŸÄ± 7500'den fazla olanlar:")
it_yÃ¼ksek_maaÅŸ = (Ã§alÄ±ÅŸan_verisi['departman'] == 'IT') & (Ã§alÄ±ÅŸan_verisi['maaÅŸ'] > 7500)
print(Ã§alÄ±ÅŸan_verisi[it_yÃ¼ksek_maaÅŸ])

# OR koÅŸulu (|)
print("\nHR'da Ã§alÄ±ÅŸan VEYA uzaktan Ã§alÄ±ÅŸanlar:")
hr_veya_uzak = (Ã§alÄ±ÅŸan_verisi['departman'] == 'HR') | (Ã§alÄ±ÅŸan_verisi['uzaktan_Ã§alÄ±ÅŸma'] == True)
print(Ã§alÄ±ÅŸan_verisi[hr_veya_uzak])

# NOT koÅŸulu (~)
print("\nIT departmanÄ±nda olmayanlar:")
it_olmayanlar = ~(Ã§alÄ±ÅŸan_verisi['departman'] == 'IT')
print(Ã§alÄ±ÅŸan_verisi[it_olmayanlar])

# KarmaÅŸÄ±k koÅŸul Ã¶rneÄŸi
print("\nYaÅŸÄ± 30-40 arasÄ±, performans puanÄ± 85'den yÃ¼ksek, IT veya Finance'ta Ã§alÄ±ÅŸanlar:")
karmaÅŸÄ±k_filtre = (
    (Ã§alÄ±ÅŸan_verisi['yaÅŸ'] >= 30) & 
    (Ã§alÄ±ÅŸan_verisi['yaÅŸ'] <= 40) &
    (Ã§alÄ±ÅŸan_verisi['performans_puanÄ±'] > 85) &
    (Ã§alÄ±ÅŸan_verisi['departman'].isin(['IT', 'Finance']))
)
print(Ã§alÄ±ÅŸan_verisi[karmaÅŸÄ±k_filtre])
```

### GeliÅŸmiÅŸ Boolean Ä°ÅŸlemleri

```python
# isin() ile Ã§oklu deÄŸer kontrolÃ¼
print("HR, IT veya Finance departmanlarÄ±nda Ã§alÄ±ÅŸanlar:")
seÃ§ili_departmanlar = ['HR', 'IT', 'Finance']
print(Ã§alÄ±ÅŸan_verisi[Ã§alÄ±ÅŸan_verisi['departman'].isin(seÃ§ili_departmanlar)])

# between() ile aralÄ±k kontrolÃ¼
print("\nMaaÅŸÄ± 7000-8500 arasÄ±nda olanlar:")
print(Ã§alÄ±ÅŸan_verisi[Ã§alÄ±ÅŸan_verisi['maaÅŸ'].between(7000, 8500)])

# String iÅŸlemleri ile filtreleme
print("\nAdÄ± 'A' ile baÅŸlayanlar:")
print(Ã§alÄ±ÅŸan_verisi[Ã§alÄ±ÅŸan_verisi['ad'].str.startswith('A')])

print("\nSoyadÄ±nda 'er' geÃ§enler:")
print(Ã§alÄ±ÅŸan_verisi[Ã§alÄ±ÅŸan_verisi['ad'].str.contains('er', case=False)])
```

## ğŸ“ loc ve iloc KullanÄ±mÄ±

`loc` ve `iloc` daha hassas veri seÃ§imi iÃ§in kullanÄ±lÄ±r.

### iloc - Pozisyon BazlÄ± SeÃ§im

```python
# iloc[satÄ±r, sÃ¼tun] formatÄ±nda Ã§alÄ±ÅŸÄ±r
print("2. satÄ±r, 3. sÃ¼tun:")
print(Ã§alÄ±ÅŸan_verisi.iloc[1, 2])

print("\nÄ°lk 3 satÄ±r, ilk 4 sÃ¼tun:")
print(Ã§alÄ±ÅŸan_verisi.iloc[:3, :4])

print("\nSon 2 satÄ±r, son 3 sÃ¼tun:")
print(Ã§alÄ±ÅŸan_verisi.iloc[-2:, -3:])

# Belirli satÄ±r ve sÃ¼tunlarÄ± seÃ§me
print("\n1., 3., 5. satÄ±rlar ve 0., 2., 4. sÃ¼tunlar:")
print(Ã§alÄ±ÅŸan_verisi.iloc[[0, 2, 4], [0, 2, 4]])

# TÃ¼m satÄ±rlar, belirli sÃ¼tunlar
print("\nTÃ¼m satÄ±rlar, 2. ve 4. sÃ¼tunlar:")
print(Ã§alÄ±ÅŸan_verisi.iloc[:, [1, 3]])
```

### loc - Etiket BazlÄ± SeÃ§im

```python
# SÃ¼tun adlarÄ± ile seÃ§im
print("Belirli satÄ±rlar ve sÃ¼tunlar:")
print(Ã§alÄ±ÅŸan_verisi.loc[:3, ['ad', 'departman', 'maaÅŸ']])

# Boolean indexleme ile loc kullanÄ±mÄ±
print("\nIT Ã§alÄ±ÅŸanlarÄ±nÄ±n ad ve maaÅŸ bilgileri:")
it_Ã§alÄ±ÅŸanlarÄ± = Ã§alÄ±ÅŸan_verisi['departman'] == 'IT'
print(Ã§alÄ±ÅŸan_verisi.loc[it_Ã§alÄ±ÅŸanlarÄ±, ['ad', 'maaÅŸ']])

# Index'i sÃ¼tun olarak ayarlayarak loc kullanÄ±mÄ±
df_isim_index = Ã§alÄ±ÅŸan_verisi.set_index('ad')
print("\nAli YÄ±lmaz'Ä±n bilgileri:")
print(df_isim_index.loc['Ali YÄ±lmaz'])

# Ã‡oklu index seÃ§imi
print("\nBelirli kiÅŸilerin maaÅŸ bilgileri:")
seÃ§ili_kiÅŸiler = ['Ali YÄ±lmaz', 'AyÅŸe Kaya', 'Mehmet Ã–z']
print(df_isim_index.loc[seÃ§ili_kiÅŸiler, 'maaÅŸ'])
```

## ğŸ” query() Fonksiyonu

`query()` fonksiyonu, SQL benzeri bir sÃ¶z dizimi ile filtreleme yapar.

### Basit Query Ã–rnekleri

```python
# Basit koÅŸullar
print("MaaÅŸÄ± 7500'den bÃ¼yÃ¼k olanlar (query ile):")
print(Ã§alÄ±ÅŸan_verisi.query('maaÅŸ > 7500'))

print("\nIT departmanÄ± Ã§alÄ±ÅŸanlarÄ± (query ile):")
print(Ã§alÄ±ÅŸan_verisi.query('departman == "IT"'))

# Ã‡oklu koÅŸullar
print("\nYaÅŸÄ± 30'dan bÃ¼yÃ¼k VE performans puanÄ± 85'den yÃ¼ksek olanlar:")
print(Ã§alÄ±ÅŸan_verisi.query('yaÅŸ > 30 and performans_puanÄ± > 85'))

print("\nHR Ã§alÄ±ÅŸanlarÄ± VEYA uzaktan Ã§alÄ±ÅŸanlar:")
print(Ã§alÄ±ÅŸan_verisi.query('departman == "HR" or uzaktan_Ã§alÄ±ÅŸma == True'))
```

### GeliÅŸmiÅŸ Query KullanÄ±mÄ±

```python
# DeÄŸiÅŸken kullanÄ±mÄ±
min_maaÅŸ = 7000
max_yaÅŸ = 35

print(f"MaaÅŸÄ± {min_maaÅŸ}'den fazla ve yaÅŸÄ± {max_yaÅŸ}'den kÃ¼Ã§Ã¼k olanlar:")
print(Ã§alÄ±ÅŸan_verisi.query('maaÅŸ > @min_maaÅŸ and yaÅŸ < @max_yaÅŸ'))

# Liste ile kontrol
hedef_departmanlar = ['IT', 'Finance']
print("IT veya Finance departmanlarÄ±nda Ã§alÄ±ÅŸanlar:")
print(Ã§alÄ±ÅŸan_verisi.query('departman in @hedef_departmanlar'))

# String iÅŸlemleri
print("AdÄ±nda 'e' harfi geÃ§enler:")
print(Ã§alÄ±ÅŸan_verisi.query('ad.str.contains("e", case=False)'))

# AralÄ±k kontrolÃ¼
print("Deneyimi 5-15 yÄ±l arasÄ± olanlar:")
print(Ã§alÄ±ÅŸan_verisi.query('5 <= deneyim_yÄ±l <= 15'))
```

## ğŸ“Š Ã–rnekleme (Sampling)

BÃ¼yÃ¼k veri setlerinden rastgele Ã¶rnekler almak iÃ§in.

```python
# Rastgele Ã¶rnekleme
print("Rastgele 3 Ã§alÄ±ÅŸan:")
print(Ã§alÄ±ÅŸan_verisi.sample(n=3, random_state=42))

# YÃ¼zdelik Ã¶rnekleme
print("\nVerinin %30'u:")
print(Ã§alÄ±ÅŸan_verisi.sample(frac=0.3, random_state=42))

# Stratified sampling (gruplar arasÄ± dengeli Ã¶rnekleme)
print("\nHer departmandan 2'ÅŸer kiÅŸi:")
dengeli_Ã¶rnek = Ã§alÄ±ÅŸan_verisi.groupby('departman').apply(
    lambda x: x.sample(min(len(x), 2), random_state=42)
).reset_index(drop=True)
print(dengeli_Ã¶rnek)
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ”— Parantez KullanÄ±mÄ±**: Ã‡oklu Boolean koÅŸullarda mutlaka parantez kullanÄ±n: `(kondisyon1) & (kondisyon2)`

> **ğŸ” loc vs iloc**: `loc` etiket bazlÄ±, `iloc` pozisyon bazlÄ±dÄ±r. KarÄ±ÅŸtÄ±rmayÄ±n!

> **âš¡ Performans**: BÃ¼yÃ¼k veriler iÃ§in `query()` daha hÄ±zlÄ± olabilir.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| `ValueError: The truth value is ambiguous` | Boolean koÅŸullarda parantez eksikliÄŸi | `(df['A'] > 5) & (df['B'] < 10)` ÅŸeklinde yazÄ±n |
| `KeyError: 'sÃ¼tun_adÄ±'` | Olmayan sÃ¼tuna eriÅŸim | `df.columns` ile sÃ¼tun listesini kontrol edin |
| `TypeError: cannot use & with these operands` | and/or kullanÄ±mÄ± yerine &/\| kullanÄ±mÄ± | Boolean iÅŸlemlerde `&`, `|`, `~` kullanÄ±n |
| `IndexError: single positional indexer is out-of-bounds` | iloc ile yanlÄ±ÅŸ index | Index sÄ±nÄ±rlarÄ±nÄ± kontrol edin |
| `SettingWithCopyWarning` | Kopyalama uyarÄ±sÄ± | `.copy()` ile aÃ§Ä±k kopya oluÅŸturun |

### GÃ¼venli Filtreleme Fonksiyonu

```python
def gÃ¼venli_filtrele(df, koÅŸul_dict):
    """
    GÃ¼venli filtreleme fonksiyonu
    
    Parametreler:
    df: DataFrame
    koÅŸul_dict: {'sÃ¼tun': {'operator': 'deÄŸer'}} formatÄ±nda koÅŸullar
    
    Ã–rnek: gÃ¼venli_filtrele(df, {'yaÅŸ': {'>=': 25}, 'departman': {'==': 'IT'}})
    """
    filtreli_df = df.copy()
    
    for sÃ¼tun, koÅŸullar in koÅŸul_dict.items():
        if sÃ¼tun not in df.columns:
            print(f"âš ï¸ UyarÄ±: '{sÃ¼tun}' sÃ¼tunu bulunamadÄ±!")
            continue
            
        for operator, deÄŸer in koÅŸullar.items():
            try:
                if operator == '==':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun] == deÄŸer]
                elif operator == '!=':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun] != deÄŸer]
                elif operator == '>':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun] > deÄŸer]
                elif operator == '>=':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun] >= deÄŸer]
                elif operator == '<':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun] < deÄŸer]
                elif operator == '<=':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun] <= deÄŸer]
                elif operator == 'in':
                    filtreli_df = filtreli_df[filtreli_df[sÃ¼tun].isin(deÄŸer)]
                    
            except Exception as e:
                print(f"âŒ Hata: {sÃ¼tun} sÃ¼tununda {operator} {deÄŸer} koÅŸulu uygulanamadÄ±: {e}")
                
    print(f"ğŸ“Š Filtreleme tamamlandÄ±: {len(df)} â†’ {len(filtreli_df)} satÄ±r")
    return filtreli_df

# KullanÄ±m Ã¶rneÄŸi
sonuÃ§ = gÃ¼venli_filtrele(Ã§alÄ±ÅŸan_verisi, {
    'yaÅŸ': {'>=': 30},
    'departman': {'in': ['IT', 'Finance']},
    'maaÅŸ': {'>': 7000}
})
```

## ğŸ¯ Egzersizler

### Egzersiz 1: Basit Filtreleme
```python
# YukarÄ±daki Ã§alÄ±ÅŸan_verisi DataFrame'ini kullanarak:
# 1. YaÅŸÄ± 30'dan bÃ¼yÃ¼k Ã§alÄ±ÅŸanlarÄ± bulun
# 2. Marketing departmanÄ±nda Ã§alÄ±ÅŸanlarÄ± listeleyin
# 3. Performans puanÄ± 90'dan yÃ¼ksek olanlarÄ± gÃ¶sterin
# 4. Uzaktan Ã§alÄ±ÅŸmayanlarÄ± filtreleyin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: KarmaÅŸÄ±k Filtreleme
```python
# AÅŸaÄŸÄ±daki koÅŸullarÄ± saÄŸlayan Ã§alÄ±ÅŸanlarÄ± bulun:
# 1. YaÅŸÄ± 25-40 arasÄ±nda VE
# 2. MaaÅŸÄ± departman ortalamasÄ±ndan yÃ¼ksek VE
# 3. Deneyimi 5+ yÄ±l VEYA performans puanÄ± 90+

# Ä°pucu: Departman ortalamasÄ± iÃ§in groupby().transform() kullanabilirsiniz

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 3: loc/iloc PratiÄŸi
```python
# 1. iloc kullanarak ilk 5 satÄ±r, son 3 sÃ¼tunu seÃ§in
# 2. loc kullanarak IT departmanÄ± Ã§alÄ±ÅŸanlarÄ±nÄ±n ad ve maaÅŸ bilgilerini alÄ±n
# 3. Query kullanarak deneyimi 5+ yÄ±l olanlarÄ± filtrelein
# 4. Her departmandan rastgele 1 Ã§alÄ±ÅŸan seÃ§in

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 4: Filtreleme KombinasyonlarÄ±
```python
# AÅŸaÄŸÄ±daki gereksinimleri karÅŸÄ±layan bir filtreleme sistemi oluÅŸturun:
# 1. KullanÄ±cÄ± departman seÃ§ebilsin
# 2. Minimum ve maksimum maaÅŸ belirleyebilsin
# 3. Uzaktan Ã§alÄ±ÅŸma durumunu filtreleybilsin
# 4. SonuÃ§larÄ± performans puanÄ±na gÃ¶re sÄ±ralayabilsin

# Fonksiyon imzasÄ±:
def Ã§alÄ±ÅŸan_filtrele(df, departmanlar=None, min_maaÅŸ=0, max_maaÅŸ=float('inf'), 
                    uzaktan_Ã§alÄ±ÅŸma=None, sÄ±ralama='performans_puanÄ±'):
    """
    Ã‡ok kriterli Ã§alÄ±ÅŸan filtreleme fonksiyonu
    """
    # Kodunuzu buraya yazÄ±n
    pass

# Test edin:
# sonuÃ§ = Ã§alÄ±ÅŸan_filtrele(Ã§alÄ±ÅŸan_verisi, departmanlar=['IT', 'HR'], min_maaÅŸ=7000, uzaktan_Ã§alÄ±ÅŸma=True)

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---# 6. ğŸ“ˆ Temel Ä°statistiksel Analizler

Ä°statistiksel analiz, veriyi anlamak ve iÃ§gÃ¶rÃ¼ elde etmek iÃ§in hayati Ã¶nem taÅŸÄ±r. Pandas, temel istatistiksel hesaplamalar iÃ§in zengin araÃ§lar sunar.

## ğŸ“Š Ã–rnek Veri Seti

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# SatÄ±ÅŸ veri seti oluÅŸturalÄ±m
np.random.seed(42)
n = 1000

satÄ±ÅŸ_verisi = pd.DataFrame({
    'tarih': pd.date_range('2024-01-01', periods=n, freq='D'),
    'Ã¼rÃ¼n_kategorisi': np.random.choice(['Elektronik', 'Giyim', 'Kitap', 'Ev EÅŸyasÄ±', 'Spor'], n),
    'satÄ±ÅŸ_miktarÄ±': np.random.poisson(lam=10, size=n),
    'birim_fiyat': np.random.gamma(shape=2, scale=50, size=n),
    'mÃ¼ÅŸteri_yaÅŸÄ±': np.random.normal(loc=35, scale=12, size=n),
    'satÄ±ÅŸ_temsilcisi': np.random.choice(['Ali', 'AyÅŸe', 'Mehmet', 'Fatma', 'Kemal'], n),
    'bÃ¶lge': np.random.choice(['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Antalya'], n),
    'sezon': np.random.choice(['Ä°lkbahar', 'Yaz', 'Sonbahar', 'KÄ±ÅŸ'], n)
})

# TÃ¼retilmiÅŸ sÃ¼tunlar
satÄ±ÅŸ_verisi['toplam_gelir'] = satÄ±ÅŸ_verisi['satÄ±ÅŸ_miktarÄ±'] * satÄ±ÅŸ_verisi['birim_fiyat']
satÄ±ÅŸ_verisi['ay'] = satÄ±ÅŸ_verisi['tarih'].dt.month
satÄ±ÅŸ_verisi['haftanÄ±n_gÃ¼nÃ¼'] = satÄ±ÅŸ_verisi['tarih'].dt.day_name()

print("SatÄ±ÅŸ veri seti:")
print(satÄ±ÅŸ_verisi.head())
print(f"Veri boyutu: {satÄ±ÅŸ_verisi.shape}")
```

## ğŸ” describe() - Temel Ä°statistiklerin Ã–zeti

`describe()` fonksiyonu, sayÄ±sal veriler iÃ§in temel istatistikleri Ã¶zetler.

### SayÄ±sal Veriler iÃ§in describe()

```python
# TÃ¼m sayÄ±sal sÃ¼tunlar iÃ§in Ã¶zet istatistikler
print("SayÄ±sal sÃ¼tunlar iÃ§in Ã¶zet istatistikler:")
print(satÄ±ÅŸ_verisi.describe())

# Belirli sÃ¼tunlar iÃ§in
print("\nSadece gelir ve mÃ¼ÅŸteri yaÅŸÄ± iÃ§in:")
print(satÄ±ÅŸ_verisi[['toplam_gelir', 'mÃ¼ÅŸteri_yaÅŸÄ±']].describe())

# YÃ¼zdelik dilimler Ã¶zelleÅŸtirme
print("\nDetaylÄ± yÃ¼zdelik dilimler:")
print(satÄ±ÅŸ_verisi['toplam_gelir'].describe(percentiles=[.1, .25, .5, .75, .9, .95]))
```

### Kategorik Veriler iÃ§in describe()

```python
# Kategorik veriler iÃ§in Ã¶zet
print("Kategorik sÃ¼tunlar iÃ§in Ã¶zet:")
print(satÄ±ÅŸ_verisi.describe(include='object'))

# Belirli bir kategorik sÃ¼tun iÃ§in detay
print("\nÃœrÃ¼n kategorisi detaylarÄ±:")
print(satÄ±ÅŸ_verisi['Ã¼rÃ¼n_kategorisi'].describe())
```

### Manuel Ä°statistik HesaplarÄ±

```python
# Temel istatistikleri manuel olarak hesaplama
toplam_gelir = satÄ±ÅŸ_verisi['toplam_gelir']

print("Manuel istatistikler:")
print(f"Ortalama: {toplam_gelir.mean():.2f}")
print(f"Medyan: {toplam_gelir.median():.2f}")
print(f"Standart sapma: {toplam_gelir.std():.2f}")
print(f"Varyans: {toplam_gelir.var():.2f}")
print(f"Minimum: {toplam_gelir.min():.2f}")
print(f"Maksimum: {toplam_gelir.max():.2f}")
print(f"Ã‡eyreklik aÃ§Ä±klÄ±ÄŸÄ± (IQR): {toplam_gelir.quantile(0.75) - toplam_gelir.quantile(0.25):.2f}")
print(f"Ã‡arpÄ±klÄ±k: {toplam_gelir.skew():.2f}")
print(f"BasÄ±klÄ±k: {toplam_gelir.kurtosis():.2f}")
```

## ğŸ“Š value_counts() - Frekans Analizi

`value_counts()` kategorik verilerin daÄŸÄ±lÄ±mÄ±nÄ± analiz eder.

### Basit Frekans Analizi

```python
# ÃœrÃ¼n kategorilerinin daÄŸÄ±lÄ±mÄ±
print("ÃœrÃ¼n kategori daÄŸÄ±lÄ±mÄ±:")
kategori_daÄŸÄ±lÄ±m = satÄ±ÅŸ_verisi['Ã¼rÃ¼n_kategorisi'].value_counts()
print(kategori_daÄŸÄ±lÄ±m)

# YÃ¼zdelik daÄŸÄ±lÄ±m
print("\nYÃ¼zdelik daÄŸÄ±lÄ±m:")
print(satÄ±ÅŸ_verisi['Ã¼rÃ¼n_kategorisi'].value_counts(normalize=True) * 100)

# BÃ¶lge daÄŸÄ±lÄ±mÄ±
print("\nBÃ¶lge daÄŸÄ±lÄ±mÄ±:")
print(satÄ±ÅŸ_verisi['bÃ¶lge'].value_counts().sort_values(ascending=False))
```

### GeliÅŸmiÅŸ Frekans Analizi

```python
# Birden fazla sÃ¼tun iÃ§in cross-tabulation
print("BÃ¶lge ve Ã¼rÃ¼n kategorisi cross-tabulation:")
Ã§apraz_tablo = pd.crosstab(satÄ±ÅŸ_verisi['bÃ¶lge'], satÄ±ÅŸ_verisi['Ã¼rÃ¼n_kategorisi'])
print(Ã§apraz_tablo)

# YÃ¼zdelik cross-tabulation
print("\nYÃ¼zdelik daÄŸÄ±lÄ±m (satÄ±r bazlÄ±):")
yÃ¼zdelik_tablo = pd.crosstab(satÄ±ÅŸ_verisi['bÃ¶lge'], satÄ±ÅŸ_verisi['Ã¼rÃ¼n_kategorisi'], 
                           normalize='index') * 100
print(yÃ¼zdelik_tablo.round(2))

# SayÄ±sal veriyi kategorik hale getirip frekans analizi
satÄ±ÅŸ_verisi['gelir_kategori'] = pd.cut(satÄ±ÅŸ_verisi['toplam_gelir'], 
                                       bins=5, 
                                       labels=['Ã‡ok DÃ¼ÅŸÃ¼k', 'DÃ¼ÅŸÃ¼k', 'Orta', 'YÃ¼ksek', 'Ã‡ok YÃ¼ksek'])
print("\nGelir kategori daÄŸÄ±lÄ±mÄ±:")
print(satÄ±ÅŸ_verisi['gelir_kategori'].value_counts().sort_index())
```

## ğŸ”— Korelasyon Analizi

Korelasyon, deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi Ã¶lÃ§er.

### Temel Korelasyon

```python
# SayÄ±sal sÃ¼tunlar iÃ§in korelasyon matrisi
sayÄ±sal_sÃ¼tunlar = ['satÄ±ÅŸ_miktarÄ±', 'birim_fiyat', 'mÃ¼ÅŸteri_yaÅŸÄ±', 'toplam_gelir', 'ay']
korelasyon_matrisi = satÄ±ÅŸ_verisi[sayÄ±sal_sÃ¼tunlar].corr()

print("Korelasyon matrisi:")
print(korelasyon_matrisi.round(3))

# Belirli bir sÃ¼tunla diÄŸerleri arasÄ±ndaki korelasyon
print("\nToplam gelir ile diÄŸer deÄŸiÅŸkenler arasÄ± korelasyon:")
gelir_korelasyon = satÄ±ÅŸ_verisi[sayÄ±sal_sÃ¼tunlar].corr()['toplam_gelir'].sort_values(ascending=False)
print(gelir_korelasyon)

# En yÃ¼ksek korelasyonlarÄ± bulma
def gÃ¼Ã§lÃ¼_korelasyonlarÄ±_bul(df, eÅŸik=0.5):
    """EÅŸikten yÃ¼ksek korelasyonlarÄ± bulan fonksiyon"""
    corr_matrix = df.corr()
    gÃ¼Ã§lÃ¼_korelasyonlar = []
    
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if abs(corr_matrix.iloc[i, j]) > eÅŸik:
                gÃ¼Ã§lÃ¼_korelasyonlar.append({
                    'deÄŸiÅŸken1': corr_matrix.columns[i],
                    'deÄŸiÅŸken2': corr_matrix.columns[j],
                    'korelasyon': corr_matrix.iloc[i, j]
                })
    
    return pd.DataFrame(gÃ¼Ã§lÃ¼_korelasyonlar).sort_values('korelasyon', key=abs, ascending=False)

gÃ¼Ã§lÃ¼_kor = gÃ¼Ã§lÃ¼_korelasyonlarÄ±_bul(satÄ±ÅŸ_verisi[sayÄ±sal_sÃ¼tunlar], eÅŸik=0.3)
print("\nGÃ¼Ã§lÃ¼ korelasyonlar (>0.3):")
print(gÃ¼Ã§lÃ¼_kor)
```

### Korelasyon GÃ¶rselleÅŸtirme

```python
# Korelasyon Ä±sÄ± haritasÄ± oluÅŸturma
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 8))
sns.heatmap(korelasyon_matrisi, annot=True, cmap='coolwarm', center=0, 
            square=True, linewidths=0.5, fmt='.3f')
plt.title('Korelasyon IsÄ± HaritasÄ±')
plt.tight_layout()
plt.savefig('/workspace/korelasyon_haritasi.png', dpi=150, bbox_inches='tight')
print("Korelasyon Ä±sÄ± haritasÄ± kaydedildi: /workspace/korelasyon_haritasi.png")
```

## ğŸ¢ GruplandÄ±rma Ä°statistikleri

Kategorik deÄŸiÅŸkenlere gÃ¶re grup istatistikleri.

### Basit GruplandÄ±rma

```python
# ÃœrÃ¼n kategorisine gÃ¶re ortalama satÄ±ÅŸ
print("Kategori bazÄ±nda ortalama satÄ±ÅŸ miktarÄ±:")
kategori_ortalamasÄ± = satÄ±ÅŸ_verisi.groupby('Ã¼rÃ¼n_kategorisi')['satÄ±ÅŸ_miktarÄ±'].mean()
print(kategori_ortalamasÄ±.sort_values(ascending=False))

# BÃ¶lgelere gÃ¶re toplam gelir
print("\nBÃ¶lge bazÄ±nda toplam gelir:")
bÃ¶lge_gelir = satÄ±ÅŸ_verisi.groupby('bÃ¶lge')['toplam_gelir'].sum()
print(bÃ¶lge_gelir.sort_values(ascending=False))

# SatÄ±ÅŸ temsilcisine gÃ¶re performans
print("\nSatÄ±ÅŸ temsilcisi performansÄ±:")
temsilci_performans = satÄ±ÅŸ_verisi.groupby('satÄ±ÅŸ_temsilcisi').agg({
    'toplam_gelir': ['sum', 'mean', 'count'],
    'satÄ±ÅŸ_miktarÄ±': 'mean'
}).round(2)
print(temsilci_performans)
```

### Ã‡ok Seviyeli GruplandÄ±rma

```python
# BÃ¶lge ve kategoriye gÃ¶re analiz
print("BÃ¶lge-Kategori bazÄ±nda analiz:")
Ã§ok_grup = satÄ±ÅŸ_verisi.groupby(['bÃ¶lge', 'Ã¼rÃ¼n_kategorisi']).agg({
    'toplam_gelir': ['count', 'mean', 'sum'],
    'satÄ±ÅŸ_miktarÄ±': 'mean'
}).round(2)

print(Ã§ok_grup)

# En iyi performans gÃ¶steren kombinasyonlar
en_iyi_kombinasyonlar = Ã§ok_grup['toplam_gelir']['sum'].sort_values(ascending=False).head(10)
print("\nEn yÃ¼ksek gelir getiren bÃ¶lge-kategori kombinasyonlarÄ±:")
print(en_iyi_kombinasyonlar)
```

## ğŸ“‹ Pivot Tablolar

Pivot tablolar, verileri Ã¶zetlemek iÃ§in gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r.

### Basit Pivot Tablo

```python
# BÃ¶lge ve kategori pivot tablosu
pivot_gelir = satÄ±ÅŸ_verisi.pivot_table(
    values='toplam_gelir',
    index='bÃ¶lge',
    columns='Ã¼rÃ¼n_kategorisi',
    aggfunc='sum',
    fill_value=0
)

print("Gelir Pivot Tablosu:")
print(pivot_gelir.round(2))

# SatÄ±ÅŸ miktarÄ± pivot tablosu
pivot_miktar = satÄ±ÅŸ_verisi.pivot_table(
    values='satÄ±ÅŸ_miktarÄ±',
    index='bÃ¶lge',
    columns='Ã¼rÃ¼n_kategorisi',
    aggfunc='mean',
    fill_value=0
)

print("\nOrtalama SatÄ±ÅŸ MiktarÄ± Pivot Tablosu:")
print(pivot_miktar.round(2))
```

### GeliÅŸmiÅŸ Pivot Analizi

```python
# Ã‡ok fonksiyonlu pivot tablo
Ã§oklu_pivot = satÄ±ÅŸ_verisi.pivot_table(
    values=['toplam_gelir', 'satÄ±ÅŸ_miktarÄ±'],
    index=['bÃ¶lge', 'sezon'],
    columns='Ã¼rÃ¼n_kategorisi',
    aggfunc={'toplam_gelir': 'sum', 'satÄ±ÅŸ_miktarÄ±': 'mean'},
    fill_value=0,
    margins=True  # Toplam satÄ±rÄ± ve sÃ¼tunu ekler
)

print("Ã‡oklu Pivot Tablosu (ilk 10 satÄ±r):")
print(Ã§oklu_pivot.head(10))

# Zaman serisi pivot analizi
satÄ±ÅŸ_verisi['ay_adÄ±'] = satÄ±ÅŸ_verisi['tarih'].dt.strftime('%B')
aylÄ±k_trend = satÄ±ÅŸ_verisi.pivot_table(
    values='toplam_gelir',
    index='ay_adÄ±',
    columns='Ã¼rÃ¼n_kategorisi',
    aggfunc='sum'
)

print("\nAylÄ±k gelir trendi:")
print(aylÄ±k_trend.fillna(0).round(2))
```

## ğŸ¯ Ä°statistiksel Testler ve Analizler

### Outlier (AykÄ±rÄ± DeÄŸer) Tespiti

```python
def aykÄ±rÄ±_deÄŸerleri_bul(series, method='IQR'):
    """
    AykÄ±rÄ± deÄŸerleri tespit eden fonksiyon
    """
    if method == 'IQR':
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        alt_sÄ±nÄ±r = Q1 - 1.5 * IQR
        Ã¼st_sÄ±nÄ±r = Q3 + 1.5 * IQR
        
        aykÄ±rÄ±_deÄŸerler = series[(series < alt_sÄ±nÄ±r) | (series > Ã¼st_sÄ±nÄ±r)]
        
    elif method == 'z-score':
        z_scores = np.abs((series - series.mean()) / series.std())
        aykÄ±rÄ±_deÄŸerler = series[z_scores > 3]
    
    return aykÄ±rÄ±_deÄŸerler

# Toplam gelirde aykÄ±rÄ± deÄŸerler
aykÄ±rÄ±_gelir = aykÄ±rÄ±_deÄŸerleri_bul(satÄ±ÅŸ_verisi['toplam_gelir'], method='IQR')
print(f"Toplam gelirde {len(aykÄ±rÄ±_gelir)} aykÄ±rÄ± deÄŸer tespit edildi")
print(f"AykÄ±rÄ± deÄŸer oranÄ±: %{len(aykÄ±rÄ±_gelir)/len(satÄ±ÅŸ_verisi)*100:.2f}")

print("\nAykÄ±rÄ± deÄŸerlerin Ã¶zeti:")
print(aykÄ±rÄ±_gelir.describe())
```

### DaÄŸÄ±lÄ±m Analizi

```python
# DaÄŸÄ±lÄ±m istatistikleri
print("Toplam gelir daÄŸÄ±lÄ±m analizi:")
gelir = satÄ±ÅŸ_verisi['toplam_gelir']

print(f"Ortalama: {gelir.mean():.2f}")
print(f"Medyan: {gelir.median():.2f}")
print(f"Mod: {gelir.mode().iloc[0]:.2f}")
print(f"Standart sapma: {gelir.std():.2f}")
print(f"Ã‡arpÄ±klÄ±k: {gelir.skew():.2f}")
print(f"BasÄ±klÄ±k: {gelir.kurtosis():.2f}")

# Ã‡arpÄ±klÄ±k yorumu
if gelir.skew() > 0.5:
    print("â†’ DaÄŸÄ±lÄ±m saÄŸa Ã§arpÄ±k (pozitif Ã§arpÄ±klÄ±k)")
elif gelir.skew() < -0.5:
    print("â†’ DaÄŸÄ±lÄ±m sola Ã§arpÄ±k (negatif Ã§arpÄ±klÄ±k)")
else:
    print("â†’ DaÄŸÄ±lÄ±m yaklaÅŸÄ±k simetrik")
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ“Š Medyan vs Ortalama**: AykÄ±rÄ± deÄŸerler varsa medyan daha gÃ¼venilir bir merkezi eÄŸilim Ã¶lÃ§Ã¼sÃ¼dÃ¼r.

> **ğŸ”— Korelasyon â‰  Nedensellik**: YÃ¼ksek korelasyon, nedensellik anlamÄ±na gelmez.

> **ğŸ“ˆ Normallik**: Ã‡oÄŸu istatistiksel test, verilerin normal daÄŸÄ±ldÄ±ÄŸÄ±nÄ± varsayar.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| AykÄ±rÄ± deÄŸerleri gÃ¶rmezden gelme | Analizleri Ã§arpÄ±tabilir | AykÄ±rÄ± deÄŸer analizi yapÄ±n |
| YanlÄ±ÅŸ agregasyon fonksiyonu | sum yerine mean kullanmak | Analiz amacÄ±na uygun fonksiyon seÃ§in |
| Eksik deÄŸerlerle istatistik | NaN deÄŸerler hesaplamalarÄ± bozar | `dropna()` veya `fillna()` kullanÄ±n |
| Kategorik veriye sayÄ±sal analiz | AnlamsÄ±z sonuÃ§lar | Veri tiplerini kontrol edin |
| KÃ¼Ã§Ã¼k Ã¶rneklem hatasÄ± | Ä°statistikler gÃ¼venilir olmayabilir | Yeterli veri olduÄŸundan emin olun |

## ğŸ¯ Egzersizler

### Egzersiz 1: Temel Ä°statistikler
```python
# YukarÄ±daki satÄ±ÅŸ_verisi DataFrame'ini kullanarak:
# 1. Her Ã¼rÃ¼n kategorisi iÃ§in ortalama birim fiyat hesaplayÄ±n
# 2. En yÃ¼ksek ve en dÃ¼ÅŸÃ¼k toplam gelirli gÃ¼nleri bulun
# 3. MÃ¼ÅŸteri yaÅŸlarÄ±nÄ±n daÄŸÄ±lÄ±m istatistiklerini hesaplayÄ±n
# 4. Hangi ay en Ã§ok satÄ±ÅŸ yapÄ±ldÄ±ÄŸÄ±nÄ± bulun

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: Korelasyon Analizi
```python
# 1. SatÄ±ÅŸ miktarÄ± ile mÃ¼ÅŸteri yaÅŸÄ± arasÄ±ndaki korelasyonu hesaplayÄ±n
# 2. 0.3'ten yÃ¼ksek korelasyonlarÄ± listeleyin
# 3. En gÃ¼Ã§lÃ¼ pozitif ve negatif korelasyonlarÄ± bulun
# 4. Korelasyon matrisini gÃ¶rselleÅŸtirin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 3: Pivot Analizi
```python
# 1. SatÄ±ÅŸ temsilcisi ve bÃ¶lgelere gÃ¶re toplam gelir pivot tablosu oluÅŸturun
# 2. Sezonlara gÃ¶re ortalama satÄ±ÅŸ miktarÄ±nÄ± analiz edin
# 3. Her bÃ¶lgenin en Ã§ok gelir getiren kategorisini bulun
# 4. HaftanÄ±n gÃ¼nlerine gÃ¶re satÄ±ÅŸ trendini analiz edin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 4: KapsamlÄ± Analiz
```python
# AÅŸaÄŸÄ±daki sorularÄ± yanÄ±tlayacak kapsamlÄ± bir analiz yapÄ±n:
# 1. Hangi faktÃ¶rler toplam geliri en Ã§ok etkiliyor?
# 2. En karlÄ± bÃ¶lge-kategori kombinasyonu hangisi?
# 3. Sezonsal trendler var mÄ±?
# 4. SatÄ±ÅŸ temsilcilerinin performanslarÄ± nasÄ±l?
# 5. AykÄ±rÄ± deÄŸerler analizi nasÄ±l Ã¼rÃ¼nleri etkiliyor?

# Fonksiyon yazarak analizinizi organize edin:
def kapsamlÄ±_satÄ±ÅŸ_analizi(df):
    """
    KapsamlÄ± satÄ±ÅŸ verisi analizi
    """
    print("ğŸ“Š KAPSAMLI SATIÅ ANALÄ°ZÄ° RAPORU")
    print("="*50)
    
    # Analizlerinizi buraya yazÄ±n
    
    return None

# kapsamlÄ±_satÄ±ÅŸ_analizi(satÄ±ÅŸ_verisi)

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---# 7. ğŸ“‹ GruplandÄ±rma ve Pivot Tablolar

Veri analizinde en gÃ¼Ã§lÃ¼ araÃ§lardan biri gruplandÄ±rmadÄ±r. Pandas'Ä±n `groupby()` fonksiyonu ve pivot tablolar, verileri kategorilere ayÄ±rÄ±p analiz etmenizi saÄŸlar.

## ğŸ‘¥ groupby() Temelleri

### Basit GruplandÄ±rma

```python
import pandas as pd
import numpy as np

# Åirket Ã§alÄ±ÅŸanlarÄ± veri seti
np.random.seed(42)
Ã§alÄ±ÅŸanlar = pd.DataFrame({
    'ad': ['Ali', 'AyÅŸe', 'Mehmet', 'Fatma', 'Kemal', 'Zeynep', 'Ozan', 'Elif', 'Murat', 'Selin',
           'Can', 'Deniz', 'Emre', 'GÃ¼l', 'Hakan', 'Ä°rem', 'Jale', 'Kaan', 'Lale', 'Mine'],
    'departman': np.random.choice(['IT', 'HR', 'Finance', 'Marketing', 'Sales'], 20),
    'ÅŸehir': np.random.choice(['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa'], 20),
    'yaÅŸ': np.random.randint(22, 55, 20),
    'maaÅŸ': np.random.randint(4000, 12000, 20),
    'deneyim_yÄ±l': np.random.randint(0, 20, 20),
    'performans_notu': np.random.randint(60, 100, 20)
})

print("Ã‡alÄ±ÅŸan veri seti:")
print(Ã§alÄ±ÅŸanlar.head(10))
```

### Tek SÃ¼tuna GÃ¶re GruplandÄ±rma

```python
# Departmana gÃ¶re gruplandÄ±rma
print("Departmana gÃ¶re ortalama maaÅŸ:")
dept_ortalama = Ã§alÄ±ÅŸanlar.groupby('departman')['maaÅŸ'].mean()
print(dept_ortalama.sort_values(ascending=False))

print("\nDepartmana gÃ¶re Ã§alÄ±ÅŸan sayÄ±sÄ±:")
dept_sayÄ± = Ã§alÄ±ÅŸanlar.groupby('departman').size()
print(dept_sayÄ±.sort_values(ascending=False))

# Birden fazla istatistik
print("\nDepartman bazÄ±nda detaylÄ± istatistikler:")
dept_detay = Ã§alÄ±ÅŸanlar.groupby('departman')['maaÅŸ'].agg(['count', 'mean', 'std', 'min', 'max'])
print(dept_detay.round(2))
```

### Ã‡oklu SÃ¼tuna GÃ¶re GruplandÄ±rma

```python
# Departman ve ÅŸehre gÃ¶re gruplandÄ±rma
print("Departman-Åehir bazÄ±nda ortalama maaÅŸ:")
Ã§oklu_grup = Ã§alÄ±ÅŸanlar.groupby(['departman', 'ÅŸehir'])['maaÅŸ'].mean()
print(Ã§oklu_grup.sort_values(ascending=False))

# Unstack ile pivot benzeri gÃ¶rÃ¼nÃ¼m
print("\nPivot benzeri gÃ¶rÃ¼nÃ¼m:")
pivot_gÃ¶rÃ¼nÃ¼m = Ã§alÄ±ÅŸanlar.groupby(['departman', 'ÅŸehir'])['maaÅŸ'].mean().unstack(fill_value=0)
print(pivot_gÃ¶rÃ¼nÃ¼m.round(0))
```

## ğŸ”¢ Aggregation (Toplama) FonksiyonlarÄ±

### Temel Aggregation

```python
# Birden fazla sÃ¼tun iÃ§in aggregation
print("Departman bazÄ±nda Ã§oklu istatistikler:")
dept_agg = Ã§alÄ±ÅŸanlar.groupby('departman').agg({
    'maaÅŸ': ['mean', 'std', 'count'],
    'yaÅŸ': ['mean', 'min', 'max'],
    'deneyim_yÄ±l': ['mean', 'sum'],
    'performans_notu': ['mean', 'std']
}).round(2)

print(dept_agg)

# SÃ¼tun isimlerini dÃ¼zenleme
dept_agg.columns = ['_'.join(col).strip() for col in dept_agg.columns.values]
print("\nDÃ¼zenlenmiÅŸ sÃ¼tun isimleri ile:")
print(dept_agg.head())
```

### Ã–zel Aggregation FonksiyonlarÄ±

```python
# Ã–zel fonksiyonlar tanÄ±mlama
def maaÅŸ_aralÄ±ÄŸÄ±(series):
    return series.max() - series.min()

def performans_kategorisi(series):
    if series.mean() >= 85:
        return 'MÃ¼kemmel'
    elif series.mean() >= 75:
        return 'Ä°yi'
    else:
        return 'GeliÅŸtirilmeli'

# Ã–zel fonksiyonlarÄ± kullanma
print("Departman bazÄ±nda Ã¶zel metrikler:")
Ã¶zel_metrikler = Ã§alÄ±ÅŸanlar.groupby('departman').agg({
    'maaÅŸ': ['mean', maaÅŸ_aralÄ±ÄŸÄ±],
    'performans_notu': ['mean', performans_kategorisi]
}).round(2)

print(Ã¶zel_metrikler)

# Lambda fonksiyonlarÄ± ile
print("\nLambda fonksiyonlarÄ± ile:")
lambda_agg = Ã§alÄ±ÅŸanlar.groupby('departman').agg({
    'maaÅŸ': [lambda x: x.max() - x.min(), lambda x: len(x[x > x.median()])],
    'yaÅŸ': lambda x: x.quantile(0.75)
}).round(2)

print(lambda_agg)
```

### Named Aggregation (Pandas 0.25+)

```python
# Daha temiz aggregation sÃ¶z dizimi
print("Named aggregation ile temiz sÃ¶z dizimi:")
temiz_agg = Ã§alÄ±ÅŸanlar.groupby('departman').agg(
    ortalama_maaÅŸ=('maaÅŸ', 'mean'),
    medyan_maaÅŸ=('maaÅŸ', 'median'),
    Ã§alÄ±ÅŸan_sayÄ±sÄ±=('ad', 'count'),
    min_yaÅŸ=('yaÅŸ', 'min'),
    max_yaÅŸ=('yaÅŸ', 'max'),
    ortalama_performans=('performans_notu', 'mean')
).round(2)

print(temiz_agg)
```

## ğŸ”„ Transform ve Apply

### Transform Ä°ÅŸlemleri

```python
# Transform - grup bazlÄ± hesaplamalar
print("Her Ã§alÄ±ÅŸanÄ±n departman ortalamasÄ±ndan farkÄ±:")

# Departman ortalamasÄ±nÄ± hesapla ve her satÄ±ra ekle
Ã§alÄ±ÅŸanlar['dept_ortalama_maaÅŸ'] = Ã§alÄ±ÅŸanlar.groupby('departman')['maaÅŸ'].transform('mean')
Ã§alÄ±ÅŸanlar['maaÅŸ_farkÄ±'] = Ã§alÄ±ÅŸanlar['maaÅŸ'] - Ã§alÄ±ÅŸanlar['dept_ortalama_maaÅŸ']

print(Ã§alÄ±ÅŸanlar[['ad', 'departman', 'maaÅŸ', 'dept_ortalama_maaÅŸ', 'maaÅŸ_farkÄ±']].head())

# Z-score hesaplama (standartlaÅŸtÄ±rma)
Ã§alÄ±ÅŸanlar['maaÅŸ_z_score'] = Ã§alÄ±ÅŸanlar.groupby('departman')['maaÅŸ'].transform(
    lambda x: (x - x.mean()) / x.std()
)

print("\nDepartman iÃ§i maaÅŸ z-score'larÄ±:")
print(Ã§alÄ±ÅŸanlar[['ad', 'departman', 'maaÅŸ', 'maaÅŸ_z_score']].round(2))
```

### Apply Ä°ÅŸlemleri

```python
# Apply - her grup iÃ§in Ã¶zel fonksiyon
def departman_analizi(grup):
    """Her departman iÃ§in detaylÄ± analiz"""
    analiz = pd.Series({
        'Ã§alÄ±ÅŸan_sayÄ±sÄ±': len(grup),
        'ortalama_maaÅŸ': grup['maaÅŸ'].mean(),
        'maaÅŸ_std': grup['maaÅŸ'].std(),
        'deneyimli_Ã§alÄ±ÅŸan_oranÄ±': len(grup[grup['deneyim_yÄ±l'] > 5]) / len(grup),
        'yÃ¼ksek_performans_oranÄ±': len(grup[grup['performans_notu'] > 85]) / len(grup),
        'en_genÃ§': grup['yaÅŸ'].min(),
        'en_yaÅŸlÄ±': grup['yaÅŸ'].max()
    })
    return analiz

print("Departman bazÄ±nda detaylÄ± analiz:")
dept_analiz = Ã§alÄ±ÅŸanlar.groupby('departman').apply(departman_analizi).round(3)
print(dept_analiz)
```

## ğŸ† En Ä°yi Performans GÃ¶sterenleri Bulma

```python
# Her departmanÄ±n en yÃ¼ksek maaÅŸlÄ± Ã§alÄ±ÅŸanÄ±
print("Her departmanÄ±n en yÃ¼ksek maaÅŸlÄ± Ã§alÄ±ÅŸanÄ±:")
en_yÃ¼ksek_maaÅŸ = Ã§alÄ±ÅŸanlar.loc[Ã§alÄ±ÅŸanlar.groupby('departman')['maaÅŸ'].idxmax()]
print(en_yÃ¼ksek_maaÅŸ[['ad', 'departman', 'maaÅŸ']])

# Her ÅŸehrin en deneyimli Ã§alÄ±ÅŸanÄ±
print("\nHer ÅŸehrin en deneyimli Ã§alÄ±ÅŸanÄ±:")
en_deneyimli = Ã§alÄ±ÅŸanlar.loc[Ã§alÄ±ÅŸanlar.groupby('ÅŸehir')['deneyim_yÄ±l'].idxmax()]
print(en_deneyimli[['ad', 'ÅŸehir', 'deneyim_yÄ±l']])

# Top N seÃ§imi - her departmanÄ±n en iyi 2 performans gÃ¶stereni
print("\nHer departmanÄ±n en iyi 2 performans gÃ¶stereni:")
top_performans = Ã§alÄ±ÅŸanlar.groupby('departman').apply(
    lambda x: x.nlargest(2, 'performans_notu')
).reset_index(drop=True)

print(top_performans[['ad', 'departman', 'performans_notu']])
```

## ğŸ“Š GeliÅŸmiÅŸ Pivot Tablo Ä°ÅŸlemleri

### Ã‡oklu DeÄŸerli Pivot Tablolar

```python
# SatÄ±ÅŸ verisi Ã¶rneÄŸi
np.random.seed(42)
satÄ±ÅŸlar = pd.DataFrame({
    'tarih': pd.date_range('2024-01-01', periods=500, freq='D'),
    'satÄ±ÅŸ_temsilcisi': np.random.choice(['Ali', 'AyÅŸe', 'Mehmet', 'Fatma'], 500),
    'bÃ¶lge': np.random.choice(['Ä°stanbul', 'Ankara', 'Ä°zmir'], 500),
    'Ã¼rÃ¼n': np.random.choice(['Laptop', 'Mouse', 'Klavye', 'Monitor'], 500),
    'miktar': np.random.randint(1, 20, 500),
    'fiyat': np.random.randint(50, 2000, 500)
})

satÄ±ÅŸlar['toplam_satÄ±ÅŸ'] = satÄ±ÅŸlar['miktar'] * satÄ±ÅŸlar['fiyat']
satÄ±ÅŸlar['ay'] = satÄ±ÅŸlar['tarih'].dt.month
satÄ±ÅŸlar['Ã§eyrek'] = satÄ±ÅŸlar['tarih'].dt.quarter

print("SatÄ±ÅŸ verisi:")
print(satÄ±ÅŸlar.head())
```

### Ã‡ok Boyutlu Pivot Tablolar

```python
# Ã‡ok katmanlÄ± pivot tablo
print("Temsilci-BÃ¶lge-ÃœrÃ¼n bazÄ±nda satÄ±ÅŸ analizi:")
Ã§ok_boyut_pivot = satÄ±ÅŸlar.pivot_table(
    values=['toplam_satÄ±ÅŸ', 'miktar'],
    index=['satÄ±ÅŸ_temsilcisi', 'bÃ¶lge'],
    columns='Ã¼rÃ¼n',
    aggfunc={'toplam_satÄ±ÅŸ': 'sum', 'miktar': 'sum'},
    fill_value=0,
    margins=True
)

print(Ã§ok_boyut_pivot)

# Zaman serisi pivot
print("\nAylÄ±k satÄ±ÅŸ trendi (temsilci bazÄ±nda):")
aylÄ±k_pivot = satÄ±ÅŸlar.pivot_table(
    values='toplam_satÄ±ÅŸ',
    index='satÄ±ÅŸ_temsilcisi',
    columns='ay',
    aggfunc='sum',
    fill_value=0
)

print(aylÄ±k_pivot)
```

### GeliÅŸmiÅŸ Cross-tabulation

```python
# DetaylÄ± cross-tabulation
print("BÃ¶lge-ÃœrÃ¼n cross-tabulation:")
cross_tab = pd.crosstab(
    satÄ±ÅŸlar['bÃ¶lge'], 
    satÄ±ÅŸlar['Ã¼rÃ¼n'], 
    values=satÄ±ÅŸlar['toplam_satÄ±ÅŸ'], 
    aggfunc='sum',
    margins=True,
    normalize='index'  # SatÄ±r bazÄ±nda normalleÅŸtirme
)

print(cross_tab.round(2))

# Chi-square test ile
from scipy.stats import chi2_contingency
chi2_tab = pd.crosstab(satÄ±ÅŸlar['bÃ¶lge'], satÄ±ÅŸlar['Ã¼rÃ¼n'])
chi2, p_value, dof, expected = chi2_contingency(chi2_tab)

print(f"\nChi-square test sonucu:")
print(f"Chi-square: {chi2:.2f}")
print(f"P-value: {p_value:.4f}")
print(f"BÃ¶lge ve Ã¼rÃ¼n tercihi arasÄ±nda anlamlÄ± iliÅŸki: {'Var' if p_value < 0.05 else 'Yok'}")
```

## ğŸ”§ Pratik Groupby Teknikleri

### KoÅŸullu Gruplama

```python
# YaÅŸ gruplarÄ±na gÃ¶re gruplama
Ã§alÄ±ÅŸanlar['yaÅŸ_grubu'] = pd.cut(Ã§alÄ±ÅŸanlar['yaÅŸ'], 
                               bins=[0, 30, 40, 50, 100], 
                               labels=['GenÃ§', 'Orta YaÅŸ', 'Deneyimli', 'KÄ±demli'])

print("YaÅŸ gruplarÄ±na gÃ¶re maaÅŸ analizi:")
yaÅŸ_grup_analiz = Ã§alÄ±ÅŸanlar.groupby('yaÅŸ_grubu')['maaÅŸ'].describe()
print(yaÅŸ_grup_analiz)

# Performans kategorilerine gÃ¶re gruplama
Ã§alÄ±ÅŸanlar['performans_kategori'] = pd.cut(Ã§alÄ±ÅŸanlar['performans_notu'],
                                         bins=[0, 70, 85, 100],
                                         labels=['GeliÅŸim Gerekli', 'Ä°yi', 'MÃ¼kemmel'])

print("\nPerformans kategorilerine gÃ¶re maaÅŸ daÄŸÄ±lÄ±mÄ±:")
perf_maaÅŸ = Ã§alÄ±ÅŸanlar.groupby('performans_kategori')['maaÅŸ'].mean()
print(perf_maaÅŸ)
```

### Rolling ve Expanding Ä°ÅŸlemler

```python
# Zaman serisi iÃ§in rolling iÅŸlemler
aylÄ±k_satÄ±ÅŸ = satÄ±ÅŸlar.groupby('tarih')['toplam_satÄ±ÅŸ'].sum().reset_index()
aylÄ±k_satÄ±ÅŸ = aylÄ±k_satÄ±ÅŸ.set_index('tarih').sort_index()

# 7 gÃ¼nlÃ¼k hareketli ortalama
aylÄ±k_satÄ±ÅŸ['7_gun_ortalama'] = aylÄ±k_satÄ±ÅŸ['toplam_satÄ±ÅŸ'].rolling(window=7).mean()

# 30 gÃ¼nlÃ¼k hareketli ortalama
aylÄ±k_satÄ±ÅŸ['30_gun_ortalama'] = aylÄ±k_satÄ±ÅŸ['toplam_satÄ±ÅŸ'].rolling(window=30).mean()

# Expanding (kÃ¼mÃ¼latif) ortalama
aylÄ±k_satÄ±ÅŸ['kÃ¼mÃ¼latif_ortalama'] = aylÄ±k_satÄ±ÅŸ['toplam_satÄ±ÅŸ'].expanding().mean()

print("Zaman serisi analizi (son 10 gÃ¼n):")
print(aylÄ±k_satÄ±ÅŸ.tail(10).round(2))
```

## âš ï¸ Dikkat Edilmesi Gerekenler

> **ğŸ” Grup BoyutlarÄ±**: Ã‡ok kÃ¼Ã§Ã¼k gruplar yanÄ±ltÄ±cÄ± istatistikler Ã¼retebilir.

> **ğŸ“Š Aggregation SeÃ§imi**: AmacanÄ±za uygun aggregation fonksiyonu seÃ§in (mean, median, sum vs).

> **âš¡ Performans**: Ã‡ok bÃ¼yÃ¼k verilerle groupby iÅŸlemleri zaman alabilir.

## ğŸš¨ SÄ±k YapÄ±lan Hatalar

| Hata | AÃ§Ä±klama | Ã‡Ã¶zÃ¼m |
|------|----------|-------|
| `KeyError` during groupby | Olmayan sÃ¼tuna gÃ¶re gruplama | SÃ¼tun adlarÄ±nÄ± kontrol edin |
| YanlÄ±ÅŸ aggregation fonksiyonu | Kategorik veriye mean uygulamak | Veri tipine uygun fonksiyon seÃ§in |
| MultiIndex karmaÅŸasÄ± | Ã‡oklu grup sonrasÄ± karÄ±ÅŸÄ±klÄ±k | `reset_index()` kullanÄ±n |
| Missing values sorunlarÄ± | NaN deÄŸerler groupby'Ä± etkiliyor | Ã–nceden temizleyin veya `dropna=False` |
| Transform vs Aggregation | KarÄ±ÅŸtÄ±rÄ±lmasÄ± | Transform: aynÄ± boyut, Agg: Ã¶zetlenmiÅŸ |

### Pratik Groupby YardÄ±mcÄ± Fonksiyonu

```python
def akÄ±llÄ±_groupby_analizi(df, grup_sÃ¼tunu, hedef_sÃ¼tun, analiz_tipi='full'):
    """
    AkÄ±llÄ± groupby analizi yapan fonksiyon
    """
    print(f"ğŸ“Š {grup_sÃ¼tunu} bazÄ±nda {hedef_sÃ¼tun} analizi")
    print("="*50)
    
    # Temel istatistikler
    if analiz_tipi in ['full', 'basic']:
        basic_stats = df.groupby(grup_sÃ¼tunu)[hedef_sÃ¼tun].describe()
        print("Temel istatistikler:")
        print(basic_stats.round(2))
        print("\n")
    
    # DaÄŸÄ±lÄ±m analizi
    if analiz_tipi in ['full', 'distribution']:
        dist_analysis = df.groupby(grup_sÃ¼tunu)[hedef_sÃ¼tun].agg([
            'count', 'mean', 'median', 'std', 
            lambda x: x.quantile(0.25),
            lambda x: x.quantile(0.75),
            'skew'
        ]).round(3)
        
        dist_analysis.columns = ['Count', 'Mean', 'Median', 'Std', 'Q25', 'Q75', 'Skewness']
        print("DaÄŸÄ±lÄ±m analizi:")
        print(dist_analysis)
        print("\n")
    
    # Outlier analizi
    if analiz_tipi in ['full', 'outliers']:
        def outlier_count(series):
            Q1, Q3 = series.quantile([0.25, 0.75])
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            return len(series[(series < lower_bound) | (series > upper_bound)])
        
        outliers = df.groupby(grup_sÃ¼tunu)[hedef_sÃ¼tun].apply(outlier_count)
        print("Grup bazÄ±nda aykÄ±rÄ± deÄŸer sayÄ±larÄ±:")
        print(outliers)
        print("\n")
    
    # Grup karÅŸÄ±laÅŸtÄ±rmasÄ±
    if analiz_tipi == 'full':
        group_comparison = df.groupby(grup_sÃ¼tunu)[hedef_sÃ¼tun].mean().sort_values(ascending=False)
        print("Grup sÄ±ralamasÄ± (ortalamaya gÃ¶re):")
        print(group_comparison)
    
    return None

# KullanÄ±m Ã¶rneÄŸi
# akÄ±llÄ±_groupby_analizi(Ã§alÄ±ÅŸanlar, 'departman', 'maaÅŸ', 'full')
```

## ğŸ¯ Egzersizler

### Egzersiz 1: Temel Groupby Ä°ÅŸlemleri
```python
# YukarÄ±daki Ã§alÄ±ÅŸanlar DataFrame'ini kullanarak:
# 1. Her ÅŸehirdeki ortalama yaÅŸÄ± hesaplayÄ±n
# 2. Departman bazÄ±nda maksimum ve minimum maaÅŸlarÄ± bulun
# 3. Hem departman hem ÅŸehire gÃ¶re ortalama performans notunu hesaplayÄ±n
# 4. Her departmandaki Ã§alÄ±ÅŸan sayÄ±sÄ±nÄ± ve toplam maaÅŸ giderini bulun

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 2: Ä°leri Seviye Aggregation
```python
# 1. Her departman iÃ§in ÅŸu metrikleri hesaplayÄ±n:
#    - Ortalama maaÅŸ
#    - MaaÅŸ standart sapmasÄ±  
#    - En deneyimli Ã§alÄ±ÅŸanÄ±n yaÅŸÄ±
#    - Performans notu 80'in Ã¼zerinde olan Ã§alÄ±ÅŸan oranÄ±
#    - MaaÅŸ aralÄ±ÄŸÄ± (max - min)

# 2. Named aggregation kullanarak temiz bir tablo oluÅŸturun

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 3: Transform ve Apply UygulamalarÄ±
```python
# 1. Her Ã§alÄ±ÅŸan iÃ§in departman iÃ§indeki maaÅŸ sÄ±ralamasÄ±nÄ± hesaplayÄ±n
# 2. Departman ortalamasÄ±ndan ne kadar sapÄ±ldÄ±ÄŸÄ±nÄ± hesaplayÄ±n (z-score)
# 3. Her departmanÄ±n en yÃ¼ksek performanslÄ± 3 Ã§alÄ±ÅŸanÄ±nÄ± bulun
# 4. Her ÅŸehirdeki en deneyimli ve en genÃ§ Ã§alÄ±ÅŸanlarÄ± listeleyin

# Ã‡Ã¶zÃ¼m alanÄ±:

```

### Egzersiz 4: KarmaÅŸÄ±k Pivot ve Cross-Tab
```python
# SatÄ±ÅŸlar DataFrame'ini kullanarak:
# 1. Ã‡eyrek-BÃ¶lge-ÃœrÃ¼n bazÄ±nda toplam satÄ±ÅŸ pivot tablosu oluÅŸturun
# 2. SatÄ±ÅŸ temsilcilerinin aylÄ±k performans trendini gÃ¶sterin
# 3. Hangi bÃ¶lge-Ã¼rÃ¼n kombinasyonu en karlÄ±?
# 4. Cross-tabulation ile bÃ¶lge ve Ã¼rÃ¼n tercihi arasÄ±nda anlamlÄ± iliÅŸki var mÄ±?

# Ã‡Ã¶zÃ¼m alanÄ±:

```

---# 8. ğŸ’¼ Pratik Uygulama Projesi

Bu bÃ¶lÃ¼mde, ÅŸimdiye kadar Ã¶ÄŸrendiÄŸiniz tÃ¼m Pandas tekniklerini gerÃ§ek bir veri analizi projesinde uygulayacaÄŸÄ±z.

## ğŸ¯ Proje: E-ticaret SatÄ±ÅŸ Analizi

### ğŸ“‹ Proje AÃ§Ä±klamasÄ±

Bir e-ticaret ÅŸirketinin 2024 yÄ±lÄ± satÄ±ÅŸ verilerini analiz edeceÄŸiz. AmacÄ±mÄ±z:
- SatÄ±ÅŸ performansÄ±nÄ± deÄŸerlendirmek
- MÃ¼ÅŸteri segmentasyonu yapmak  
- ÃœrÃ¼n performansÄ± analizi
- Sezonsal trendleri belirlemek
- Ä°ÅŸ geliÅŸtirme Ã¶nerileri sunmak

### ğŸ“Š Veri Seti OluÅŸturma

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Veri seti oluÅŸturma
np.random.seed(42)

# Temel parametreler
num_orders = 10000
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 12, 31)

# Tarih aralÄ±ÄŸÄ± oluÅŸturma
date_range = pd.date_range(start_date, end_date)

# E-ticaret veri seti oluÅŸturma
print("ğŸ”„ E-ticaret veri seti oluÅŸturuluyor...")

eticaret_data = pd.DataFrame({
    'siparis_id': range(1, num_orders + 1),
    'tarih': np.random.choice(date_range, num_orders),
    'musteri_id': np.random.randint(1001, 5000, num_orders),
    'urun_kategori': np.random.choice([
        'Elektronik', 'Giyim', 'Ev & YaÅŸam', 'Kitap', 'Spor', 
        'Kozmetik', 'Oyuncak', 'Otomotiv'
    ], num_orders, p=[0.2, 0.15, 0.15, 0.1, 0.1, 0.1, 0.1, 0.1]),
    
    'urun_adi': np.random.choice([
        'Laptop', 'Telefon', 'KulaklÄ±k', 'TiÅŸÃ¶rt', 'Pantolon', 
        'AyakkabÄ±', 'Kitap', 'Oyun', 'ParfÃ¼m', 'Saat'
    ], num_orders),
    
    'adet': np.random.choice([1, 2, 3, 4, 5], num_orders, p=[0.5, 0.25, 0.15, 0.07, 0.03]),
    
    'birim_fiyat': np.random.gamma(shape=2, scale=100, size=num_orders),
    
    'musteri_yas': np.random.normal(35, 15, num_orders),
    
    'sehir': np.random.choice([
        'Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya', 
        'Adana', 'Konya', 'Kayseri'
    ], num_orders, p=[0.3, 0.15, 0.12, 0.08, 0.08, 0.07, 0.1, 0.1]),
    
    'odeme_yontem': np.random.choice([
        'Kredi KartÄ±', 'Banka KartÄ±', 'Nakit', 'Havale'
    ], num_orders, p=[0.6, 0.25, 0.1, 0.05]),
    
    'kargo_ucreti': np.random.choice([0, 15, 25, 35], num_orders, p=[0.4, 0.3, 0.2, 0.1])
})

# TÃ¼retilmiÅŸ sÃ¼tunlar
eticaret_data['toplam_fiyat'] = eticaret_data['adet'] * eticaret_data['birim_fiyat']
eticaret_data['toplam_odeme'] = eticaret_data['toplam_fiyat'] + eticaret_data['kargo_ucreti']

# YaÅŸ grubunu float olan deÄŸerleri integer'a Ã§evirme
eticaret_data['musteri_yas'] = eticaret_data['musteri_yas'].astype(int)
eticaret_data['musteri_yas'] = eticaret_data['musteri_yas'].clip(18, 80)  # 18-80 yaÅŸ arasÄ±

# Tarih sÃ¼tunundan ek bilgiler
eticaret_data['ay'] = eticaret_data['tarih'].dt.month
eticaret_data['gun'] = eticaret_data['tarih'].dt.day
eticaret_data['hafta'] = eticaret_data['tarih'].dt.isocalendar().week
eticaret_data['haftanin_gunu'] = eticaret_data['tarih'].dt.day_name()
eticaret_data['ceyrek'] = eticaret_data['tarih'].dt.quarter

print("âœ… Veri seti baÅŸarÄ±yla oluÅŸturuldu!")
print(f"ğŸ“Š Toplam sipariÅŸ sayÄ±sÄ±: {len(eticaret_data):,}")
print(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {eticaret_data['tarih'].min()} - {eticaret_data['tarih'].max()}")
print("\nğŸ” Veri setinin ilk 5 satÄ±rÄ±:")
print(eticaret_data.head())
```

## ğŸ§¹ AdÄ±m 1: Veri Temizleme ve Ã–n Ä°nceleme

```python
print("=" * 60)
print("ğŸ§¹ ADIM 1: VERÄ° TEMÄ°ZLEME VE Ã–N Ä°NCELEME")
print("=" * 60)

# 1.1 Temel bilgileri inceleme
print("ğŸ“Š Veri seti genel bilgileri:")
print(f"Boyut: {eticaret_data.shape}")
print(f"SÃ¼tun sayÄ±sÄ±: {len(eticaret_data.columns)}")
print(f"SatÄ±r sayÄ±sÄ±: {len(eticaret_data)}")

print("\nğŸ” Veri tipleri:")
print(eticaret_data.dtypes)

# 1.2 Eksik veri kontrolÃ¼
print("\nğŸ•³ï¸ Eksik veri kontrolÃ¼:")
eksik_veriler = eticaret_data.isnull().sum()
print(eksik_veriler[eksik_veriler > 0])

if eksik_veriler.sum() == 0:
    print("âœ… HiÃ§ eksik veri yok!")
else:
    print(f"âš ï¸ Toplam eksik veri: {eksik_veriler.sum()}")

# 1.3 Duplikasyon kontrolÃ¼
duplikasyon_sayisi = eticaret_data.duplicated().sum()
print(f"\nğŸ”„ Duplikasyon kontrolÃ¼: {duplikasyon_sayisi} adet")

if duplikasyon_sayisi > 0:
    print("ğŸ§¹ Duplikasyonlar temizleniyor...")
    eticaret_data = eticaret_data.drop_duplicates()
    print(f"âœ… {duplikasyon_sayisi} duplikasyon temizlendi!")

# 1.4 SayÄ±sal sÃ¼tunlar iÃ§in temel istatistikler
print("\nğŸ“ˆ SayÄ±sal sÃ¼tunlar iÃ§in temel istatistikler:")
sayisal_sutunlar = ['adet', 'birim_fiyat', 'toplam_fiyat', 'toplam_odeme', 'musteri_yas']
print(eticaret_data[sayisal_sutunlar].describe().round(2))

# 1.5 Kategorik sÃ¼tunlar iÃ§in Ã¶zet
print("\nğŸ“Š Kategorik sÃ¼tunlar daÄŸÄ±lÄ±mÄ±:")
kategorik_sutunlar = ['urun_kategori', 'sehir', 'odeme_yontem']
for sutun in kategorik_sutunlar:
    print(f"\n{sutun}:")
    print(eticaret_data[sutun].value_counts().head())
```

## ğŸ“Š AdÄ±m 2: KeÅŸifsel Veri Analizi (EDA)

```python
print("\n" + "=" * 60)
print("ğŸ“Š ADIM 2: KEÅÄ°FSEL VERÄ° ANALÄ°ZÄ°")
print("=" * 60)

# 2.1 SatÄ±ÅŸ performansÄ± Ã¶zeti
print("ğŸ’° GENEL SATIÅ PERFORMANSI")
print("-" * 30)

toplam_gelir = eticaret_data['toplam_odeme'].sum()
ortalama_siparis = eticaret_data['toplam_odeme'].mean()
siparis_sayisi = len(eticaret_data)
benzersiz_musteri = eticaret_data['musteri_id'].nunique()

print(f"ğŸ’µ Toplam Gelir: â‚º{toplam_gelir:,.2f}")
print(f"ğŸ“¦ Toplam SipariÅŸ: {siparis_sayisi:,}")
print(f"ğŸ‘¥ Benzersiz MÃ¼ÅŸteri: {benzersiz_musteri:,}")
print(f"ğŸ’° Ortalama SipariÅŸ DeÄŸeri: â‚º{ortalama_siparis:.2f}")
print(f"ğŸ”„ MÃ¼ÅŸteri BaÅŸÄ±na Ortalama SipariÅŸ: {siparis_sayisi/benzersiz_musteri:.1f}")

# 2.2 En Ã§ok satan kategori analizi
print("\nğŸ† EN Ã‡OK SATAN KATEGORÄ°LER")
print("-" * 30)

kategori_performans = eticaret_data.groupby('urun_kategori').agg({
    'toplam_odeme': 'sum',
    'siparis_id': 'count',
    'musteri_id': 'nunique'
}).round(2)

kategori_performans.columns = ['Toplam_Gelir', 'Siparis_Sayisi', 'Musteri_Sayisi']
kategori_performans['Ortalama_Siparis'] = (kategori_performans['Toplam_Gelir'] / 
                                          kategori_performans['Siparis_Sayisi']).round(2)

kategori_performans = kategori_performans.sort_values('Toplam_Gelir', ascending=False)
print(kategori_performans)

# En performanslÄ± kategori
en_iyi_kategori = kategori_performans.index[0]
print(f"\nğŸ¥‡ En baÅŸarÄ±lÄ± kategori: {en_iyi_kategori}")
print(f"   ğŸ’° Gelir: â‚º{kategori_performans.loc[en_iyi_kategori, 'Toplam_Gelir']:,.2f}")

# 2.3 Åehir bazÄ±nda analiz
print("\nğŸ™ï¸ ÅEHÄ°R BAZINDA PERFORMANS")
print("-" * 30)

sehir_analiz = eticaret_data.groupby('sehir').agg({
    'toplam_odeme': ['sum', 'mean', 'count'],
    'musteri_id': 'nunique'
}).round(2)

sehir_analiz.columns = ['Toplam_Gelir', 'Ort_Siparis_Degeri', 'Siparis_Sayisi', 'Musteri_Sayisi']
sehir_analiz = sehir_analiz.sort_values('Toplam_Gelir', ascending=False)
print(sehir_analiz.head())

# 2.4 Ã–deme yÃ¶ntemi analizi
print("\nğŸ’³ Ã–DEME YÃ–NTEMÄ° ANALÄ°ZÄ°")
print("-" * 30)

odeme_analiz = eticaret_data.groupby('odeme_yontem').agg({
    'toplam_odeme': ['sum', 'mean', 'count'],
    'musteri_id': 'nunique'
}).round(2)

odeme_analiz.columns = ['Toplam_Gelir', 'Ort_Siparis_Degeri', 'Siparis_Sayisi', 'Musteri_Sayisi']
print(odeme_analiz.sort_values('Toplam_Gelir', ascending=False))
```

## ğŸ“ˆ AdÄ±m 3: Zaman Serisi Analizi

```python
print("\n" + "=" * 60)
print("ğŸ“ˆ ADIM 3: ZAMAN SERÄ°SÄ° ANALÄ°ZÄ°")
print("=" * 60)

# 3.1 AylÄ±k satÄ±ÅŸ trendi
print("ğŸ“… AYLIK SATIÅ TRENDÄ°")
print("-" * 25)

aylik_satÄ±ÅŸ = eticaret_data.groupby('ay').agg({
    'toplam_odeme': ['sum', 'count'],
    'musteri_id': 'nunique'
}).round(2)

aylik_satÄ±ÅŸ.columns = ['Toplam_Gelir', 'Siparis_Sayisi', 'Musteri_Sayisi']

# Ay isimlerini ekleme
ay_isimleri = ['Ocak', 'Åubat', 'Mart', 'Nisan', 'MayÄ±s', 'Haziran',
               'Temmuz', 'AÄŸustos', 'EylÃ¼l', 'Ekim', 'KasÄ±m', 'AralÄ±k']
aylik_satÄ±ÅŸ['Ay_Adi'] = [ay_isimleri[i-1] for i in aylik_satÄ±ÅŸ.index]

print(aylik_satÄ±ÅŸ[['Ay_Adi', 'Toplam_Gelir', 'Siparis_Sayisi']])

# En iyi ve en kÃ¶tÃ¼ aylar
en_iyi_ay = aylik_satÄ±ÅŸ.loc[aylik_satÄ±ÅŸ['Toplam_Gelir'].idxmax(), 'Ay_Adi']
en_kotu_ay = aylik_satÄ±ÅŸ.loc[aylik_satÄ±ÅŸ['Toplam_Gelir'].idxmin(), 'Ay_Adi']

print(f"\nğŸ† En baÅŸarÄ±lÄ± ay: {en_iyi_ay}")
print(f"ğŸ“‰ En dÃ¼ÅŸÃ¼k performans: {en_kotu_ay}")

# 3.2 Ã‡eyrek bazÄ±nda analiz
print("\nğŸ“Š Ã‡EYREK BAZINDA PERFORMANS")
print("-" * 30)

ceyrek_analiz = eticaret_data.groupby('ceyrek').agg({
    'toplam_odeme': ['sum', 'mean'],
    'siparis_id': 'count',
    'musteri_id': 'nunique'
}).round(2)

ceyrek_analiz.columns = ['Toplam_Gelir', 'Ort_Siparis_Degeri', 'Siparis_Sayisi', 'Musteri_Sayisi']
print(ceyrek_analiz)

# 3.3 HaftanÄ±n gÃ¼nlerine gÃ¶re analiz
print("\nğŸ“… HAFTANIN GÃœNLERÄ°NE GÃ–RE ANALÄ°Z")
print("-" * 35)

# TÃ¼rkÃ§e gÃ¼n isimleri mapping
gun_mapping = {
    'Monday': 'Pazartesi',
    'Tuesday': 'SalÄ±', 
    'Wednesday': 'Ã‡arÅŸamba',
    'Thursday': 'PerÅŸembe',
    'Friday': 'Cuma',
    'Saturday': 'Cumartesi',
    'Sunday': 'Pazar'
}

eticaret_data['gun_tr'] = eticaret_data['haftanin_gunu'].map(gun_mapping)

gunluk_analiz = eticaret_data.groupby('gun_tr').agg({
    'toplam_odeme': ['sum', 'mean'],
    'siparis_id': 'count'
}).round(2)

gunluk_analiz.columns = ['Toplam_Gelir', 'Ort_Siparis_Degeri', 'Siparis_Sayisi']

# HaftanÄ±n gÃ¼nlerini doÄŸru sÄ±rada gÃ¶sterme
gun_sirasi = ['Pazartesi', 'SalÄ±', 'Ã‡arÅŸamba', 'PerÅŸembe', 'Cuma', 'Cumartesi', 'Pazar']
gunluk_analiz = gunluk_analiz.reindex(gun_sirasi)

print(gunluk_analiz)

en_yoÄŸun_gun = gunluk_analiz['Siparis_Sayisi'].idxmax()
print(f"\nğŸ“ˆ En yoÄŸun gÃ¼n: {en_yoÄŸun_gun}")
```

## ğŸ‘¥ AdÄ±m 4: MÃ¼ÅŸteri Segmentasyonu

```python
print("\n" + "=" * 60)
print("ğŸ‘¥ ADIM 4: MÃœÅTERÄ° SEGMENTASYONU")
print("=" * 60)

# 4.1 MÃ¼ÅŸteri bazÄ±nda analiz
print("ğŸ” MÃœÅTERÄ° ANALÄ°ZÄ° HAZIRLANIYOR...")

musteri_analiz = eticaret_data.groupby('musteri_id').agg({
    'toplam_odeme': ['sum', 'mean', 'count'],
    'tarih': ['min', 'max'],
    'urun_kategori': lambda x: x.nunique()
}).round(2)

# SÃ¼tun isimlerini dÃ¼zenleme
musteri_analiz.columns = [
    'Toplam_Harcama', 'Ort_Siparis_Degeri', 'Siparis_Sayisi',
    'Ilk_Siparis', 'Son_Siparis', 'Farkli_Kategori'
]

# MÃ¼ÅŸteri deÄŸerini hesaplama (Customer Lifetime Value - basit versiyon)
musteri_analiz['CLV'] = (musteri_analiz['Toplam_Harcama'] * 
                        musteri_analiz['Siparis_Sayisi'] / 100).round(2)

# MÃ¼ÅŸteri yaÅŸ segmentasyonu
musteri_yas = eticaret_data.groupby('musteri_id')['musteri_yas'].first()
musteri_analiz['Yas'] = musteri_yas

# YaÅŸ gruplarÄ±nÄ± oluÅŸturma
musteri_analiz['Yas_Grubu'] = pd.cut(
    musteri_analiz['Yas'], 
    bins=[0, 25, 35, 50, 100], 
    labels=['Z KuÅŸaÄŸÄ± (18-25)', 'Milenyum (26-35)', 'X KuÅŸaÄŸÄ± (36-50)', 'Baby Boomer (50+)']
)

print("\nğŸ“Š MÃœÅTERI SEGMENTASYONU SONUÃ‡LARI")
print("-" * 35)

# YaÅŸ grubu analizi
yas_grubu_analiz = musteri_analiz.groupby('Yas_Grubu').agg({
    'Toplam_Harcama': ['count', 'mean', 'sum'],
    'Siparis_Sayisi': 'mean',
    'CLV': 'mean'
}).round(2)

print("YaÅŸ Grubu BazÄ±nda Analiz:")
print(yas_grubu_analiz)

# En deÄŸerli mÃ¼ÅŸteriler (Top 5)
print("\nğŸ† EN DEÄERLÄ° MÃœÅTERÄ°LER (Top 5)")
print("-" * 30)
top_musteriler = musteri_analiz.nlargest(5, 'Toplam_Harcama')
print(top_musteriler[['Toplam_Harcama', 'Siparis_Sayisi', 'Ort_Siparis_Degeri', 'Yas_Grubu']])

# RFM Analizi (BasitleÅŸtirilmiÅŸ)
print("\nğŸ“Š RFM ANALÄ°ZÄ° (Recency, Frequency, Monetary)")
print("-" * 45)

# Recency: Son sipariÅŸten bu yana geÃ§en gÃ¼n sayÄ±sÄ±
max_tarih = eticaret_data['tarih'].max()
musteri_analiz['Recency'] = (max_tarih - musteri_analiz['Son_Siparis']).dt.days

# Frequency: SipariÅŸ sÄ±klÄ±ÄŸÄ± (zaten var)
# Monetary: Toplam harcama (zaten var)

# RFM skorlarÄ±nÄ± hesaplama (1-5 arasÄ±)
musteri_analiz['R_Score'] = pd.qcut(musteri_analiz['Recency'], 5, labels=range(5,0,-1))
musteri_analiz['F_Score'] = pd.qcut(musteri_analiz['Siparis_Sayisi'], 5, labels=range(1,6))
musteri_analiz['M_Score'] = pd.qcut(musteri_analiz['Toplam_Harcama'], 5, labels=range(1,6))

# RFM segmentleri
def rfm_segment(row):
    if row['R_Score'] >= 4 and row['F_Score'] >= 4 and row['M_Score'] >= 4:
        return 'Champions'
    elif row['R_Score'] >= 3 and row['F_Score'] >= 3:
        return 'Loyal Customers'
    elif row['R_Score'] >= 3 and row['M_Score'] >= 3:
        return 'Potential Loyalists'
    elif row['R_Score'] <= 2:
        return 'At Risk'
    else:
        return 'Others'

musteri_analiz['RFM_Segment'] = musteri_analiz.apply(rfm_segment, axis=1)

segment_dagÄ±lÄ±m = musteri_analiz['RFM_Segment'].value_counts()
print("MÃ¼ÅŸteri Segment DaÄŸÄ±lÄ±mÄ±:")
print(segment_dagÄ±lÄ±m)
print(f"\nSegment YÃ¼zdelik DaÄŸÄ±lÄ±mÄ±:")
print((segment_dagÄ±lÄ±m / len(musteri_analiz) * 100).round(1))
```

## ğŸ¯ AdÄ±m 5: ÃœrÃ¼n Performans Analizi

```python
print("\n" + "=" * 60)
print("ğŸ¯ ADIM 5: ÃœRÃœN PERFORMANS ANALÄ°ZÄ°")
print("=" * 60)

# 5.1 ÃœrÃ¼n kategori detay analizi
print("ğŸ“¦ ÃœRÃœN KATEGORÄ° DETAY ANALÄ°ZÄ°")
print("-" * 30)

urun_performans = eticaret_data.groupby('urun_kategori').agg({
    'toplam_odeme': ['sum', 'mean', 'count'],
    'adet': ['sum', 'mean'],
    'musteri_id': 'nunique',
    'birim_fiyat': 'mean'
}).round(2)

# SÃ¼tun isimlerini dÃ¼zenleme
urun_performans.columns = [
    'Toplam_Gelir', 'Ort_Siparis_Degeri', 'Siparis_Sayisi',
    'Toplam_Adet', 'Ort_Adet', 'Musteri_Sayisi', 'Ort_Birim_Fiyat'
]

# Pazar payÄ± hesaplama
urun_performans['Pazar_PayÄ±_%'] = (urun_performans['Toplam_Gelir'] / 
                                   urun_performans['Toplam_Gelir'].sum() * 100).round(1)

# KarlÄ±lÄ±k gÃ¶stergesi (basit)
urun_performans['Karlilik_Skoru'] = (
    urun_performans['Ort_Siparis_Degeri'] * urun_performans['Siparis_Sayisi'] / 
    urun_performans['Siparis_Sayisi'].sum()
).round(2)

urun_performans = urun_performans.sort_values('Toplam_Gelir', ascending=False)
print(urun_performans)

# 5.2 En popÃ¼ler Ã¼rÃ¼nler
print(f"\nğŸ† EN POPÃœLER ÃœRÃœNLER")
print("-" * 20)

urun_popÃ¼lerlik = eticaret_data.groupby('urun_adi').agg({
    'siparis_id': 'count',
    'adet': 'sum',
    'toplam_odeme': 'sum'
}).round(2)

urun_popÃ¼lerlik.columns = ['Siparis_Sayisi', 'Toplam_Adet', 'Toplam_Gelir']
urun_popÃ¼lerlik = urun_popÃ¼lerlik.sort_values('Siparis_Sayisi', ascending=False)

print("SipariÅŸ sayÄ±sÄ±na gÃ¶re top 10:")
print(urun_popÃ¼lerlik.head(10))

# 5.3 Kategori Ã§apraz analizi
print(f"\nğŸ”„ KATEGORÄ° Ã‡APRAZ ANALÄ°Z")
print("-" * 25)

# Kategorilerin ÅŸehirlere gÃ¶re daÄŸÄ±lÄ±mÄ±
kategori_sehir = pd.crosstab(
    eticaret_data['urun_kategori'], 
    eticaret_data['sehir'], 
    values=eticaret_data['toplam_odeme'], 
    aggfunc='sum'
).fillna(0)

print("Kategori-Åehir bazÄ±nda gelir daÄŸÄ±lÄ±mÄ±:")
print(kategori_sehir.round(0))

# Her ÅŸehrin en Ã§ok tercih ettiÄŸi kategori
print(f"\nHer ÅŸehrin en Ã§ok tercih ettiÄŸi kategoriler:")
for sehir in kategori_sehir.columns:
    en_popÃ¼ler = kategori_sehir[sehir].idxmax()
    gelir = kategori_sehir.loc[en_popÃ¼ler, sehir]
    print(f"{sehir}: {en_popÃ¼ler} (â‚º{gelir:,.0f})")
```

## ğŸ“‹ AdÄ±m 6: Ã–neriler ve SonuÃ§lar

```python
print("\n" + "=" * 60)
print("ğŸ“‹ ADIM 6: Ã–NERILER VE SONUÃ‡LAR")
print("=" * 60)

# 6.1 Ana bulgular Ã¶zeti
print("ğŸ” ANA BULGULAR")
print("-" * 15)

print(f"ğŸ’° Toplam Gelir: â‚º{toplam_gelir:,.2f}")
print(f"ğŸ“¦ Toplam SipariÅŸ: {siparis_sayisi:,}")
print(f"ğŸ‘¥ Toplam MÃ¼ÅŸteri: {benzersiz_musteri:,}")
print(f"ğŸ’µ Ortalama SipariÅŸ DeÄŸeri: â‚º{ortalama_siparis:.2f}")

# En baÅŸarÄ±lÄ± performanslar
print(f"\nğŸ† EN BAÅARILIFLAR:")
print(f"   ğŸ“Š Kategori: {en_iyi_kategori}")
print(f"   ğŸ™ï¸ Åehir: {sehir_analiz.index[0]}")
print(f"   ğŸ“… Ay: {en_iyi_ay}")
print(f"   ğŸ“† GÃ¼n: {en_yoÄŸun_gun}")
print(f"   ğŸ’³ Ã–deme: {odeme_analiz.index[0]}")

# MÃ¼ÅŸteri segmentasyonu Ã¶zetleri
print(f"\nğŸ‘¥ MÃœÅTERÄ° SEGMENTLERÄ°:")
for segment in segment_dagÄ±lÄ±m.index:
    yuzde = (segment_dagÄ±lÄ±m[segment] / len(musteri_analiz) * 100)
    print(f"   â€¢ {segment}: %{yuzde:.1f} ({segment_dagÄ±lÄ±m[segment]} mÃ¼ÅŸteri)")

# 6.2 Ä°ÅŸ geliÅŸtirme Ã¶nerileri
print(f"\nğŸ“ˆ Ä°Å GELÄ°ÅTÄ°RME Ã–NERÄ°LERÄ°")
print("-" * 25)

print("1. ğŸ¯ PAZARLAMA STRATEJÄ°LERÄ°:")
print(f"   â€¢ {en_iyi_kategori} kategorisine Ã¶zel kampanyalar dÃ¼zenleyin")
print(f"   â€¢ {en_yoÄŸun_gun} gÃ¼nleri iÃ§in Ã¶zel promosyonlar planlayÄ±n")
print(f"   â€¢ {sehir_analiz.index[0]} ÅŸehrine yoÄŸunlaÅŸÄ±n (en yÃ¼ksek gelir)")

print("\n2. ğŸ‘¥ MÃœÅTERÄ° YÃ–NETÄ°MÄ°:")
champions_oran = segment_dagÄ±lÄ±m.get('Champions', 0) / len(musteri_analiz) * 100
print(f"   â€¢ Champions mÃ¼ÅŸterileri (%{champions_oran:.1f}) iÃ§in VIP programÄ± baÅŸlatÄ±n")
print("   â€¢ 'At Risk' segmentindeki mÃ¼ÅŸteriler iÃ§in geri kazanÄ±m kampanyasÄ± yapÄ±n")
print("   â€¢ Potential Loyalists'larÄ± Champions'a dÃ¶nÃ¼ÅŸtÃ¼rmeye odaklanÄ±n")

print("\n3. ğŸ“¦ ÃœRÃœN YÃ–NETÄ°MÄ°:")
en_az_satan_kategori = kategori_performans.index[-1]
print(f"   â€¢ {en_az_satan_kategori} kategorisinin performansÄ±nÄ± iyileÅŸtirin")
print("   â€¢ PopÃ¼ler Ã¼rÃ¼nlerin stoklarÄ±nÄ± artÄ±rÄ±n")
print("   â€¢ Ã‡apraz satÄ±ÅŸ fÄ±rsatlarÄ±nÄ± deÄŸerlendirin")

print("\n4. ğŸšš OPERASYONEL Ä°YÄ°LEÅTÄ°RMELER:")
print("   â€¢ Ãœcretsiz kargo eÅŸik deÄŸerini optimize edin")
print("   â€¢ Peak gÃ¼nlerde (Ã¶zellikle hafta sonlarÄ±) kapasiteyi artÄ±rÄ±n")
print("   â€¢ Mobil Ã¶deme seÃ§eneklerini geliÅŸtirin")

# 6.3 KPI takibi Ã¶nerileri
print(f"\nğŸ“Š TAKÄ°P EDÄ°LMESÄ° GEREKEN KPI'LAR")
print("-" * 35)

print("â€¢ AylÄ±k gelir bÃ¼yÃ¼mesi")
print("â€¢ MÃ¼ÅŸteri kazanÄ±m maliyeti (CAC)")
print("â€¢ MÃ¼ÅŸteri yaÅŸam deÄŸeri (CLV)")
print("â€¢ Sepet terk etme oranÄ±")
print("â€¢ MÃ¼ÅŸteri memnuniyet skoru")
print("â€¢ Kategori bazÄ±nda pazar payÄ± deÄŸiÅŸimi")

print(f"\nâœ… ANALÄ°Z TAMAMLANDI!")
print("ğŸ“Š DetaylÄ± raporlar ve gÃ¶rselleÅŸtirmeler iÃ§in ek analizler yapÄ±labilir.")
```

## ğŸ¯ Proje DeÄŸerlendirme SorularÄ±

### Analitik DÃ¼ÅŸÃ¼nme SorularÄ±

1. **Veri Kalitesi**: Hangi veri kalitesi sorunlarÄ±yla karÅŸÄ±laÅŸtÄ±k ve nasÄ±l Ã§Ã¶zdÃ¼k?

2. **Trend Analizi**: AylÄ±k satÄ±ÅŸ trendlerinde gÃ¶zlemlenen pattern'lar ne anlama geliyor?

3. **MÃ¼ÅŸteri DavranÄ±ÅŸlarÄ±**: RFM analizinden Ã§Ä±kan segmentler iÅŸletme iÃ§in ne ifade ediyor?

4. **ÃœrÃ¼n PerformansÄ±**: Hangi kategoriler beklenenden farklÄ± performans gÃ¶sterdi?

5. **CoÄŸrafi DaÄŸÄ±lÄ±m**: Åehirler arasÄ± performans farklarÄ± neyin gÃ¶stergesi?

### Teknik Beceri DeÄŸerlendirmesi

Bu projede kullandÄ±ÄŸÄ±mÄ±z Pandas teknikleri:
- âœ… DataFrame oluÅŸturma ve manipÃ¼lasyonu
- âœ… Veri temizleme ve preprocessing
- âœ… Groupby ve aggregation iÅŸlemleri
- âœ… Pivot tablo analizi
- âœ… Zaman serisi iÅŸlemleri
- âœ… Boolean indexleme ve filtreleme
- âœ… Veri tipi dÃ¶nÃ¼ÅŸÃ¼mleri
- âœ… Ä°statistiksel analiz
- âœ… Korelasyon analizi
- âœ… Segmentasyon teknikleri

### Ä°leri Seviye GeliÅŸtirmeler

Bu projeyi ÅŸu yÃ¶nlerle geliÅŸtirebilirsiniz:

1. **GÃ¶rselleÅŸtirme**: Matplotlib/Seaborn ile grafikler
2. **Makine Ã–ÄŸrenimi**: MÃ¼ÅŸteri segmentasyonu iÃ§in clustering
3. **Tahminleme**: Gelecek satÄ±ÅŸ tahminleri
4. **Dashboard**: Streamlit/Plotly ile interaktif panel
5. **Otomasyon**: Raporlama sÃ¼reÃ§lerini otomatikleÅŸtirme

---

**ğŸ“ Tebrikler!** Bu kapsamlÄ± projede gerÃ§ek dÃ¼nya veri analizi deneyimi yaÅŸadÄ±nÄ±z. Pandas'Ä±n gÃ¼cÃ¼nÃ¼ keÅŸfederek, veriyi anlamlÄ± bilgiye dÃ¶nÃ¼ÅŸtÃ¼rmeyi Ã¶ÄŸrendiniz.

---# 9. ğŸ“ Pandas Cheat Sheet

HÄ±zlÄ± referans iÃ§in en Ã§ok kullanÄ±lan Pandas komutlarÄ± ve ipuÃ§larÄ±.

## ğŸš€ Temel Ä°mport ve Kurulum

```python
import pandas as pd
import numpy as np

# Pandas ayarlarÄ±
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_rows', 100)
```

## ğŸ“Š DataFrame OluÅŸturma

```python
# SÃ¶zlÃ¼kten DataFrame
df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})

# Liste listesinden DataFrame
df = pd.DataFrame([[1, 2], [3, 4]], columns=['A', 'B'])

# CSV'den okuma
df = pd.read_csv('dosya.csv', encoding='utf-8')

# Excel'den okuma
df = pd.read_excel('dosya.xlsx', sheet_name='Sayfa1')
```

## ğŸ” Veri KeÅŸfi

```python
# Temel bilgiler
df.shape                    # (satÄ±r, sÃ¼tun)
df.info()                   # DetaylÄ± bilgi
df.describe()               # Ä°statistikler
df.head()                   # Ä°lk 5 satÄ±r
df.tail()                   # Son 5 satÄ±r
df.columns                  # SÃ¼tun isimleri
df.dtypes                   # Veri tipleri

# Eksik veri kontrolÃ¼
df.isnull().sum()           # SÃ¼tun bazÄ±nda eksik sayÄ±
df.isnull().any()           # Eksik veri var mÄ±?

# Duplikasyon kontrolÃ¼
df.duplicated().sum()       # Duplikasyon sayÄ±sÄ±
```

## ğŸ¯ Veri SeÃ§me

```python
# SÃ¼tun seÃ§me
df['sÃ¼tun']                 # Tek sÃ¼tun (Series)
df[['sÃ¼tun1', 'sÃ¼tun2']]   # Birden fazla sÃ¼tun

# SatÄ±r seÃ§me
df.iloc[0]                  # Ä°lk satÄ±r
df.iloc[0:5]               # Ä°lk 5 satÄ±r
df.iloc[-1]                # Son satÄ±r

# Label bazlÄ± seÃ§im
df.loc[0, 'sÃ¼tun']         # Belirli satÄ±r-sÃ¼tun
df.loc[:, 'A':'C']         # SÃ¼tun aralÄ±ÄŸÄ±

# KoÅŸullu seÃ§im
df[df['A'] > 5]            # KoÅŸullu filtreleme
df[(df['A'] > 5) & (df['B'] < 10)]  # Ã‡oklu koÅŸul
df.query('A > 5 and B < 10')        # SQL-benzeri
```

## ğŸ§¹ Veri Temizleme

```python
# Eksik veri yÃ¶netimi
df.dropna()                 # Eksik satÄ±rlarÄ± sil
df.dropna(axis=1)          # Eksik sÃ¼tunlarÄ± sil
df.fillna(0)               # 0 ile doldur
df.fillna(df.mean())       # Ortalama ile doldur
df.fillna(method='ffill')  # Ã–nceki deÄŸerle doldur

# Duplikasyon
df.drop_duplicates()       # DuplikasyonlarÄ± sil

# Veri tipi dÃ¶nÃ¼ÅŸÃ¼mÃ¼
df['sÃ¼tun'].astype(int)    # Integer'a Ã§evir
pd.to_numeric(df['sÃ¼tun'], errors='coerce')  # SayÄ±ya Ã§evir
pd.to_datetime(df['tarih']) # Tarihe Ã§evir

# String iÅŸlemleri
df['sÃ¼tun'].str.upper()    # BÃ¼yÃ¼k harf
df['sÃ¼tun'].str.lower()    # KÃ¼Ã§Ã¼k harf
df['sÃ¼tun'].str.strip()    # BoÅŸluk temizle
df['sÃ¼tun'].str.replace('eski', 'yeni')  # DeÄŸiÅŸtir
```

## ğŸ“ˆ GruplandÄ±rma ve Aggregation

```python
# Basit gruplandÄ±rma
df.groupby('kategori').mean()           # Ortalama
df.groupby('kategori').sum()            # Toplam
df.groupby('kategori').count()          # SayÄ±m
df.groupby('kategori').size()           # Grup boyutu

# Ã‡oklu grup
df.groupby(['kat1', 'kat2']).mean()

# Ã–zel aggregation
df.groupby('kategori').agg({
    'sÃ¼tun1': 'mean',
    'sÃ¼tun2': ['sum', 'count']
})

# Transform
df.groupby('kategori')['deÄŸer'].transform('mean')
```

## ğŸ“‹ Pivot ve Reshape

```python
# Pivot tablo
df.pivot_table(values='deÄŸer', 
               index='satÄ±r', 
               columns='sÃ¼tun', 
               aggfunc='sum')

# Cross-tabulation
pd.crosstab(df['A'], df['B'])

# Melt (geniÅŸ â†’ uzun format)
df.melt(id_vars=['id'], 
        value_vars=['A', 'B'])

# Stack/Unstack
df.stack()                  # SÃ¼tunlarÄ± satÄ±r yap
df.unstack()               # SatÄ±rlarÄ± sÃ¼tun yap
```

## ğŸ“Š Ä°statistikler

```python
# Temel istatistikler
df.mean()                   # Ortalama
df.median()                 # Medyan
df.std()                    # Standart sapma
df.var()                    # Varyans
df.min()                    # Minimum
df.max()                    # Maksimum
df.quantile(0.25)          # Ã‡eyreklik

# Korelasyon
df.corr()                   # Korelasyon matrisi
df['A'].corr(df['B'])      # Ä°ki sÃ¼tun korelasyonu

# Value counts
df['kategori'].value_counts()           # Frekans
df['kategori'].value_counts(normalize=True)  # YÃ¼zdelik
```

## ğŸ• Zaman Serileri

```python
# Tarih oluÅŸturma
pd.date_range('2024-01-01', periods=100, freq='D')

# Tarih parÃ§alarÄ±
df['tarih'].dt.year         # YÄ±l
df['tarih'].dt.month        # Ay
df['tarih'].dt.day          # GÃ¼n
df['tarih'].dt.dayofweek    # HaftanÄ±n gÃ¼nÃ¼
df['tarih'].dt.quarter      # Ã‡eyrek

# Resample
df.resample('M').mean()     # AylÄ±k ortalama
df.resample('D').sum()      # GÃ¼nlÃ¼k toplam

# Rolling
df['deÄŸer'].rolling(7).mean()     # 7 gÃ¼nlÃ¼k hareketli ortalama
```

## ğŸ”— BirleÅŸtirme Ä°ÅŸlemleri

```python
# Concat
pd.concat([df1, df2])              # Dikey birleÅŸtirme
pd.concat([df1, df2], axis=1)      # Yatay birleÅŸtirme

# Merge (SQL-benzeri join)
pd.merge(df1, df2, on='anahtar')           # Inner join
pd.merge(df1, df2, on='anahtar', how='left')   # Left join
pd.merge(df1, df2, on='anahtar', how='outer')  # Full outer join

# Join (index bazlÄ±)
df1.join(df2)                      # Index'e gÃ¶re birleÅŸtir
```

## ğŸ’¾ Kaydetme

```python
# CSV kaydetme
df.to_csv('dosya.csv', index=False, encoding='utf-8')

# Excel kaydetme
df.to_excel('dosya.xlsx', index=False, sheet_name='Veri')

# Ã‡oklu sayfa Excel
with pd.ExcelWriter('dosya.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sayfa1')
    df2.to_excel(writer, sheet_name='Sayfa2')

# Parquet (bÃ¼yÃ¼k veriler iÃ§in)
df.to_parquet('dosya.parquet')

# JSON
df.to_json('dosya.json', orient='records')
```

## âš¡ Performans Ä°puÃ§larÄ±

```python
# Kategorik veriler iÃ§in bellek tasarrufu
df['sÃ¼tun'] = df['sÃ¼tun'].astype('category')

# Veri tipi optimizasyonu
df.select_dtypes(include=['int64']).astype('int32')

# Chunk ile bÃ¼yÃ¼k dosya okuma
for chunk in pd.read_csv('bÃ¼yÃ¼k_dosya.csv', chunksize=10000):
    process(chunk)

# Query vs Boolean indexing (bÃ¼yÃ¼k veriler iÃ§in query daha hÄ±zlÄ±)
df.query('A > 5')  # HÄ±zlÄ±
df[df['A'] > 5]    # YavaÅŸ (bÃ¼yÃ¼k veriler iÃ§in)
```

---

# 10. ğŸ”— Kaynaklar ve Ek Materyaller

## ğŸ“š Resmi DokÃ¼mantasyon

### Pandas Resmi KaynaklarÄ±
- **Pandas DokÃ¼mantasyonu**: https://pandas.pydata.org/docs/
- **Pandas Getting Started**: https://pandas.pydata.org/docs/getting_started/
- **Pandas User Guide**: https://pandas.pydata.org/docs/user_guide/
- **Pandas API Reference**: https://pandas.pydata.org/docs/reference/

### NumPy (Pandas'Ä±n temel baÄŸÄ±mlÄ±lÄ±ÄŸÄ±)
- **NumPy DokÃ¼mantasyonu**: https://numpy.org/doc/stable/
- **NumPy Quickstart**: https://numpy.org/doc/stable/user/quickstart.html

## ğŸ“– Ã–nerilen Kitaplar

### TÃ¼rkÃ§e Kaynaklar
- "Python ile Veri Analizi" - Wes McKinney
- "Pandas ile Veri ManipÃ¼lasyonu" - Ã§eÅŸitli yazarlar
- "Python Veri Bilimi KÃ¼tÃ¼phaneleri" - Jake VanderPlas

### Ä°ngilizce Kaynaklar
- "Python for Data Analysis" - Wes McKinney (Pandas'Ä±n yaratÄ±cÄ±sÄ±)
- "Pandas 1.x Cookbook" - Matt Harrison & Theodore Petrou
- "Effective Pandas" - Matt Harrison
- "Python Data Science Handbook" - Jake VanderPlas

## ğŸ“ Online Kurslar ve EÄŸitimler

### Ãœcretsiz Kaynaklar
- **Kaggle Learn - Pandas**: https://www.kaggle.com/learn/pandas
- **DataCamp Community**: Pandas temel eÄŸitimleri
- **Real Python - Pandas Tutorials**: https://realpython.com/pandas-python-explore-dataset/
- **YouTube**: "Corey Schafer Pandas Series"

### Ãœcretli Platformlar
- **DataCamp**: KapsamlÄ± Pandas eÄŸitimleri
- **Coursera**: "Python for Data Science" kurslarÄ±
- **edX**: MIT ve Harvard'dan veri bilimi kurslarÄ±
- **Udemy**: Pandas Ã¶zel kurslarÄ±

## ğŸ’» Pratik YapabileceÄŸiniz Platformlar

### Veri Seti KaynaklarÄ±
- **Kaggle Datasets**: https://www.kaggle.com/datasets
- **UCI Machine Learning Repository**: https://archive.ics.uci.edu/ml/
- **Google Dataset Search**: https://datasetsearch.research.google.com/
- **TÃœÄ°K (TÃ¼rkiye Ä°statistik Kurumu)**: https://www.tuik.gov.tr/
- **Veri.gov.tr**: TÃ¼rkiye aÃ§Ä±k veri portalÄ±

### Pratik Projeler
1. **COVID-19 veri analizi** (John Hopkins University dataset)
2. **Borsa verilerini analiz etme** (Yahoo Finance API)
3. **E-ticaret satÄ±ÅŸ verisi analizi** (Kaggle'dan)
4. **Film ve dizi veritabanÄ± analizi** (IMDb dataset)
5. **Sosyal medya trend analizi**

## ğŸ› ï¸ GeliÅŸtirme OrtamlarÄ±

### IDE ve EditÃ¶rler
- **Jupyter Notebook**: Veri analizi iÃ§in ideal
- **Jupyter Lab**: Daha geliÅŸmiÅŸ notebook ortamÄ±
- **Google Colab**: Ãœcretsiz bulut tabanlÄ± notebook
- **VS Code**: Python extension ile
- **PyCharm**: Professional Python IDE
- **Spyder**: Bilimsel Python geliÅŸtirme ortamÄ±

### Cloud Platformlar
- **Google Colab**: Ãœcretsiz GPU/TPU eriÅŸimi
- **Kaggle Notebooks**: YarÄ±ÅŸma odaklÄ± platform
- **Azure Machine Learning Studio**
- **AWS SageMaker**
- **IBM Watson Studio**

## ğŸš¨ YaygÄ±n Hata MesajlarÄ± ve Ã‡Ã¶zÃ¼mleri

| Hata MesajÄ± | Nedeni | Ã‡Ã¶zÃ¼mÃ¼ |
|-------------|--------|--------|
| `ModuleNotFoundError: No module named 'pandas'` | Pandas kurulu deÄŸil | `pip install pandas` |
| `UnicodeDecodeError` | Karakter encoding sorunu | `pd.read_csv('dosya.csv', encoding='utf-8')` |
| `KeyError: 'sÃ¼tun_adÄ±'` | SÃ¼tun mevcut deÄŸil | `df.columns` ile kontrol edin |
| `ValueError: cannot convert string to float` | String'i sayÄ±ya Ã§evirme hatasÄ± | `pd.to_numeric(df['sÃ¼tun'], errors='coerce')` |
| `SettingWithCopyWarning` | DataFrame slice Ã¼zerinde deÄŸiÅŸiklik | `.copy()` kullanÄ±n |
| `AttributeError: 'Series' object has no attribute 'reshape'` | Series/DataFrame karÄ±ÅŸÄ±klÄ±ÄŸÄ± | Tip kontrolÃ¼ yapÄ±n |
| `ValueError: Length mismatch` | SÃ¼tun uzunluklarÄ± farklÄ± | UzunluklarÄ± eÅŸitleyin |
| `TypeError: unhashable type: 'list'` | Liste'yi dictionary key olarak kullanma | Tuple kullanÄ±n |
| `IndexError: single positional indexer is out-of-bounds` | Index sÄ±nÄ±rlarÄ± aÅŸÄ±mÄ± | Index aralÄ±ÄŸÄ±nÄ± kontrol edin |
| `ParserError` | CSV parsing hatasÄ± | `error_bad_lines=False` ekleyin |

## ğŸ”§ Troubleshooting Rehberi

### YaygÄ±n Problemler ve Ã‡Ã¶zÃ¼mleri

#### 1. Bellek SorunlarÄ±
```python
# Problem: MemoryError
# Ã‡Ã¶zÃ¼m: Chunk'lar halinde okuyun
for chunk in pd.read_csv('bÃ¼yÃ¼k_dosya.csv', chunksize=10000):
    process(chunk)

# Veri tiplerini optimize edin
df['kategori'] = df['kategori'].astype('category')
df['sayÄ±'] = df['sayÄ±'].astype('int32')  # int64 yerine
```

#### 2. Performans SorunlarÄ±
```python
# Problem: YavaÅŸ iÅŸlemler
# Ã‡Ã¶zÃ¼m 1: Vectorized iÅŸlemler kullanÄ±n
df['yeni'] = df['A'] + df['B']  # Ä°yi
df['yeni'] = df.apply(lambda x: x['A'] + x['B'], axis=1)  # KÃ¶tÃ¼

# Ã‡Ã¶zÃ¼m 2: Query kullanÄ±n (bÃ¼yÃ¼k veriler iÃ§in)
df.query('A > 5')  # HÄ±zlÄ±
df[df['A'] > 5]    # YavaÅŸ
```

#### 3. Index Problemleri
```python
# Problem: Index karmaÅŸasÄ±
# Ã‡Ã¶zÃ¼m: Reset index
df = df.reset_index(drop=True)

# MultiIndex sorunlarÄ±
df = df.droplevel(level=0, axis=1)  # SÃ¼tun seviyesi sil
```

#### 4. Tarih SorunlarÄ±
```python
# Problem: Tarih parsing hatalarÄ±
# Ã‡Ã¶zÃ¼m: Manuel parsing
df['tarih'] = pd.to_datetime(df['tarih'], format='%d/%m/%Y', errors='coerce')

# Zaman dilimi sorunlarÄ±
df['tarih'] = df['tarih'].dt.tz_localize('UTC').dt.tz_convert('Europe/Istanbul')
```

## ğŸ“± Mobil ve Web UygulamalarÄ±

### Dashboard ve GÃ¶rselleÅŸtirme
- **Streamlit**: HÄ±zlÄ± web app geliÅŸtirme
- **Dash (Plotly)**: Ä°nteraktif dashboard'lar
- **Panel (HoloViz)**: Esnek veri uygulamalarÄ±
- **VoilÃ **: Jupyter notebook'larÄ± web app'e Ã§evirme

### GÃ¶rselleÅŸtirme KÃ¼tÃ¼phaneleri
```python
# Matplotlib (temel)
import matplotlib.pyplot as plt
df.plot()

# Seaborn (istatistiksel)
import seaborn as sns
sns.heatmap(df.corr())

# Plotly (interaktif)
import plotly.express as px
px.scatter(df, x='A', y='B')

# Altair (grammar of graphics)
import altair as alt
alt.Chart(df).mark_circle().encode(x='A', y='B')
```

## ğŸ¯ Sonraki AdÄ±mlar

### Ä°leri Seviye Konular
1. **Pandas ile Makine Ã–ÄŸrenimi entegrasyonu** (scikit-learn)
2. **BÃ¼yÃ¼k veri iÅŸleme** (Dask, Modin)
3. **VeritabanÄ± entegrasyonu** (SQLAlchemy)
4. **API'lerle veri Ã§ekme** (requests, pandas-datareader)
5. **Web scraping ile veri toplama** (BeautifulSoup, Scrapy)

### DiÄŸer Ä°lgili KÃ¼tÃ¼phaneler
- **NumPy**: SayÄ±sal hesaplamalar
- **SciPy**: Bilimsel hesaplamalar
- **scikit-learn**: Makine Ã¶ÄŸrenimi
- **statsmodels**: Ä°statistiksel modelleme
- **matplotlib/seaborn**: GÃ¶rselleÅŸtirme
- **requests**: HTTP istekleri
- **SQLAlchemy**: VeritabanÄ± ORM

---

## ğŸ’¡ Son Ä°puÃ§larÄ±

### En Ä°yi Pratikler
1. **ğŸ“ Kodunuzu dokÃ¼mante edin**: Yorumlar ve docstring'ler yazÄ±n
2. **ğŸ§ª KÃ¼Ã§Ã¼k Ã¶rneklerle test edin**: BÃ¼yÃ¼k veriler Ã¼zerinde Ã§alÄ±ÅŸmadan Ã¶nce
3. **ğŸ’¾ DÃ¼zenli olarak kaydedin**: Ã–zellikle uzun analiz sÃ¼reÃ§lerinde
4. **ğŸ” Veriyi anlayÄ±n**: Ä°statistikleri ve daÄŸÄ±lÄ±mlarÄ± inceleyin
5. **âš¡ PerformansÄ± izleyin**: `%%time` ile kod parÃ§alarÄ±nÄ± Ã¶lÃ§Ã¼n

### Hata AyÄ±klama Ä°puÃ§larÄ±
```python
# Debug iÃ§in kullanÄ±ÅŸlÄ± komutlar
print(df.shape)                    # Boyut kontrolÃ¼
print(df.dtypes)                   # Tip kontrolÃ¼
print(df.isnull().sum())           # Eksik veri kontrolÃ¼
print(df.describe())               # Ä°statistik Ã¶zeti
df.head()                          # Veriyi gÃ¶rme
```

**ğŸŠ Tebrikler!** Bu eÄŸitim dokÃ¼manÄ±nÄ± tamamladÄ±nÄ±z. ArtÄ±k Pandas ile gÃ¼venli bir ÅŸekilde veri analizi yapabilirsiniz!

---