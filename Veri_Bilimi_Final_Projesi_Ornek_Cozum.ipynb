{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Ticaret MÃ¼ÅŸteri DavranÄ±ÅŸ Analizi ve SatÄ±ÅŸ Tahmini\n",
    "\n",
    "## Proje HakkÄ±nda\n",
    "Bu notebook, e-ticaret verilerini kullanarak mÃ¼ÅŸteri davranÄ±ÅŸ analizi, segmentasyon, satÄ±ÅŸ tahmini ve mÃ¼ÅŸteri sÄ±nÄ±flandÄ±rmasÄ± gerÃ§ekleÅŸtirmektedir.\n",
    "\n",
    "### Ä°Ã§erik:\n",
    "1. **Veri YÃ¼kleme ve HazÄ±rlÄ±k**\n",
    "2. **KeÅŸifsel Veri Analizi (EDA)**\n",
    "3. **Veri Ã–n Ä°ÅŸleme**\n",
    "4. **MÃ¼ÅŸteri Segmentasyonu (KÃ¼meleme)**\n",
    "5. **SatÄ±ÅŸ Tahmini (Regresyon)**\n",
    "6. **MÃ¼ÅŸteri DavranÄ±ÅŸ SÄ±nÄ±flandÄ±rmasÄ±**\n",
    "7. **SonuÃ§lar ve Ã–neriler**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. KÃ¼tÃ¼phaneler ve Veri YÃ¼kleme\n",
    "\n",
    "Bu bÃ¶lÃ¼mde projemiz iÃ§in gerekli Python kÃ¼tÃ¼phanelerini yÃ¼klÃ¼yor ve veri setlerini okuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phanelerin yÃ¼klenmesi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib best practice setup\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\" TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setlerinin yÃ¼klenmesi\n",
    "try:\n",
    "    # E-ticaret veri setleri\n",
    "    customers_df = pd.read_csv('data/customers.csv')\n",
    "    products_df = pd.read_csv('data/products.csv')\n",
    "    transactions_df = pd.read_csv('data/transactions.csv')\n",
    "    interactions_df = pd.read_csv('data/interactions.csv')\n",
    "    \n",
    "    print(\" TÃ¼m veri setleri baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "    \n",
    "    # Veri seti bilgileri\n",
    "    datasets = {\n",
    "        'MÃ¼ÅŸteriler': customers_df,\n",
    "        'ÃœrÃ¼nler': products_df,\n",
    "        'Ä°ÅŸlemler': transactions_df,\n",
    "        'EtkileÅŸimler': interactions_df\n",
    "    }\n",
    "    \n",
    "    for name, df in datasets.items():\n",
    "        print(f\"\\n {name} Dataset:\")\n",
    "        print(f\"  - Boyut: {df.shape}\")\n",
    "        print(f\"  - SÃ¼tunlar: {list(df.columns)}\")\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\" Veri dosyasÄ± bulunamadÄ±: {e}\")\n",
    "    print(\"Ã–rnek veri oluÅŸturuluyor...\")\n",
    "    \n",
    "    # Ã–rnek veri oluÅŸturma fonksiyonu\n",
    "    def create_sample_data():\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # MÃ¼ÅŸteri verisi\n",
    "        customers_data = {\n",
    "            'customer_id': range(1, 1001),\n",
    "            'age': np.random.randint(18, 80, 1000),\n",
    "            'gender': np.random.choice(['M', 'F'], 1000),\n",
    "            'city': np.random.choice(['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa'], 1000),\n",
    "            'registration_date': pd.date_range('2020-01-01', periods=1000, freq='D'),\n",
    "            'total_spent': np.random.uniform(100, 5000, 1000),\n",
    "            'purchase_frequency': np.random.randint(1, 50, 1000)\n",
    "        }\n",
    "        \n",
    "        # ÃœrÃ¼n verisi\n",
    "        products_data = {\n",
    "            'product_id': range(1, 501),\n",
    "            'product_name': [f'ÃœrÃ¼n_{i}' for i in range(1, 501)],\n",
    "            'category': np.random.choice(['Elektronik', 'Giyim', 'Ev & YaÅŸam', 'Kitap', 'Spor'], 500),\n",
    "            'price': np.random.uniform(10, 1000, 500),\n",
    "            'brand': np.random.choice(['Marka_A', 'Marka_B', 'Marka_C', 'Marka_D'], 500)\n",
    "        }\n",
    "        \n",
    "        # Ä°ÅŸlem verisi\n",
    "        transactions_data = {\n",
    "            'transaction_id': range(1, 5001),\n",
    "            'customer_id': np.random.randint(1, 1001, 5000),\n",
    "            'product_id': np.random.randint(1, 501, 5000),\n",
    "            'quantity': np.random.randint(1, 10, 5000),\n",
    "            'price': np.random.uniform(10, 1000, 5000),\n",
    "            'discount': np.random.uniform(0, 0.3, 5000),\n",
    "            'transaction_date': pd.date_range('2023-01-01', periods=5000, freq='6H'),\n",
    "            'payment_method': np.random.choice(['Kredi KartÄ±', 'Debit Kart', 'Havale/EFT', 'KapÄ±da Ã–deme'], 5000)\n",
    "        }\n",
    "        \n",
    "        # EtkileÅŸim verisi\n",
    "        interactions_data = {\n",
    "            'interaction_id': range(1, 10001),\n",
    "            'customer_id': np.random.randint(1, 1001, 10000),\n",
    "            'product_id': np.random.randint(1, 501, 10000),\n",
    "            'interaction_type': np.random.choice(['view', 'click', 'add_to_cart', 'wishlist'], 10000),\n",
    "            'interaction_date': pd.date_range('2023-01-01', periods=10000, freq='3H')\n",
    "        }\n",
    "        \n",
    "        return (\n",
    "            pd.DataFrame(customers_data),\n",
    "            pd.DataFrame(products_data),\n",
    "            pd.DataFrame(transactions_data),\n",
    "            pd.DataFrame(interactions_data)\n",
    "        )\n",
    "    \n",
    "    # Ã–rnek verileri oluÅŸtur\n",
    "    customers_df, products_df, transactions_df, interactions_df = create_sample_data()\n",
    "    print(\" Ã–rnek veriler oluÅŸturuldu!\")\n",
    "    \n",
    "    # DataFrame'leri kaydet\n",
    "    customers_df.to_csv('data/customers.csv', index=False)\n",
    "    products_df.to_csv('data/products.csv', index=False)\n",
    "    transactions_df.to_csv('data/transactions.csv', index=False)\n",
    "    interactions_df.to_csv('data/interactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KeÅŸifsel Veri Analizi (EDA)\n",
    "\n",
    "Bu bÃ¶lÃ¼mde veri setlerimizi detaylÄ± olarak inceleyerek temel istatistikleri, daÄŸÄ±lÄ±mlarÄ± ve iliÅŸkileri analiz edeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setlerinin genel bilgileri\n",
    "print(\"=== VERÄ° SETÄ° GENEL BÄ°LGÄ°LERÄ° ===\\n\")\n",
    "\n",
    "datasets_info = {\n",
    "    'MÃ¼ÅŸteriler': customers_df,\n",
    "    'ÃœrÃ¼nler': products_df,\n",
    "    'Ä°ÅŸlemler': transactions_df,\n",
    "    'EtkileÅŸimler': interactions_df\n",
    "}\n",
    "\n",
    "for name, df in datasets_info.items():\n",
    "    print(f\" {name} Dataset:\")\n",
    "    print(f\"  Boyut: {df.shape}\")\n",
    "    print(f\"  Bellek KullanÄ±mÄ±: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"  Eksik DeÄŸerler: {df.isnull().sum().sum()}\")\n",
    "    print(f\"  SÃ¼tunlar: {list(df.columns)}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel istatistikler - MÃ¼ÅŸteri verisi\n",
    "print(\"=== MÃœÅžTERÄ° VERÄ°SÄ° TEMEL Ä°STATÄ°STÄ°KLERÄ° ===\")\n",
    "print(\"\\n SayÄ±sal DeÄŸiÅŸkenler:\")\n",
    "print(customers_df.describe())\n",
    "\n",
    "print(\"\\n Kategorik DeÄŸiÅŸkenler:\")\n",
    "print(\"\\nCinsiyet DaÄŸÄ±lÄ±mÄ±:\")\n",
    "print(customers_df['gender'].value_counts())\n",
    "\n",
    "print(\"\\nÅžehir DaÄŸÄ±lÄ±mÄ±:\")\n",
    "print(customers_df['city'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÃ¼ÅŸteri demografik analizi\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('MÃ¼ÅŸteri Demografik Analizi', fontsize=16, fontweight='bold')\n",
    "\n",
    "# YaÅŸ daÄŸÄ±lÄ±mÄ±\n",
    "axes[0,0].hist(customers_df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('YaÅŸ DaÄŸÄ±lÄ±mÄ±')\n",
    "axes[0,0].set_xlabel('YaÅŸ')\n",
    "axes[0,0].set_ylabel('Frekans')\n",
    "\n",
    "# Cinsiyet daÄŸÄ±lÄ±mÄ±\n",
    "gender_counts = customers_df['gender'].value_counts()\n",
    "axes[0,1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0,1].set_title('Cinsiyet DaÄŸÄ±lÄ±mÄ±')\n",
    "\n",
    "# Åžehir daÄŸÄ±lÄ±mÄ±\n",
    "city_counts = customers_df['city'].value_counts()\n",
    "axes[1,0].bar(city_counts.index, city_counts.values, color='lightcoral')\n",
    "axes[1,0].set_title('Åžehir DaÄŸÄ±lÄ±mÄ±')\n",
    "axes[1,0].set_xlabel('Åžehir')\n",
    "axes[1,0].set_ylabel('MÃ¼ÅŸteri SayÄ±sÄ±')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Toplam harcama daÄŸÄ±lÄ±mÄ±\n",
    "axes[1,1].hist(customers_df['total_spent'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1,1].set_title('Toplam Harcama DaÄŸÄ±lÄ±mÄ±')\n",
    "axes[1,1].set_xlabel('Toplam Harcama (â‚º)')\n",
    "axes[1,1].set_ylabel('Frekans')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Korelasyon matrisi\n",
    "plt.figure(figsize=(10, 8))\n",
    "numeric_cols = customers_df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = customers_df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('MÃ¼ÅŸteri Verisi Korelasyon Matrisi')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÃœrÃ¼n analizi\n",
    "print(\"=== ÃœRÃœN VERÄ°SÄ° ANALÄ°ZÄ° ===\")\n",
    "print(\"\\n Kategori DaÄŸÄ±lÄ±mÄ±:\")\n",
    "print(products_df['category'].value_counts())\n",
    "\n",
    "print(\"\\n Fiyat Ä°statistikleri:\")\n",
    "print(products_df['price'].describe())\n",
    "\n",
    "# ÃœrÃ¼n kategorileri ve fiyat analizi\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Kategori daÄŸÄ±lÄ±mÄ±\n",
    "category_counts = products_df['category'].value_counts()\n",
    "axes[0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "axes[0].set_title('ÃœrÃ¼n Kategorisi DaÄŸÄ±lÄ±mÄ±')\n",
    "\n",
    "# Kategoriye gÃ¶re fiyat daÄŸÄ±lÄ±mÄ±\n",
    "products_df.boxplot(column='price', by='category', ax=axes[1])\n",
    "axes[1].set_title('Kategoriye GÃ¶re Fiyat DaÄŸÄ±lÄ±mÄ±')\n",
    "axes[1].set_xlabel('Kategori')\n",
    "axes[1].set_ylabel('Fiyat (â‚º)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ä°ÅŸlem verisi analizi\n",
    "print(\"=== Ä°ÅžLEM VERÄ°SÄ° ANALÄ°ZÄ° ===\")\n",
    "\n",
    "# Tarih formatÄ±nÄ± dÃ¼zenle\n",
    "transactions_df['transaction_date'] = pd.to_datetime(transactions_df['transaction_date'])\n",
    "transactions_df['month'] = transactions_df['transaction_date'].dt.month\n",
    "transactions_df['day_of_week'] = transactions_df['transaction_date'].dt.dayofweek\n",
    "transactions_df['hour'] = transactions_df['transaction_date'].dt.hour\n",
    "\n",
    "print(\"\\n Ã–deme YÃ¶ntemi DaÄŸÄ±lÄ±mÄ±:\")\n",
    "print(transactions_df['payment_method'].value_counts())\n",
    "\n",
    "print(\"\\n Miktar Ä°statistikleri:\")\n",
    "print(transactions_df['quantity'].describe())\n",
    "\n",
    "# Ä°ÅŸlem trendleri\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Ä°ÅŸlem Verisi Analizi', fontsize=16)\n",
    "\n",
    "# Ã–deme yÃ¶ntemi daÄŸÄ±lÄ±mÄ±\n",
    "payment_counts = transactions_df['payment_method'].value_counts()\n",
    "axes[0,0].pie(payment_counts.values, labels=payment_counts.index, autopct='%1.1f%%')\n",
    "axes[0,0].set_title('Ã–deme YÃ¶ntemi DaÄŸÄ±lÄ±mÄ±')\n",
    "\n",
    "# AylÄ±k satÄ±ÅŸ trendi\n",
    "monthly_sales = transactions_df.groupby('month')['price'].sum()\n",
    "axes[0,1].plot(monthly_sales.index, monthly_sales.values, marker='o')\n",
    "axes[0,1].set_title('AylÄ±k SatÄ±ÅŸ Trendi')\n",
    "axes[0,1].set_xlabel('Ay')\n",
    "axes[0,1].set_ylabel('Toplam SatÄ±ÅŸ (â‚º)')\n",
    "\n",
    "# HaftanÄ±n gÃ¼nlerine gÃ¶re satÄ±ÅŸ\n",
    "daily_sales = transactions_df.groupby('day_of_week')['price'].sum()\n",
    "day_names = ['Pazartesi', 'SalÄ±', 'Ã‡arÅŸamba', 'PerÅŸembe', 'Cuma', 'Cumartesi', 'Pazar']\n",
    "axes[1,0].bar(range(7), daily_sales.values)\n",
    "axes[1,0].set_xticks(range(7))\n",
    "axes[1,0].set_xticklabels([d[:3] for d in day_names])\n",
    "axes[1,0].set_title('HaftanÄ±n GÃ¼nlerine GÃ¶re SatÄ±ÅŸ')\n",
    "axes[1,0].set_ylabel('Toplam SatÄ±ÅŸ (â‚º)')\n",
    "\n",
    "# Saatlik satÄ±ÅŸ daÄŸÄ±lÄ±mÄ±\n",
    "hourly_sales = transactions_df.groupby('hour')['price'].sum()\n",
    "axes[1,1].plot(hourly_sales.index, hourly_sales.values, marker='o')\n",
    "axes[1,1].set_title('Saatlik SatÄ±ÅŸ DaÄŸÄ±lÄ±mÄ±')\n",
    "axes[1,1].set_xlabel('Saat')\n",
    "axes[1,1].set_ylabel('Toplam SatÄ±ÅŸ (â‚º)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EtkileÅŸim verisi analizi\n",
    "print(\"=== ETKÄ°LEÅžÄ°M VERÄ°SÄ° ANALÄ°ZÄ° ===\")\n",
    "\n",
    "# EtkileÅŸim tarihlerini dÃ¼zenle\n",
    "interactions_df['interaction_date'] = pd.to_datetime(interactions_df['interaction_date'])\n",
    "interactions_df['interaction_hour'] = interactions_df['interaction_date'].dt.hour\n",
    "\n",
    "print(\"\\n EtkileÅŸim TÃ¼rÃ¼ DaÄŸÄ±lÄ±mÄ±:\")\n",
    "interaction_counts = interactions_df['interaction_type'].value_counts()\n",
    "print(interaction_counts)\n",
    "\n",
    "# EtkileÅŸim analizi gÃ¶rselleÅŸtirme\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# EtkileÅŸim tÃ¼rÃ¼ daÄŸÄ±lÄ±mÄ±\n",
    "axes[0].pie(interaction_counts.values, labels=interaction_counts.index, autopct='%1.1f%%')\n",
    "axes[0].set_title('EtkileÅŸim TÃ¼rÃ¼ DaÄŸÄ±lÄ±mÄ±')\n",
    "\n",
    "# Saatlik etkileÅŸim daÄŸÄ±lÄ±mÄ±\n",
    "hourly_interactions = interactions_df.groupby('interaction_hour').size()\n",
    "axes[1].plot(hourly_interactions.index, hourly_interactions.values, marker='o', color='orange')\n",
    "axes[1].set_title('Saatlik EtkileÅŸim DaÄŸÄ±lÄ±mÄ±')\n",
    "axes[1].set_xlabel('Saat')\n",
    "axes[1].set_ylabel('EtkileÅŸim SayÄ±sÄ±')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Veri Ã–n Ä°ÅŸleme\n",
    "\n",
    "Bu bÃ¶lÃ¼mde verilerimizi modelleme iÃ§in hazÄ±rlayacaÄŸÄ±z: eksik deÄŸerleri doldurma, aykÄ±rÄ± deÄŸerleri tespit etme, Ã¶zellik mÃ¼hendisliÄŸi ve normalizasyon iÅŸlemleri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik deÄŸer analizi\n",
    "print(\"=== EKSÄ°K DEÄžER ANALÄ°ZÄ° ===\\n\")\n",
    "\n",
    "for name, df in datasets_info.items():\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percent = (missing_values / len(df)) * 100\n",
    "    \n",
    "    if missing_values.sum() > 0:\n",
    "        print(f\" {name} - Eksik DeÄŸerler:\")\n",
    "        for col in df.columns:\n",
    "            if missing_values[col] > 0:\n",
    "                print(f\"  {col}: {missing_values[col]} ({missing_percent[col]:.1f}%)\")\n",
    "    else:\n",
    "        print(f\" {name} - Eksik deÄŸer yok\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik deÄŸerleri doldurma (eÄŸer varsa)\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"Eksik deÄŸerleri uygun stratejilerle doldur\"\"\"\n",
    "    df_filled = df.copy()\n",
    "    \n",
    "    # SayÄ±sal deÄŸiÅŸkenler iÃ§in median\n",
    "    numeric_cols = df_filled.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if df_filled[col].isnull().sum() > 0:\n",
    "            df_filled[col].fillna(df_filled[col].median(), inplace=True)\n",
    "    \n",
    "    # Kategorik deÄŸiÅŸkenler iÃ§in mode\n",
    "    categorical_cols = df_filled.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df_filled[col].isnull().sum() > 0:\n",
    "            df_filled[col].fillna(df_filled[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "# Eksik deÄŸerleri iÅŸle\n",
    "customers_df = handle_missing_values(customers_df)\n",
    "products_df = handle_missing_values(products_df)\n",
    "transactions_df = handle_missing_values(transactions_df)\n",
    "interactions_df = handle_missing_values(interactions_df)\n",
    "\n",
    "print(\" Eksik deÄŸerler dolduruldu!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AykÄ±rÄ± deÄŸer tespiti ve temizleme\n",
    "def detect_outliers(df, column, method='iqr'):\n",
    "    \"\"\"AykÄ±rÄ± deÄŸerleri tespit et\"\"\"\n",
    "    if method == 'iqr':\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    \n",
    "    elif method == 'zscore':\n",
    "        z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n",
    "        outliers = df[z_scores > 3]\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "# AykÄ±rÄ± deÄŸer analizi\n",
    "print(\"=== AYKIRI DEÄžER ANALÄ°ZÄ° ===\\n\")\n",
    "\n",
    "# SayÄ±sal deÄŸiÅŸkenler iÃ§in aykÄ±rÄ± deÄŸer kontrolÃ¼\n",
    "numeric_columns = ['age', 'total_spent', 'purchase_frequency', 'price', 'quantity', 'discount']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in transactions_df.columns or col in customers_df.columns or col in products_df.columns:\n",
    "        # Uygun dataframe'i seÃ§\n",
    "        if col in customers_df.columns:\n",
    "            df = customers_df\n",
    "        elif col in transactions_df.columns:\n",
    "            df = transactions_df\n",
    "        elif col in products_df.columns:\n",
    "            df = products_df\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        outliers = detect_outliers(df, col)\n",
    "        print(f\" {col}: {len(outliers)} aykÄ±rÄ± deÄŸer tespit edildi\")\n",
    "        \n",
    "        if len(outliers) > 0:\n",
    "            # AykÄ±rÄ± deÄŸerleri gÃ¶rselleÅŸtir\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.boxplot(df[col])\n",
    "            plt.title(f'{col} - Box Plot')\n",
    "            plt.ylabel(col)\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.hist(df[col], bins=30, alpha=0.7)\n",
    "            plt.title(f'{col} - Histogram')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frekans')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–zellik MÃ¼hendisliÄŸi\n",
    "print(\"=== Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ° ===\\n\")\n",
    "\n",
    "# 1. RFM Analizi (Recency, Frequency, Monetary)\n",
    "def calculate_rfm(df_transactions, df_customers):\n",
    "    \"\"\"RFM analizini hesapla\"\"\"\n",
    "    \n",
    "    # En son iÅŸlem tarihi\n",
    "    max_date = df_transactions['transaction_date'].max()\n",
    "    \n",
    "    # MÃ¼ÅŸteri baÅŸÄ±na RFM hesapla\n",
    "    rfm = df_transactions.groupby('customer_id').agg({\n",
    "        'transaction_date': 'max',  # Recency: Son iÅŸlem tarihi\n",
    "        'transaction_id': 'count',  # Frequency: Ä°ÅŸlem sayÄ±sÄ±\n",
    "        'price': 'sum'              # Monetary: Toplam harcama\n",
    "    }).reset_index()\n",
    "    \n",
    "    rfm.columns = ['customer_id', 'last_purchase_date', 'frequency', 'monetary']\n",
    "    \n",
    "    # Recency'yi gÃ¼n olarak hesapla\n",
    "    rfm['recency'] = (max_date - rfm['last_purchase_date']).dt.days\n",
    "    \n",
    "    # MÃ¼ÅŸteri verileriyle birleÅŸtir\n",
    "    rfm = rfm.merge(df_customers[['customer_id', 'age', 'gender', 'city']], on='customer_id', how='left')\n",
    "    \n",
    "    return rfm\n",
    "\n",
    "# RFM hesapla\n",
    "rfm_data = calculate_rfm(transactions_df, customers_df)\n",
    "print(\"RFM Analizi tamamlandÄ±!\")\n",
    "print(f\"RFM verisi boyutu: {rfm_data.shape}\")\n",
    "print(\"\\nRFM Ä°statistikleri:\")\n",
    "print(rfm_data[['recency', 'frequency', 'monetary']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MÃ¼ÅŸteri YaÅŸam Boyu DeÄŸeri (CLV) Hesaplama\n",
    "def calculate_clv(rfm_df, discount_rate=0.01):\n",
    "    \"\"\"MÃ¼ÅŸteri YaÅŸam Boyu DeÄŸerini hesapla\"\"\"\n",
    "    \n",
    "    # Ortalama satÄ±n alma sÄ±klÄ±ÄŸÄ± (aylÄ±k)\n",
    "    avg_purchase_frequency = rfm_df['frequency'] / 12  # 12 ay varsayÄ±mÄ±\n",
    "    \n",
    "    # Ortalama sipariÅŸ deÄŸeri\n",
    "    avg_order_value = rfm_df['monetary'] / rfm_df['frequency']\n",
    "    \n",
    "    # YaÅŸam boyu deÄŸer (basit formÃ¼l)\n",
    "    clv = avg_order_value * avg_purchase_frequency * (1 / discount_rate)\n",
    "    \n",
    "    rfm_df['clv'] = clv\n",
    "    rfm_df['avg_order_value'] = avg_order_value\n",
    "    rfm_df['avg_purchase_frequency'] = avg_purchase_frequency\n",
    "    \n",
    "    return rfm_df\n",
    "\n",
    "# CLV hesapla\n",
    "rfm_data = calculate_clv(rfm_data)\n",
    "\n",
    "print(\" CLV Hesaplama tamamlandÄ±!\")\n",
    "print(\"\\nCLV Ä°statistikleri:\")\n",
    "print(rfm_data[['clv', 'avg_order_value', 'avg_purchase_frequency']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. MÃ¼ÅŸteri segmentasyonu iÃ§in kategorik deÄŸiÅŸkenleri encode etme\n",
    "def encode_categorical_features(df):\n",
    "    \"\"\"Kategorik deÄŸiÅŸkenleri encode et\"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    # Gender encoding\n",
    "    df_encoded['gender_encoded'] = df_encoded['gender'].map({'M': 1, 'F': 0})\n",
    "    \n",
    "    # City encoding (Label Encoding)\n",
    "    le_city = LabelEncoder()\n",
    "    df_encoded['city_encoded'] = le_city.fit_transform(df_encoded['city'])\n",
    "    \n",
    "    return df_encoded, le_city\n",
    "\n",
    "# Kategorik deÄŸiÅŸkenleri encode et\n",
    "rfm_encoded, city_encoder = encode_categorical_features(rfm_data)\n",
    "\n",
    "print(\" Kategorik deÄŸiÅŸkenler encode edildi!\")\n",
    "print(f\"\\nÅžehir encoding haritasÄ±:\")\n",
    "for i, city in enumerate(city_encoder.classes_):\n",
    "    print(f\"  {city}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Veri normalizasyonu/Ã¶lÃ§ekleme\n",
    "def scale_features(df, feature_columns):\n",
    "    \"\"\"Ã–zellikleri Ã¶lÃ§ekle\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # Ã–lÃ§eklenecek Ã¶zellikler\n",
    "    scaled_features = scaler.fit_transform(df[feature_columns])\n",
    "    \n",
    "    # Scaled features'larÄ± DataFrame'e ekle\n",
    "    for i, col in enumerate(feature_columns):\n",
    "        df_scaled[f'{col}_scaled'] = scaled_features[:, i]\n",
    "    \n",
    "    return df_scaled, scaler\n",
    "\n",
    "# Ã–lÃ§eklenecek Ã¶zellikler\n",
    "features_to_scale = ['age', 'recency', 'frequency', 'monetary', 'clv', 'avg_order_value']\n",
    "\n",
    "# Ã–zellikleri Ã¶lÃ§ekle\n",
    "rfm_scaled, feature_scaler = scale_features(rfm_encoded, features_to_scale)\n",
    "\n",
    "print(\" Veri normalizasyonu tamamlandÄ±!\")\n",
    "print(\"\\nÃ–lÃ§eklenmiÅŸ Ã¶zelliklerin istatistikleri:\")\n",
    "print(rfm_scaled[[f'{col}_scaled' for col in features_to_scale]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HazÄ±rlanan verinin final kontrolÃ¼\n",
    "print(\"=== HAZIRLANAN VERÄ° KONTROLÃœ ===\\n\")\n",
    "\n",
    "print(f\"Final RFM verisi boyutu: {rfm_scaled.shape}\")\n",
    "print(f\"SÃ¼tunlar: {list(rfm_scaled.columns)}\")\n",
    "print(f\"Eksik deÄŸerler: {rfm_scaled.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nSon birkaÃ§ satÄ±r:\")\n",
    "print(rfm_scaled.head())\n",
    "\n",
    "# Final veri setini kaydet\n",
    "rfm_scaled.to_csv('data/processed_rfm_data.csv', index=False)\n",
    "print(\"\\n Ä°ÅŸlenmiÅŸ veri kaydedildi: data/processed_rfm_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MÃ¼ÅŸteri Segmentasyonu (KÃ¼meleme)\n",
    "\n",
    "Bu bÃ¶lÃ¼mde K-Means algoritmasÄ± kullanarak mÃ¼ÅŸterileri segmentlere ayÄ±racaÄŸÄ±z ve optimal cluster sayÄ±sÄ±nÄ± belirleyeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal cluster sayÄ±sÄ±nÄ± belirleme\n",
    "print(\"=== KÃœMELEME ANALÄ°ZÄ° ===\\n\")\n",
    "\n",
    "# KÃ¼meleme iÃ§in Ã¶zellikler\n",
    "clustering_features = ['recency_scaled', 'frequency_scaled', 'monetary_scaled', 'clv_scaled', 'age_scaled']\n",
    "X_clustering = rfm_scaled[clustering_features]\n",
    "\n",
    "print(f\"KÃ¼meleme iÃ§in kullanÄ±lacak Ã¶zellikler: {clustering_features}\")\n",
    "print(f\"Veri boyutu: {X_clustering.shape}\")\n",
    "\n",
    "# Elbow Method\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_clustering)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_clustering, kmeans.labels_))\n",
    "\n",
    "# Elbow Method gÃ¶rselleÅŸtirme\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Elbow plot\n",
    "ax1.plot(K_range, inertias, marker='o')\n",
    "ax1.set_title('Elbow Method (Within-Cluster Sum of Squares)')\n",
    "ax1.set_xlabel('Cluster SayÄ±sÄ± (k)')\n",
    "ax1.set_ylabel('WCSS')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Silhouette score plot\n",
    "ax2.plot(K_range, silhouette_scores, marker='s', color='orange')\n",
    "ax2.set_title('Silhouette Score')\n",
    "ax2.set_xlabel('Cluster SayÄ±sÄ± (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# En iyi k deÄŸerini bul\n",
    "best_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\n En iyi cluster sayÄ±sÄ± (Silhouette Score'a gÃ¶re): {best_k}\")\n",
    "print(f\"En yÃ¼ksek Silhouette Score: {max(silhouette_scores):.3f}\")\n",
    "\n",
    "# Tablo olarak gÃ¶ster\n",
    "results_df = pd.DataFrame({\n",
    "    'K': K_range,\n",
    "    'WCSS': inertias,\n",
    "    'Silhouette_Score': silhouette_scores\n",
    "})\n",
    "print(\"\\nKÃ¼meleme SonuÃ§larÄ±:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal k ile final kÃ¼meleme\n",
    "print(f\"=== K={best_k} Ä°LE KÃœMELEME ===\\n\")\n",
    "\n",
    "# Final K-Means model\n",
    "final_kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "cluster_labels = final_kmeans.fit_predict(X_clustering)\n",
    "\n",
    "# Cluster etiketlerini veriye ekle\n",
    "rfm_scaled['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"KÃ¼me daÄŸÄ±lÄ±mÄ±:\")\n",
    "cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
    "for i, count in cluster_counts.items():\n",
    "    print(f\"  Cluster {i}: {count} mÃ¼ÅŸteri (%{count/len(cluster_labels)*100:.1f})\")\n",
    "\n",
    "# Cluster merkezleri\n",
    "cluster_centers = final_kmeans.cluster_centers_\n",
    "centers_df = pd.DataFrame(cluster_centers, columns=clustering_features)\n",
    "centers_df['cluster'] = range(best_k)\n",
    "\n",
    "print(\"\\nCluster Merkezleri (Ã¶lÃ§eklenmiÅŸ deÄŸerler):\")\n",
    "print(centers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment analizi ve yorumlama\n",
    "print(\"=== SEGMENT ANALÄ°ZÄ° VE YORUMLAMA ===\\n\")\n",
    "\n",
    "# Her cluster'Ä±n Ã¶zelliklerini analiz et\n",
    "cluster_analysis = rfm_scaled.groupby('cluster').agg({\n",
    "    'age': 'mean',\n",
    "    'recency': 'mean',\n",
    "    'frequency': 'mean',\n",
    "    'monetary': 'mean',\n",
    "    'clv': 'mean',\n",
    "    'avg_order_value': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Cluster Ã–zellikleri:\")\n",
    "print(cluster_analysis)\n",
    "\n",
    "# Segment isimlendirme ve yorumlama\n",
    "segment_names = {}\n",
    "for cluster_id in range(best_k):\n",
    "    cluster_data = cluster_analysis.loc[cluster_id]\n",
    "    \n",
    "    # Segment karakteristiklerine gÃ¶re isimlendirme\n",
    "    if cluster_data['recency'] < cluster_analysis['recency'].median() and cluster_data['frequency'] > cluster_analysis['frequency'].median():\n",
    "        name = \"Loyal Customers\"\n",
    "    elif cluster_data['monetary'] > cluster_analysis['monetary'].quantile(0.75):\n",
    "        name = \"High Value Customers\"\n",
    "    elif cluster_data['recency'] > cluster_analysis['recency'].quantile(0.75):\n",
    "        name = \"At Risk Customers\"\n",
    "    elif cluster_data['frequency'] < cluster_analysis['frequency'].quantile(0.25):\n",
    "        name = \"New Customers\"\n",
    "    else:\n",
    "        name = f\"Segment {cluster_id}\"\n",
    "    \n",
    "    segment_names[cluster_id] = name\n",
    "    \n",
    "    print(f\"\\nCluster {cluster_id}: {name}\")\n",
    "    print(f\"   MÃ¼ÅŸteri SayÄ±sÄ±: {cluster_counts[cluster_id]} (%{cluster_counts[cluster_id]/len(cluster_labels)*100:.1f})\")\n",
    "    print(f\"   Ortalama YaÅŸ: {cluster_data['age']:.1f}\")\n",
    "    print(f\"   Ortalama Recency: {cluster_data['recency']:.1f} gÃ¼n\")\n",
    "    print(f\"   Ortalama Frequency: {cluster_data['frequency']:.1f}\")\n",
    "    print(f\"   Ortalama Monetary: {cluster_data['monetary']:.2f} â‚º\")\n",
    "    print(f\"   Ortalama CLV: {cluster_data['clv']:.2f} â‚º\")\n",
    "\n",
    "# Segment isimlerini veriye ekle\n",
    "rfm_scaled['segment_name'] = rfm_scaled['cluster'].map(segment_names)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SEGMENT Ã–ZETÄ°:\")\n",
    "segment_summary = rfm_scaled['segment_name'].value_counts()\n",
    "print(segment_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment gÃ¶rselleÅŸtirme\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('MÃ¼ÅŸteri Segmentleri Analizi', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Segment daÄŸÄ±lÄ±mÄ± (pasta grafik)\n",
    "segment_counts = rfm_scaled['segment_name'].value_counts()\n",
    "axes[0,0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%')\n",
    "axes[0,0].set_title('MÃ¼ÅŸteri Segment DaÄŸÄ±lÄ±mÄ±')\n",
    "\n",
    "# 2. Recency vs Frequency scatter\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple'][:best_k]\n",
    "for i in range(best_k):\n",
    "    cluster_data = rfm_scaled[rfm_scaled['cluster'] == i]\n",
    "    axes[0,1].scatter(cluster_data['recency'], cluster_data['frequency'], \n",
    "                     c=colors[i], label=segment_names[i], alpha=0.6)\n",
    "axes[0,1].set_xlabel('Recency (GÃ¼n)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].set_title('Recency vs Frequency')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. Monetary vs CLV scatter\n",
    "for i in range(best_k):\n",
    "    cluster_data = rfm_scaled[rfm_scaled['cluster'] == i]\n",
    "    axes[1,0].scatter(cluster_data['monetary'], cluster_data['clv'], \n",
    "                     c=colors[i], label=segment_names[i], alpha=0.6)\n",
    "axes[1,0].set_xlabel('Monetary (â‚º)')\n",
    "axes[1,0].set_ylabel('CLV (â‚º)')\n",
    "axes[1,0].set_title('Monetary vs CLV')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# 4. Segment baÅŸÄ±na ortalama CLV\n",
    "avg_clv_by_segment = rfm_scaled.groupby('segment_name')['clv'].mean().sort_values(ascending=False)\n",
    "axes[1,1].bar(range(len(avg_clv_by_segment)), avg_clv_by_segment.values)\n",
    "axes[1,1].set_xticks(range(len(avg_clv_by_segment)))\n",
    "axes[1,1].set_xticklabels(avg_clv_by_segment.index, rotation=45, ha='right')\n",
    "axes[1,1].set_title('Segment BaÅŸÄ±na Ortalama CLV')\n",
    "axes[1,1].set_ylabel('Ortalama CLV (â‚º)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Silhouette analizi\n",
    "sample_silhouette_values = silhouette_samples(X_clustering, cluster_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "y_lower = 10\n",
    "for i in range(best_k):\n",
    "    cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "    color = colors[i]\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.set_xlabel('Silhouette coefficient values')\n",
    "ax.set_ylabel('Cluster label')\n",
    "ax.set_title('Silhouette Analysis')\n",
    "\n",
    "ax.axvline(x=np.mean(sample_silhouette_values), color=\"red\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SatÄ±ÅŸ Tahmini (Regresyon)\n",
    "\n",
    "Bu bÃ¶lÃ¼mde mÃ¼ÅŸteri segmentasyonu ve diÄŸer Ã¶zellikleri kullanarak gelecekteki satÄ±ÅŸlarÄ± tahmin edeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SatÄ±ÅŸ tahmini iÃ§in veri hazÄ±rlama\n",
    "print(\"=== SATIÅž TAHMÄ°NÄ° VERÄ° HAZIRLAMA ===\\n\")\n",
    "\n",
    "# GÃ¼nlÃ¼k satÄ±ÅŸ verilerini hazÄ±rla\n",
    "daily_sales = transactions_df.groupby('transaction_date').agg({\n",
    "    'price': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'transaction_id': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "daily_sales.columns = ['date', 'total_sales', 'total_quantity', 'transaction_count']\n",
    "\n",
    "# Zaman Ã¶zellikleri ekle\n",
    "daily_sales['day_of_week'] = daily_sales['date'].dt.dayofweek\n",
    "daily_sales['month'] = daily_sales['date'].dt.month\n",
    "daily_sales['day_of_month'] = daily_sales['date'].dt.day\n",
    "daily_sales['quarter'] = daily_sales['date'].dt.quarter\n",
    "daily_sales['is_weekend'] = (daily_sales['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Lag Ã¶zellikleri (gecikmeli deÄŸerler)\n",
    "daily_sales['sales_lag1'] = daily_sales['total_sales'].shift(1)\n",
    "daily_sales['sales_lag7'] = daily_sales['total_sales'].shift(7)\n",
    "daily_sales['sales_lag30'] = daily_sales['total_sales'].shift(30)\n",
    "\n",
    "# Hareketli ortalamalar\n",
    "daily_sales['sales_ma7'] = daily_sales['total_sales'].rolling(window=7).mean()\n",
    "daily_sales['sales_ma30'] = daily_sales['total_sales'].rolling(window=30).mean()\n",
    "\n",
    "# Ä°lk eksik deÄŸerleri kaldÄ±r\n",
    "daily_sales = daily_sales.dropna()\n",
    "\n",
    "print(f\" GÃ¼nlÃ¼k satÄ±ÅŸ verisi boyutu: {daily_sales.shape}\")\n",
    "print(f\"Tarih aralÄ±ÄŸÄ±: {daily_sales['date'].min()} - {daily_sales['date'].max()}\")\n",
    "print(\"\\nGÃ¼nlÃ¼k satÄ±ÅŸ istatistikleri:\")\n",
    "print(daily_sales['total_sales'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–zellik seÃ§imi ve hazÄ±rlama\n",
    "# Hedef deÄŸiÅŸken: total_sales\n",
    "target = 'total_sales'\n",
    "\n",
    "# Ã–zellik seti\n",
    "feature_columns = [\n",
    "    'total_quantity', 'transaction_count', 'day_of_week', 'month', \n",
    "    'day_of_month', 'quarter', 'is_weekend', 'sales_lag1', 'sales_lag7',\n",
    "    'sales_lag30', 'sales_ma7', 'sales_ma30'\n",
    "]\n",
    "\n",
    "X = daily_sales[feature_columns]\n",
    "y = daily_sales[target]\n",
    "\n",
    "print(f\"Ã–zellik sayÄ±sÄ±: {len(feature_columns)}\")\n",
    "print(f\"Ã–rnek sayÄ±sÄ±: {len(X)}\")\n",
    "print(f\"Hedef deÄŸiÅŸken: {target}\")\n",
    "\n",
    "# EÄŸitim/test split\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, shuffle=False, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nEÄŸitim seti boyutu: {X_train.shape}\")\n",
    "print(f\"Test seti boyutu: {X_test.shape}\")\n",
    "\n",
    "# Ã–zellik Ã¶lÃ§ekleme\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\" Ã–zellik Ã¶lÃ§ekleme tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model eÄŸitimi ve deÄŸerlendirme\n",
    "print(\"=== REGRESYON MODELLERÄ° ===\\n\")\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Model sonuÃ§larÄ±nÄ± saklayacak liste\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"ðŸ”§ {name} eÄŸitiliyor...\")\n",
    "    \n",
    "    # Model eÄŸitimi\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Tahminler\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrikler\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    cv_mae = -cv_scores.mean()\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train MAE': train_mae,\n",
    "        'Test MAE': test_mae,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Train RÂ²': train_r2,\n",
    "        'Test RÂ²': test_r2,\n",
    "        'CV MAE': cv_mae\n",
    "    })\n",
    "    \n",
    "    print(f\"   Test MAE: {test_mae:.2f}\")\n",
    "    print(f\"   Test RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"   Test RÂ²: {test_r2:.3f}\")\n",
    "    print(f\"   CV MAE: {cv_mae:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# SonuÃ§larÄ± DataFrame'e Ã§evir\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n MODEL KARÅžILAÅžTIRMA:\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modeli seÃ§ ve detaylÄ± analiz\n",
    "best_model_name = results_df.loc[results_df['Test MAE'].idxmin(), 'Model']\n",
    "print(f\" En iyi model: {best_model_name}\")\n",
    "\n",
    "# En iyi modeli yeniden eÄŸit\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature importance (eÄŸer model destekliyorsa)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n {best_model_name} - Feature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Feature importance gÃ¶rselleÅŸtirme\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "    plt.title(f'{best_model_name} - Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    feature_coef = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'coefficient': best_model.coef_\n",
    "    }).sort_values('coefficient', key=abs, ascending=False)\n",
    "    \n",
    "    print(f\"\\n {best_model_name} - Feature Coefficients:\")\n",
    "    print(feature_coef)\n",
    "\n",
    "# Tahmin vs gerÃ§ek deÄŸerler\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('GerÃ§ek DeÄŸerler')\n",
    "plt.ylabel('Tahmin Edilen DeÄŸerler')\n",
    "plt.title(f'{best_model_name} - Tahmin vs GerÃ§ek')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_test_pred\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Tahmin Edilen DeÄŸerler')\n",
    "plt.ylabel('ArtÄ±klar (Residuals)')\n",
    "plt.title('ArtÄ±k Analizi')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MÃ¼ÅŸteri DavranÄ±ÅŸ SÄ±nÄ±flandÄ±rmasÄ±\n",
    "\n",
    "Bu bÃ¶lÃ¼mde mÃ¼ÅŸterileri loyal/non-loyal olarak sÄ±nÄ±flandÄ±racaÄŸÄ±z ve hangi faktÃ¶rlerin mÃ¼ÅŸteri sadakatini etkilediÄŸini analiz edeceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loyal mÃ¼ÅŸteri sÄ±nÄ±flandÄ±rmasÄ± iÃ§in veri hazÄ±rlama\n",
    "print(\"=== MÃœÅžTERÄ° DAVRANIÅž SINIFLANDIRMASI ===\\n\")\n",
    "\n",
    "# Loyal mÃ¼ÅŸteri tanÄ±mÄ± (frequency ve monetary'e gÃ¶re)\n",
    "frequency_threshold = rfm_scaled['frequency'].quantile(0.7)  # Ãœst %30\n",
    "monetary_threshold = rfm_scaled['monetary'].quantile(0.7)   # Ãœst %30\n",
    "\n",
    "print(f\" Loyal MÃ¼ÅŸteri EÅŸikleri:\")\n",
    "print(f\"  Frequency eÅŸiÄŸi: {frequency_threshold:.2f}\")\n",
    "print(f\"  Monetary eÅŸiÄŸi: {monetary_threshold:.2f}\")\n",
    "\n",
    "# Loyal mÃ¼ÅŸteri etiketi oluÅŸtur\n",
    "rfm_scaled['is_loyal'] = ((rfm_scaled['frequency'] >= frequency_threshold) & \n",
    "                          (rfm_scaled['monetary'] >= monetary_threshold)).astype(int)\n",
    "\n",
    "loyal_counts = rfm_scaled['is_loyal'].value_counts()\n",
    "print(f\"\\n MÃ¼ÅŸteri DaÄŸÄ±lÄ±mÄ±:\")\n",
    "print(f\"  Loyal mÃ¼ÅŸteriler: {loyal_counts[1]} (%{loyal_counts[1]/len(rfm_scaled)*100:.1f})\")\n",
    "print(f\"  Non-loyal mÃ¼ÅŸteriler: {loyal_counts[0]} (%{loyal_counts[0]/len(rfm_scaled)*100:.1f})\")\n",
    "\n",
    "# SÄ±nÄ±flandÄ±rma iÃ§in Ã¶zellikler\n",
    "classification_features = [\n",
    "    'age_scaled', 'recency_scaled', 'frequency_scaled', \n",
    "    'monetary_scaled', 'clv_scaled', 'avg_order_value_scaled',\n",
    "    'gender_encoded', 'city_encoded'\n",
    "]\n",
    "\n",
    "X_class = rfm_scaled[classification_features]\n",
    "y_class = rfm_scaled['is_loyal']\n",
    "\n",
    "print(f\"\\n SÄ±nÄ±flandÄ±rma veri boyutu: {X_class.shape}\")\n",
    "print(f\"Ã–zellikler: {classification_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "print(f\"EÄŸitim seti boyutu: {X_train_class.shape}\")\n",
    "print(f\"Test seti boyutu: {X_test_class.shape}\")\n",
    "print(f\"EÄŸitim seti loyal oranÄ±: {y_train_class.mean():.3f}\")\n",
    "print(f\"Test seti loyal oranÄ±: {y_test_class.mean():.3f}\")\n",
    "\n",
    "# Ã–zellik Ã¶lÃ§ekleme\n",
    "class_scaler = StandardScaler()\n",
    "X_train_class_scaled = class_scaler.fit_transform(X_train_class)\n",
    "X_test_class_scaled = class_scaler.transform(X_test_class)\n",
    "\n",
    "print(\" SÄ±nÄ±flandÄ±rma veri hazÄ±rlÄ±ÄŸÄ± tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÄ±nÄ±flandÄ±rma modelleri\n",
    "print(\"=== SINIFLANDIRMA MODELLERÄ° ===\\n\")\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "classification_results = []\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\" {name} eÄŸitiliyor...\")\n",
    "    \n",
    "    # Model eÄŸitimi\n",
    "    clf.fit(X_train_class_scaled, y_train_class)\n",
    "    \n",
    "    # Tahminler\n",
    "    y_train_pred = clf.predict(X_train_class_scaled)\n",
    "    y_test_pred = clf.predict(X_test_class_scaled)\n",
    "    \n",
    "    # SÄ±nÄ±flandÄ±rma raporu\n",
    "    test_report = classification_report(y_test_class, y_test_pred, output_dict=True)\n",
    "    train_report = classification_report(y_train_class, y_train_pred, output_dict=True)\n",
    "    \n",
    "    classification_results.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': train_report['accuracy'],\n",
    "        'Test Accuracy': test_report['accuracy'],\n",
    "        'Test Precision': test_report['1']['precision'],\n",
    "        'Test Recall': test_report['1']['recall'],\n",
    "        'Test F1-Score': test_report['1']['f1-score']\n",
    "    })\n",
    "    \n",
    "    print(f\"   Test Accuracy: {test_report['accuracy']:.3f}\")\n",
    "    print(f\"   Test Precision: {test_report['1']['precision']:.3f}\")\n",
    "    print(f\"   Test Recall: {test_report['1']['recall']:.3f}\")\n",
    "    print(f\"   Test F1-Score: {test_report['1']['f1-score']:.3f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# SonuÃ§larÄ± DataFrame'e Ã§evir\n",
    "class_results_df = pd.DataFrame(classification_results)\n",
    "print(\"\\n SINIFLANDIRMA MODEL KARÅžILAÅžTIRMA:\")\n",
    "print(class_results_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi sÄ±nÄ±flandÄ±rma modelini seÃ§\n",
    "best_classifier_name = class_results_df.loc[class_results_df['Test F1-Score'].idxmax(), 'Model']\n",
    "print(f\" En iyi sÄ±nÄ±flandÄ±rma modeli: {best_classifier_name}\")\n",
    "\n",
    "# En iyi modeli yeniden eÄŸit\n",
    "best_classifier = classifiers[best_classifier_name]\n",
    "best_classifier.fit(X_train_class_scaled, y_train_class)\n",
    "\n",
    "# Confusion Matrix\n",
    "y_test_pred_class = best_classifier.predict(X_test_class_scaled)\n",
    "cm = confusion_matrix(y_test_class, y_test_pred_class)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Loyal', 'Loyal'], \n",
    "            yticklabels=['Non-Loyal', 'Loyal'])\n",
    "plt.title(f'{best_classifier_name} - Confusion Matrix')\n",
    "plt.ylabel('GerÃ§ek DeÄŸer')\n",
    "plt.xlabel('Tahmin Edilen')\n",
    "\n",
    "# Classification Report\n",
    "plt.subplot(1, 2, 2)\n",
    "report = classification_report(y_test_class, y_test_pred_class, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df = report_df.round(3)\n",
    "\n",
    "# Heatmap olarak gÃ¶ster\n",
    "sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap='RdYlGn')\n",
    "plt.title('Classification Report')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(pd.DataFrame(classification_report(y_test_class, y_test_pred_class, output_dict=True)).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance analizi\n",
    "print(\"=== FEATURE IMPORTANCE ANALÄ°ZÄ° ===\\n\")\n",
    "\n",
    "if hasattr(best_classifier, 'feature_importances_'):\n",
    "    # Random Forest iÃ§in feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': classification_features,\n",
    "        'importance': best_classifier.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "elif hasattr(best_classifier, 'coef_'):\n",
    "    # Logistic Regression iÃ§in feature importance (coefficients)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': classification_features,\n",
    "        'importance': np.abs(best_classifier.coef_[0])\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\" {best_classifier_name} - Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Feature importance gÃ¶rselleÅŸtirme\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.title(f'{best_classifier_name} - Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# En Ã¶nemli Ã¶zellikler yorumu\n",
    "print(\"\\nðŸ’¡ EN Ã–NEMLÄ° Ã–ZELLÄ°KLER:\")\n",
    "top_features = feature_importance.head(5)\n",
    "for idx, row in top_features.iterrows():\n",
    "    feature_name = row['feature'].replace('_scaled', '').replace('_encoded', '')\n",
    "    print(f\"  {idx+1}. {feature_name}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SonuÃ§lar ve Raporlama\n",
    "\n",
    "Bu bÃ¶lÃ¼mde proje sonuÃ§larÄ±nÄ± Ã¶zetleyip iÅŸ Ã¶nerileri ve gelecek Ã§alÄ±ÅŸmalar iÃ§in Ã¶neriler sunacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJE SONUÃ‡LARI Ã–ZETÄ°\n",
    "print(\"=\" * 80)\n",
    "print(\"                    PROJE SONUÃ‡LARI Ã–ZETÄ°\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n 1. VERÄ° ANALÄ°ZÄ° SONUÃ‡LARI:\")\n",
    "print(f\"   â€¢ Toplam mÃ¼ÅŸteri sayÄ±sÄ±: {len(customers_df):,}\")\n",
    "print(f\"   â€¢ Toplam Ã¼rÃ¼n sayÄ±sÄ±: {len(products_df):,}\")\n",
    "print(f\"   â€¢ Toplam iÅŸlem sayÄ±sÄ±: {len(transactions_df):,}\")\n",
    "print(f\"   â€¢ Toplam etkileÅŸim sayÄ±sÄ±: {len(interactions_df):,}\")\n",
    "\n",
    "avg_customer_value = customers_df['total_spent'].mean()\n",
    "print(f\"   â€¢ Ortalama mÃ¼ÅŸteri deÄŸeri: {avg_customer_value:.2f} â‚º\")\n",
    "\n",
    "print(\"\\n 2. MÃœÅžTERÄ° SEGMENTASYONU:\")\n",
    "print(f\"   â€¢ Optimum cluster sayÄ±sÄ±: {best_k}\")\n",
    "print(f\"   â€¢ Segment daÄŸÄ±lÄ±mÄ±:\")\n",
    "for segment, count in segment_summary.items():\n",
    "    print(f\"     - {segment}: {count} mÃ¼ÅŸteri (%{count/len(rfm_scaled)*100:.1f})\")\n",
    "\n",
    "print(\"\\n 3. SATIÅž TAHMÄ°NÄ°:\")\n",
    "best_regression = results_df.loc[results_df['Test MAE'].idxmin()]\n",
    "print(f\"   â€¢ En iyi model: {best_regression['Model']}\")\n",
    "print(f\"   â€¢ Test MAE: {best_regression['Test MAE']:.2f}\")\n",
    "print(f\"   â€¢ Test RÂ²: {best_regression['Test RÂ²']:.3f}\")\n",
    "print(f\"   â€¢ Test RMSE: {best_regression['Test RMSE']:.2f}\")\n",
    "\n",
    "print(\"\\n 4. MÃœÅžTERÄ° SINIFLANDIRMASI:\")\n",
    "best_classification = class_results_df.loc[class_results_df['Test F1-Score'].idxmax()]\n",
    "print(f\"   â€¢ En iyi model: {best_classification['Model']}\")\n",
    "print(f\"   â€¢ Test Accuracy: {best_classification['Test Accuracy']:.3f}\")\n",
    "print(f\"   â€¢ Test F1-Score: {best_classification['Test F1-Score']:.3f}\")\n",
    "print(f\"   â€¢ Loyal mÃ¼ÅŸteri oranÄ±: %{y_class.mean()*100:.1f}\")\n",
    "\n",
    "print(\"\\n 5. Ã–NE Ã‡IKAN BULGULAR:\")\n",
    "print(f\"   â€¢ En deÄŸerli segment: {avg_clv_by_segment.index[0]}\")\n",
    "print(f\"   â€¢ En yÃ¼ksek CLV: {avg_clv_by_segment.iloc[0]:.2f} â‚º\")\n",
    "\n",
    "# Feature importance'dan en Ã¶nemli faktÃ¶r\n",
    "top_factor = feature_importance.iloc[0]['feature'].replace('_scaled', '').replace('_encoded', '')\n",
    "print(f\"   â€¢ MÃ¼ÅŸteri sadakatinde en Ã¶nemli faktÃ¶r: {top_factor}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ä°ÅŸ Ã¶nerileri ve stratejiler\n",
    "print(\"=\" * 80)\n",
    "print(\"                    Ä°Åž Ã–NERÄ°LERÄ° VE STRATEJÄ°LER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\ 1. MÃœÅžTERÄ° SEGMENTASYONU STRATEJÄ°LERÄ°:\")\n",
    "print(\"\\n    Loyal Customers (%_loyal):\")\n",
    "print(\"   â€¢ Ã–zel mÃ¼ÅŸteri programlarÄ± oluÅŸturun\")\n",
    "print(\"   â€¢ Early access fÄ±rsatlarÄ± sunun\")\n",
    "print(\"   â€¢ KiÅŸiselleÅŸtirilmiÅŸ Ã¶neriler geliÅŸtirin\")\n",
    "print(\"   â€¢ Sadakat Ã¶dÃ¼lleri programlarÄ± uygulayÄ±n\")\n",
    "\n",
    "print(\"\\n    High Value Customers:\")\n",
    "print(\"   â€¢ Premium hizmet paketleri oluÅŸturun\")\n",
    "print(\"   â€¢ VIP mÃ¼ÅŸteri temsilcisi atayÄ±n\")\n",
    "print(\"   â€¢ Exclusive Ã¼rÃ¼n lansmanlarÄ± yapÄ±n\")\n",
    "print(\"   â€¢ Ä°ndirim ve kampanya Ã¶nceliÄŸi verin\")\n",
    "\n",
    "print(\"\\n     At Risk Customers:\")\n",
    "print(\"   â€¢ Win-back kampanyalarÄ± dÃ¼zenleyin\")\n",
    "print(\"   â€¢ Ã–zel indirimler teklif edin\")\n",
    "print(\"   â€¢ Anketlerle geri bildirim alÄ±n\")\n",
    "print(\"   â€¢ MÃ¼ÅŸteri hizmetleri ile iletiÅŸime geÃ§in\")\n",
    "\n",
    "print(\"\\n 2. SATIÅž TAHMÄ°NÄ° VE Ä°Åž PLANLAMA:\")\n",
    "print(\"   â€¢ GÃ¼nlÃ¼k satÄ±ÅŸ tahminlerini kullanarak envanter yÃ¶netimini optimize edin\")\n",
    "print(\"   â€¢ YÃ¼ksek satÄ±ÅŸ gÃ¼nleri iÃ§in hazÄ±rlÄ±k yapÄ±n\")\n",
    "print(\"   â€¢ Sezonluk trendleri gÃ¶z Ã¶nÃ¼nde bulundurun\")\n",
    "print(\"   â€¢ Pazarlama bÃ¼tÃ§esini tahminlere gÃ¶re planlayÄ±n\")\n",
    "\n",
    "print(\"\\n 3. MÃœÅžTERÄ° DAVRANIÅž ANALÄ°ZÄ°:\")\n",
    "print(f\"   â€¢ En Ã¶nemli faktÃ¶r ({top_factor}) Ã¼zerinde odaklanÄ±n\")\n",
    "print(\"   â€¢ MÃ¼ÅŸteri yolculuÄŸunu optimize edin\")\n",
    "print(\"   â€¢ KiÅŸiselleÅŸtirilmiÅŸ deneyimler sunun\")\n",
    "print(\"   â€¢ EtkileÅŸim noktalarÄ±nÄ± gÃ¼Ã§lendirin\")\n",
    "\n",
    "print(\"\\n  4. GENEL Ä°Åž GELÄ°ÅžTÄ°RME Ã–NERÄ°LERÄ°:\")\n",
    "print(\"   â€¢ Real-time analitik dashboard oluÅŸturun\")\n",
    "print(\"   â€¢ MÃ¼ÅŸteri yaÅŸam dÃ¶ngÃ¼sÃ¼ takibini otomatikleÅŸtirin\")\n",
    "print(\"   â€¢ AI destekli Ã¶neri sistemleri geliÅŸtirin\")\n",
    "print(\"   â€¢ Multi-channel entegrasyon saÄŸlayÄ±n\")\n",
    "print(\"   â€¢ A/B testleri ile stratejileri optimize edin\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gelecek Ã§alÄ±ÅŸmalar ve iyileÅŸtirmeler\n",
    "print(\"=\" * 80)\n",
    "print(\"                 GELECEK Ã‡ALIÅžMALAR VE Ä°YÄ°LEÅžTÄ°RMELER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n 1. VERÄ° BÄ°LÄ°MÄ° GELÄ°ÅžTÄ°RMELERÄ°:\")\n",
    "print(\"    Veri GeniÅŸletme:\")\n",
    "print(\"   â€¢ Daha fazla mÃ¼ÅŸteri demografik verisi toplayÄ±n\")\n",
    "print(\"   â€¢ Sosyal medya etkileÅŸim verilerini dahil edin\")\n",
    "print(\"   â€¢ ÃœrÃ¼n yorum ve puanlama verilerini kullanÄ±n\")\n",
    "print(\"   â€¢ Sesli mÃ¼ÅŸteri hizmetleri kayÄ±tlarÄ±nÄ± analiz edin\")\n",
    "\n",
    "print(\"\\n    GeliÅŸmiÅŸ Modeller:\")\n",
    "print(\"   â€¢ Deep Learning modelleri deneyin (LSTM, GRU)\")\n",
    "print(\"   â€¢ Ensemble yÃ¶ntemlerini test edin\")\n",
    "print(\"   â€¢ Time series forecasting iÃ§in Prophet kullanÄ±n\")\n",
    "print(\"   â€¢ NLP analizi ile Ã¼rÃ¼n aÃ§Ä±klamalarÄ±nÄ± deÄŸerlendirin\")\n",
    "\n",
    "print(\"\\ 2. TEKNÄ°K GELÄ°ÅžTÄ°RMELER:\")\n",
    "print(\"    Sistem Optimizasyonu:\")\n",
    "print(\"   â€¢ Real-time scoring sistemi kurun\")\n",
    "print(\"   â€¢ MLOps pipeline'Ä±nÄ± otomatikleÅŸtirin\")\n",
    "print(\"   â€¢ API servisi geliÅŸtirin\")\n",
    "print(\"   â€¢ Cloud tabanlÄ± Ã§Ã¶zÃ¼mler implementasyonu\")\n",
    "\n",
    "print(\"\\n    GÃ¶rselleÅŸtirme ve Raporlama:\")\n",
    "print(\"   â€¢ Interactive dashboard geliÅŸtirin\")\n",
    "print(\"   â€¢ Automated reporting sistemi\")\n",
    "print(\"   â€¢ Mobile-friendly uygulamalar\")\n",
    "print(\"   â€¢ Executive summary raporlarÄ±\")\n",
    "\n",
    "print(\"\\n 3. Ä°Åž UYGULAMALARI:\")\n",
    "print(\"    Operasyonel Entegrasyon:\")\n",
    "print(\"   â€¢ CRM sistemine entegre edin\")\n",
    "print(\"   â€¢ Marketing automation ile baÄŸlantÄ± kurun\")\n",
    "print(\"   â€¢ Inventory management sistemine dahil edin\")\n",
    "print(\"   â€¢ Customer support'ta kullanÄ±n\")\n",
    "\n",
    "print(\"\\n    SÃ¼rekli Ä°yileÅŸtirme:\")\n",
    "print(\"   â€¢ Model performansÄ±nÄ± dÃ¼zenli izleyin\")\n",
    "print(\"   â€¢ A/B testing ile validasyon yapÄ±n\")\n",
    "print(\"   â€¢ Feedback loop kurun\")\n",
    "print(\"   â€¢ Business impact'ini Ã¶lÃ§Ã¼n\")\n",
    "\n",
    "print(\"\\n  4. ARAÅžTIRMA KONULARI:\")\n",
    "print(\"   â€¢ Causal inference analizi\")\n",
    "print(\"   â€¢ Customer churn prediction\")\n",
    "print(\"   â€¢ Market basket analysis\")\n",
    "print(\"   â€¢ Recommendation systems optimization\")\n",
    "print(\"   â€¢ Dynamic pricing strategies\")\n",
    "print(\"   â€¢ Cross-channel customer journey mapping\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Bu projede elde edilen sonuÃ§lar ve Ã¶neriler,\")\n",
    "print(\" iÅŸletmenizin mÃ¼ÅŸteri deneyimini iyileÅŸtirmek ve\")\n",
    "print(\" bÃ¼yÃ¼me stratejilerinizi desteklemek iÃ§in kullanÄ±labilir.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sonuÃ§larÄ± kaydet\n",
    "print(\"=== SONUÃ‡LARI KAYDETME ===\\n\")\n",
    "\n",
    "try:\n",
    "    # Ana sonuÃ§larÄ± kaydet\n",
    "    rfm_scaled.to_csv('data/final_rfm_with_segments.csv', index=False)\n",
    "    print(\"RFM verisi segmentlerle birlikte kaydedildi: data/final_rfm_with_segments.csv\")\n",
    "    \n",
    "    # Model sonuÃ§larÄ±nÄ± kaydet\n",
    "    results_df.to_csv('data/model_performance_results.csv', index=False)\n",
    "    print(\"Model performans sonuÃ§larÄ± kaydedildi: data/model_performance_results.csv\")\n",
    "    \n",
    "    class_results_df.to_csv('data/classification_results.csv', index=False)\n",
    "    print(\" SÄ±nÄ±flandÄ±rma sonuÃ§larÄ± kaydedildi: data/classification_results.csv\")\n",
    "    \n",
    "    # Feature importance'Ä± kaydet\n",
    "    feature_importance.to_csv('data/feature_importance.csv', index=False)\n",
    "    print(\"Feature importance kaydedildi: data/feature_importance.csv\")\n",
    "    \n",
    "    # Segment analizini kaydet\n",
    "    cluster_analysis.to_csv('data/cluster_analysis.csv')\n",
    "    print(\" Cluster analizi kaydedildi: data/cluster_analysis.csv\")\n",
    "    \n",
    "    # GÃ¼nlÃ¼k satÄ±ÅŸ verilerini kaydet\n",
    "    daily_sales.to_csv('data/daily_sales_data.csv', index=False)\n",
    "    print(\" GÃ¼nlÃ¼k satÄ±ÅŸ verileri kaydedildi: data/daily_sales_data.csv\")\n",
    "    \n",
    "    print(\" TÃ¼m sonuÃ§lar 'data/' klasÃ¶rÃ¼ne kaydedildi.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Kaydetme sÄ±rasÄ±nda hata: {e}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"JUPYTER NOTEBOOK SONUNDA!\")\n",
    "print(\"TÃ¼m analizler tamamlandÄ± ve sonuÃ§lar kaydedildi.\")\n",
    "print(\" Elde edilen insights'larÄ± iÅŸ stratejilerinizde kullanabilirsiniz.\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
